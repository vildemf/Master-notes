Automatically generated by Mendeley Desktop 1.17.11
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Turek2017,
abstract = {Markov chain Monte Carlo (MCMC) sampling is an important and commonly used tool for the analysis of hierarchical models. Nevertheless, prac-titioners generally have two options for MCMC: utilize existing software that generates a black-box " one size fits all " algorithm, or the challenging (and time consuming) task of implementing a problem-specific MCMC algorithm. Either choice may result in inefficient sampling, and hence researchers have become ac-customed to MCMC runtimes on the order of days (or longer) for large models. We propose an automated procedure to determine an efficient MCMC block-sampling algorithm for a given model and computing platform. Our procedure dynami-cally determines blocks of parameters for joint sampling that result in efficient MCMC sampling of the entire model. We test this procedure using a diverse suite of example models, and observe non-trivial improvements in MCMC efficiency for many models. Our procedure is the first attempt at such, and may be generalized to a broader space of MCMC algorithms. Our results suggest that substantive improvements in MCMC efficiency may be practically realized using our auto-mated blocking procedure, or variants thereof, which warrants additional study and application.},
author = {Turek, Daniel and {De Valpine}, Perry and Paciorek, Christopher J and Anderson-Bergman, Clifford},
doi = {10.1214/16-BA1008},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Turek et al. - 2017 - Automated Parameter Blocking for Efficient Markov Chain Monte Carlo Sampling.pdf:pdf},
journal = {Bayesian Analysis},
keywords = {MCMC,Metropolis?Hastings,NIMBLE,block sampling,integrated autocorrelation time,mixing},
number = {2},
pages = {465--490},
title = {{Automated Parameter Blocking for Efficient Markov Chain Monte Carlo Sampling}},
url = {https://projecteuclid.org/download/pdfview{\_}1/euclid.ba/1464266500},
volume = {12},
year = {2017}
}
@article{Luo2007,
abstract = {We present a perturbative treatment of Jastrow-type correlation factors which focus on an accurate descrip-tion of short-range correlations. Our approach is closely related to coupled cluster perturbation theory with the essential difference that we start from a variational formulation for the energy. Such kind of perturbation theory is especially suited for multiscale bases, such as wavelets, which provide sparse representations for Jastrow factors. Envisaged applications in solid-state physics are confined many-particle systems such as electrons or multiexcitons in quantum dots. The resulting Jastrow factors can be further used as trial wave functions in quantum Monte Carlo calculations for these systems. First applications to a screened homogeneous Fermi gas model demonstrate that first-order Jastrow factors already recover 95{\%} of the correlation energy in variational Monte Carlo calculations over a fairly large range of densities and screening parameters. The corresponding second-and third-order perturbation energies turned out to be more sensitive to the specific choice of the model parameters. Furthermore, we have compared our first-order Jastrow factors with those obtained from Fermi hypernetted chain calculations, where excellent agreement at short and intermediate interparticle distances has been observed.},
author = {Luo, Hongjun and Kolb, Dietmar and Flad, Heinz-J{\"{u}}rgen and Hackbusch, Wolfgang},
doi = {10.1103/PhysRevB.75.125111},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Luo et al. - Unknown - Perturbative calculation of Jastrow factors Accurate description of short-range correlations.pdf:pdf},
journal = {Physical Review B},
number = {10},
title = {{Perturbative Calculation of Jastrow Factors: Accurate Description of Short-Range Correlations}},
url = {https://journals.aps.org/prb/pdf/10.1103/PhysRevB.75.125111},
volume = {75},
year = {2007}
}
@article{Huang1997,
annote = {!!},
author = {Huang, Chien-Jung and Umrigar, C J and Nightingale, M P},
doi = {10.1063/1.1727484},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Huang, Umrigar, Nightingale - 1997 - Accuracy of Electronic Wave Functions in Quantum Monte Carlo The Effect of Higher-Order Correlation.pdf:pdf},
journal = {The Journal of Chemical Physics},
title = {{Accuracy of Electronic Wave Functions in Quantum Monte Carlo: The Effect of Higher-Order Correlations}},
url = {https://doi.org/10.1063/1.474658},
volume = {107},
year = {1997}
}
@article{Ceperley1977,
abstract = {The Metropolis Monte Carlo method is used to sample the square of an antisymmetric wave function composed of a product of a Jastrow wave function and a number of Slater determinants. {\%}e calculate variational energies for 'He and several models of neutron matter. The first-order Wu-Feenberg expansion is shown always to underestimate the energy, sometimes seriously. The phase diagram for ground-state Yukawa matter is determined. There is a class of Yukawa potentials which do not lead to a crystal phase at any density.},
annote = {First(?) application of VMC to fermions

Also: shows better to update 1 electron at a time than all (i appendixet). (Umrigar1999)},
author = {Ceperley, D and Chester, G V and Kalos, M H},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Ceperley, Chester, Kalos - 1977 - Monte Carlo Simulation of a Many-Fermion Study.pdf:pdf},
journal = {Physical Review B},
number = {7},
title = {{Monte Carlo Simulation of a Many-Fermion Study}},
url = {https://journals.aps.org/prb/pdf/10.1103/PhysRevB.16.3081},
volume = {16},
year = {1977}
}
@article{Hinton2002,
abstract = {It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renor-malizing. This way of combining individual " expert " models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally in-dependent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. For-tunately, a PoE can be trained using a different objective function called " contrastive divergence " whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data.},
annote = {Probably the first use of the term "The Restricted Boltzmann Machine" and the third paper to discuss them. (Welling2005)

It includes the statement
"Boltzmann machines and PoEs are very different classes of probabilistic generative model, and the intersection of the two classes is RBMs."},
author = {Hinton, Geoffrey E},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Hinton - Unknown - Training Products of Experts by Minimizing Contrastive Divergence.pdf:pdf},
journal = {Neural Computation},
number = {8},
pages = {1771--1800},
title = {{Training Products of Experts by Minimizing Contrastive Divergence}},
url = {http://www.cs.cmu.edu/{~}bhiksha/courses/deeplearning/Fall.2016/pdfs/Hinton{\_}2002.pdf},
volume = {14},
year = {2002}
}
@book{HjortJensen2017,
annote = {Chapter 9:
-Short and precise intro to all VMC elements (variational principle, local energy, MC methods and Markov chains)
-Including autocorrelation, blocking, wavefunction constructing, and optimization},
author = {Hjort-Jensen, Morten and Lombardo, Maria Paola and {Van Kolck}, Ubirajara},
doi = {10.1007/978-3-319-53336-0},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Hjorth-Jensen Maria Paola Lombardo Ubirajara van Kolck Editors - Unknown - Lecture Notes in Physics 936 An Advanced Course in Computatio.pdf:pdf},
isbn = {978-3-319-53335-3},
publisher = {Springer International Publishing},
title = {{An Advanced Course in Computational Nuclear Physics: Bridging the Scales from Quarks to Neutron Stars}},
url = {https://link.springer.com/content/pdf/10.1007{\%}2F978-3-319-53336-0.pdf},
year = {2017}
}
@phdthesis{Nilsen2010,
author = {Nilsen, Jon K},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Kerr Nilsen - 2010 - Quantum Monte Carlo and Data Management in Grid Middleware.pdf:pdf},
school = {University of Oslo},
title = {{Quantum Monte Carlo and Data Management in Grid Middleware}},
type = {PhD thesis},
url = {https://www.duo.uio.no/bitstream/handle/10852/10982/2/dravh-publ-Nilsen.pdf},
year = {2010}
}
@article{Klos2016,
abstract = {Ab initio calculations provide direct access to the properties of pure neutron systems that are challenging to study experimentally. In addition to their importance for fundamental physics, their properties are required as input for effective field theories of the strong interaction. In this work, we perform auxiliary-field diffusion Monte Carlo calculations of the ground state and first excited state of two neutrons in a finite box, considering a simple contact potential as well as chiral effective field theory interactions. We compare the results against exact diagonalizations and present a detailed analysis of the finite-volume effects, whose understanding is crucial for determining observables from the calculated energies. Using the L{\"{u}}scher formula, we extract the low-energy S-wave scattering parameters from ground-and excited-state energies for different box sizes.},
author = {Klos, P and Lynn, J E and Tews, I and Gandolfi, S and Gezerlis, A and Hammer, H.-W and Hoferichter, M and Schwenk, A},
doi = {10.1103/PhysRevC.94.054005},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Klos et al. - Unknown - Quantum Monte Carlo calculations of two neutrons in finite volume.pdf:pdf},
journal = {Physical Review C},
number = {5},
title = {{Quantum Monte Carlo Calculations of Two Neutrons in Finite Volume}},
url = {https://journals.aps.org/prc/pdf/10.1103/PhysRevC.94.054005},
volume = {94},
year = {2016}
}
@article{Toulouse2008,
author = {Toulouse, Julien and Umrigar, C J},
doi = {10.1063/1.2908237},
file = {:Users/Vilde/Downloads/TouUmr-JCP-08.pdf:pdf},
journal = {The Journal of Chemical Physics},
title = {{Full optimization of Jastrow–Slater Wave Functions with Application to the First-Row Atoms and Homonuclear Diatomic Molecules}},
volume = {128},
year = {2008}
}
@incollection{Bengio2007,
abstract = {One long-term goal of machine learning research is to produce methods that are applicable to highly complex tasks, such as perception (vision, audition), rea-soning, intelligent control, and other artificially intelligent behaviors. We argue that in order to progress toward this goal, the Machine Learning community must endeavor to discover algorithms that can learn highly complex functions, with min-imal need for prior knowledge, and with minimal human intervention. We present mathematical and empirical evidence suggesting that many popular approaches to non-parametric learning, particularly kernel methods, are fundamentally lim-ited in their ability to learn complex high-dimensional functions. Our analysis focuses on two problems. First, kernel machines are shallow architectures, in which one large layer of simple template matchers is followed by a single layer of trainable coefficients. We argue that shallow architectures can be very ineffi-cient in terms of required number of computational elements and examples. Sec-ond, we analyze a limitation of kernel machines with a local kernel, linked to the curse of dimensionality, that applies to supervised, unsupervised (manifold learn-ing) and semi-supervised kernel machines. Using empirical results on invariant image recognition tasks, kernel methods are compared with deep architectures, in which lower-level features or concepts are progressively combined into more ab-stract and higher-level representations. We argue that deep architectures have the potential to generalize in non-local ways, i.e., beyond immediate neighbors, and that this is crucial in order to make progress on the kind of complex tasks required for artificial intelligence.},
annote = {Inkluderer noen bredere perspektiver p{\aa} hvilke "costs" vi {\o}nsker minimere etc.},
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large-Scale Kernel Machines},
editor = {Bottou, L{\'{e}}on and Chapelle, Olivier and DeCoste, Dennis and Weston, Jason},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Bengio, LeCun - 2007 - Scaling Learning Algorithms towards AI.pdf:pdf},
isbn = {9780262026253},
publisher = {MIT Press},
title = {{Scaling Learning Algorithms towards AI}},
url = {http://www.iro.umontreal.ca/{~}lisa/bib/pub{\_}subject/language/pointeurs/bengio+lecun-chapter2007.pdf},
year = {2007}
}
@article{Chang2016,
abstract = {Quantum Monte Carlo (QMC) algorithms have long relied on Jastrow factors to incorporate dynamic correlation into trial wave functions. While Jastrow-type wave functions have been widely employed in real-space algorithms, they have seen limited use in second-quantized QMC methods, particularly in projection methods that involve a stochastic evolution of the wave function in imaginary time. Here we propose a scheme for generating Jastrow-type correlated trial wave functions for auxiliary-field QMC methods. The method is based on decoupling the two-body Jastrow into one-body projectors coupled to auxiliary fields, which then operate on a single determinant to produce a multideterminant trial wave function. We demonstrate that intelligent sampling of the most significant determinants in this expansion can produce compact trial wave functions that reduce errors in the calculated energies. Our technique may be readily generalized to accommodate a wide range of two-body Jastrow factors and applied to a variety of model and chemical systems.},
author = {Chang, Chia-Chen and Rubenstein, Brenda M and Morales, Miguel A},
doi = {10.1103/PhysRevB.94.235144},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Chang, Rubenstein, Morales - 2016 - Auxiliary-field-based trial wave functions in quantum Monte Carlo calculations.pdf:pdf},
journal = {Physical Review B},
title = {{Auxiliary-Field-Based Trial Wave Functions in Quantum Monte Carlo Calculations}},
url = {https://journals.aps.org/prb/pdf/10.1103/PhysRevB.94.235144},
volume = {94},
year = {2016}
}
@article{Flyvbjerg1989,
abstract = {We describe how the true statistical error on an average of correlated data can be obtained with ease and efficiency by a renormalization group method. The method is illustrated with numerical and analytical examples, having finite as well as infinite range correlations.},
annote = {used by (Lervag2010) for blocking.},
author = {Flyvbjerg, H and Petersen, H G},
doi = {10.1063/1.457480},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Flyvbjerg, Petersen - 1989 - Error estimates on averages of correlated data Comparison of simple potential functions for simulating liqu.pdf:pdf},
journal = {The Journal of Chemical Physics},
number = {461},
title = {{Error Estimates on Averages of Correlated Data}},
url = {https://doi.org/10.1063/1.457480 http://aip.scitation.org/toc/jcp/91/1},
volume = {91},
year = {1989}
}
@article{Kim2018,
abstract = {QMCPACK is an open source quantum Monte Carlo package for ab initio electronic structure calculations. It supports calculations of metallic and insulating solids, molecules, atoms, and some model Hamiltonians. Implemented real space quantum Monte Carlo algorithms include variational, diffusion, and reptation Monte Carlo. QMCPACK uses Slater–Jastrow type trial wavefunctions in conjunction with a sophisticated optimizer capable of optimizing tens of thousands of parameters. The orbital space auxiliary-field quantum Monte Carlo method is also implemented, enabling cross validation between different highly accurate methods. The code is specifically optimized for calculations with large numbers of electrons on the latest high performance computing architectures, including multicore central processing unit and graphical processing unit systems. We detail the program's capabilities, outline its structure, and give examples of its use in current research calculations. The package is available at http://qmcpack.org.},
author = {Kim, Jeongnim and Baczewski, Andrew D and Beaudet, Todd D and Benali, Anouar and {Chandler Bennett}, M and Berrill, Mark A and Blunt, Nick S and {Josu{\'{e}} Landinez Borda}, Edgar and Casula, Michele and Ceperley, David M and Chiesa, S and Clark, B and Clay, R and Delaney, K and Dewing, M and Esler, K and Hao, H and Heinonen, O and Kent, P and Krogel, J and Kylanpaa, I and Li, Y and Lopez, M and Luo, Y and Malone, F and Martin, R and Mathuriya, A and McMinis, J and Melton, C and Mitas, L and Morales, M and Neuscamman, E and Parker, W and Flores, Sergio and Romero, Nichols and Rubenstein, B and Shea, J and Shin, H and Schulenburger, L and Tillack, A and Townsend, J and Tubman, N and {Van Der Goetz}, B and Vincent, J and Yang, D and Yang, Y and Zhang, S and Zhao, L},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Kim et al. - 2018 - QMCPACK an open source ab initio quantum Monte Carlo package for the electronic structure of atoms, molecules and so.pdf:pdf},
journal = {Journal of Physics: Condensed Matter},
keywords = {electronic structure,quantum Monte Carlo,quantum chemistry},
number = {19},
title = {{QMCPACK: An Open Source Ab Initio Quantum Monte Carlo Package for the Electronic Structure of Atoms, Molecules and Solids}},
url = {http://iopscience.iop.org/article/10.1088/1361-648X/aab9c3/pdf},
volume = {30},
year = {2018}
}
@phdthesis{Lervag2010,
author = {Lerv{\aa}g, Lars Eivind},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Lerv{\aa}g - 2010 - VMC Calculations of Two-Dimensional Quantum Dots.pdf:pdf},
school = {University of Oslo},
title = {{VMC Calculations of Two-Dimensional Quantum Dots}},
type = {MCs thesis},
url = {https://www.duo.uio.no/bitstream/handle/10852/10993/master.pdf?sequence=1{\&}isAllowed=y},
year = {2010}
}
@phdthesis{Treider2017,
author = {Treider, H{\aa}kon Vik{\o}r},
file = {:Users/Vilde/Downloads/aaa{\_}masteroppgaven.pdf:pdf},
school = {University of Oslo},
title = {{Speeding Up Ab-Initio Molecular Dynamics With Artificial Neural Networks}},
type = {MSc thesis},
year = {2017}
}
@article{Harju2002,
abstract = {We study two-dimensional quantum dots using the variational quantum Monte Carlo technique in the weak-confinement limit where the system approaches the Wigner molecule, i.e., the classical solution of point charges in an external potential. We observe the spin-polarization of electrons followed by a smooth transition to a Wigner-molecule-like state as the confining potential is made weaker.},
author = {Harju, A and Siljam{\"{a}}, S and Nieminen, R M},
doi = {10.1103/PhysRevB.65.075309},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Harju, Siljam{\"{a}}, Nieminen - Unknown - Wigner molecules in quantum dots A quantum Monte Carlo study.pdf:pdf},
journal = {Physical Review B},
title = {{Wigner Molecules in Quantum Dots: A Quantum Monte Carlo Study}},
url = {https://journals.aps.org/prb/pdf/10.1103/PhysRevB.65.075309},
volume = {65},
year = {2002}
}
@unpublished{Shee2018,
abstract = {We present an implementation of phaseless Auxiliary-Field Quantum Monte Carlo (ph-AFQMC) utilizing graphical processing units (GPUs). The AFQMC method is recast in terms of matrix operations which are spread across thousands of processing cores and are executed in batches using custom Compute Unified Device Architecture kernels and the hardware-optimized cuBLAS matrix library. Algorithmic advances include a batched Sherman-Morrison-Woodbury algorithm to quickly update matrix determinants and inverses, density-fitting of the two-electron integrals, an energy algorithm involving a high-dimensional precomputed tensor, and the use of single-precision floating point arithmetic. These strategies result in dramatic reductions in wall-times for both single-and multi-determinant trial wavefunctions. For typical calculations we find speed-ups of roughly two orders of magnitude using just a single GPU card. Furthermore, we achieve near-unity parallel efficiency using 8 GPU cards on a single node, and can reach moderate system sizes via a local memory-slicing approach. We illustrate the robustness of our implementation on hydrogen chains of increasing length, and through the calculation of all-electron ionization potentials of the first-row transition metal atoms. We compare long imaginary-time calculations utilizing a population control algorithm with our previously published correlated sampling approach, and show that the latter improves not only the efficiency but also the accuracy of the computed ionization potentials. Taken together, the GPU implementation combined with correlated sampling provides a compelling computational method that will broaden the application of ph-AFQMC to the description of realistic correlated electronic systems.},
author = {Shee, James and Reichman, David R and Friesner, Richard A and Arthur, Evan J and Zhang, Shiwei},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Shee et al. - Unknown - Phaseless Auxiliary-Field Quantum Monte Carlo on Graphical Processing Units.pdf:pdf},
title = {{Phaseless Auxiliary-Field Quantum Monte Carlo on Graphical Processing Units}},
url = {https://arxiv.org/pdf/1804.03310.pdf},
year = {2018}
}
@article{Kvaal2009,
abstract = {We give a thorough analysis of the convergence properties of the configuration-interaction method as applied to parabolic quantum dots among other systems, including a priori error estimates. The method converges slowly in general, and in order to overcome this, we propose to use an effective two-body interaction well known from nuclear physics. Through numerical experiments we demonstrate a significant increase in accu-racy of the configuration-interaction method.},
annote = {Genius intro to HO potential w/Couloumb interaction as a quantum dot. Also applies the (full) configuration-interaction method.},
author = {Kvaal, Simen},
doi = {10.1103/PhysRevB.80.045321},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Kvaal - Unknown - Harmonic oscillator eigenfunction expansions, quantum dots, and effective interactions.pdf:pdf},
journal = {Physical Review B},
number = {4},
pages = {045321},
title = {{Harmonic Oscillator Eigenfunction Expansions, Quantum Dots, and Effective Interactions}},
url = {https://journals.aps.org/prb/pdf/10.1103/PhysRevB.80.045321},
volume = {80},
year = {2009}
}
@article{LeRoux2011,
abstract = {Computer vision has grown tremendously in the past two decades. De-spite all efforts, existing attempts at matching parts of the human visual system's extraordinary ability to understand visual scenes lack either scope or power. By combining the advantages of general low-level gen-erative models and powerful layer-based and hierarchical models, this work aims at being a first step toward richer, more flexible models of images. After comparing various types of restricted Boltzmann machines (RBMs) able to model continuous-valued data, we introduce our basic model, the masked RBM, which explicitly models occlusion boundaries in image patches by factoring the appearance of any patch region from its shape. We then propose a generative model of larger images using a field of such RBMs. Finally, we discuss how masked RBMs could be stacked to form a deep model able to generate more complicated structures and suitable for various tasks such as segmentation or object recognition.},
annote = {Training GB-RBM known to be hard, this article focused on improving the model in the view of generative models (Melchior2017).

To derive a better understanding of the limitations of the GB-RBM model, the authors in this article evaluated its capabilities from the perspective of image reconstruction.
They analyse the model to show the failures empirically, but there are few works accounting for the failure analytically (Melchior2012).},
author = {{Le Roux}, Nicolas and Heess, Nicolas and Shotton, Jamie and Winn, John},
doi = {10.1162/NECO},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Le Roux et al. - Unknown - Learning a Generative Model of Images by Factoring Appearance and Shape.pdf:pdf},
journal = {Neural Computation},
number = {3},
pages = {593--650},
title = {{Learning a Generative Model of Images by Factoring Appearance and Shape}},
url = {https://www.mitpressjournals.org/doi/pdf/10.1162/NECO{\_}a{\_}00086},
volume = {23},
year = {2011}
}
@incollection{Freund1992,
abstract = {We study a particular type of Boltzmann machine with a bipartite graph structure called a harmo-nium. Our interest is in using such a machine to model a probability distribution on binary input vectors. We analyze the class of probability distributions that can be modeled by such machines. showing that for each n {\~{}} 1 this class includes arbitrarily good appwximations to any distribution on the set of all n-vectors of binary inputs. We then present two learning algorithms for these machines .. The first learning algorithm is the standard gradient ascent heuristic for computing maximum likelihood estimates for the parameters (i.e. weights and thresholds) of the modeL Here we give a closed form for this gradient that is significantly easier to compute than the corresponding gradient for the general Boltzmann machine . The second learning algorithm is a greedy method that creates the hidden units and computes their weights one at a time. This method is a variant of the standard method for projection pursuit density estimation . We give experimental results for these learning methods on synthetic data and natural data from the domain of handwritten digits.},
annote = {The second earliest paper to study the RBM, that I know of, according to the introductory summary in (Welling2005).

Replacing the binary visible units in the RBM with linear units with dependent Gaussian noise was first suggested here. ("Rectified linear units improve restricted boltzmann machines")},
author = {Freund, Yoav and Haussler, David},
booktitle = {Advances in Neural Information Processing Systems 4},
editor = {Moody, J. E. and Hanson, S. J. and Lippmann, R. P.},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Freund{\textperiodcentered}, Haussler - Unknown - Unsupervised learning of distributions on binary vectors using two layer networks.pdf:pdf},
pages = {912--919},
publisher = {Morgan-Kaufmann},
title = {{Unsupervised Learning of Distributions on Binary Vectors Using Two Layer Networks}},
url = {https://papers.nips.cc/paper/535-unsupervised-learning-of-distributions-on-binary-vectors-using-two-layer-networks.pdf},
year = {1992}
}
@book{Gross1991,
annote = {An alternative text book that also discusses bosons.},
author = {Gross, E K U and Runge, E and Heinonen, O},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(3).pdf:pdf},
isbn = {0-7503-0155-4},
publisher = {IOP Publishing Ltd},
title = {{Many-Particle Theory}},
year = {1991}
}
@phdthesis{Mariadason2018,
author = {Mariadason, Alocias},
file = {:Users/Vilde/Downloads/cg-print.pdf:pdf},
pages = {1--10},
school = {University of Oslo},
title = {{Quantum many-Body Simulations of Double Dot System}},
type = {MSc thesis},
year = {2018}
}
@article{Dubois2001,
abstract = {Several properties of trapped hard-sphere bosons are evaluated using variational Monte Carlo techniques. A trial wave function composed of a renormalized single-particle Gaussian and a hard-sphere Jastrow function for pair correlations is used to study the sensitivity of condensate and noncondensate properties to the hard-sphere radius and the number of particles. Special attention is given to diagonalizing the one-body density matrix and obtaining the corresponding single-particle natural orbitals and their occupation numbers for the system. The condensate wave function and condensate fraction are then obtained from the single-particle orbital with the highest occupation. The effect of interaction on other quantities such as the ground-state energy, the mean radial displacement, and the momentum distribution is calculated as well. Results are com-pared with mean-field theory in the dilute limit.},
annote = {Example of successful use of the hard core boson interaction potential (Nilsen2007).},
author = {Dubois, J L and Glyde, H R},
doi = {10.1103/PhysRevA.63.023602},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Dubois, Glyde - Unknown - Bose-Einstein condensation in trapped bosons A variational Monte Carlo analysis.pdf:pdf},
journal = {Physical Review A},
keywords = {0375Fi,PACS number͑s͒},
title = {{Bose-Einstein Condensation in Trapped Bosons: A Variational Monte Carlo Analysis}},
url = {https://journals.aps.org/pra/pdf/10.1103/PhysRevA.63.023602},
volume = {63},
year = {2001}
}
@unpublished{Mehta2018,
abstract = {Machine Learning (ML) is one of the most exciting and dynamic areas of modern research and application. The purpose of this review is to provide an introduction to the core concepts and tools of machine learning in a manner easily understood and intuitive to physicists. The review begins by covering fundamental concepts in ML and modern statistics such as the bias-variance tradeoff, overfitting, regularization, and generalization before moving on to more advanced topics in both supervised and unsupervised learning. Topics covered in the review include ensemble models, deep learning and neural networks, clustering and data visualization, energy-based models (including MaxEnt models and Restricted Boltzmann Machines), and variational methods. Throughout, we emphasize the many natural connections between ML and statistical physics. A notable aspect of the review is the use of Jupyter notebooks to introduce modern ML/statistical packages to readers using physics-inspired datasets (the Ising Model and Monte-Carlo simulations of supersymmetric decays of proton-proton collisions). We conclude with an extended outlook discussing possible uses of machine learning for furthering our understanding of the physical world as well as open problems in ML where physicists maybe able to contribute.},
author = {Mehta, Pankaj and Wang, Ching-Hao and Day, Alexandre G R and Richardson, Clint},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Mehta et al. - 2018 - A High-Bias, Low-Variance Introduction to Machine Learning for Physicists.pdf:pdf},
title = {{A High-Bias, Low-Variance Introduction to Machine Learning for Physicists}},
url = {https://arxiv.org/pdf/1803.08823.pdf},
year = {2018}
}
@phdthesis{Merlot2009,
author = {Merlot, Patrick},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(6).pdf:pdf},
school = {University of Oslo},
title = {{Many-Body Approaches to Quantum Dots}},
type = {MSc thesis},
year = {2009}
}
@unpublished{Saito2018,
abstract = {A machine learning technique to obtain the ground states of quantum few-body systems using artificial neural net-works is developed. Bosons in continuous space are considered and a neural network is optimized in such a way that when particle positions are input into the network, the ground-state wave function is output from the network. The method is applied to the Calogero-Sutherland model in one-dimensional space and Efimov bound states in three-dimensional space.},
archivePrefix = {arXiv},
arxivId = {arXiv:1804.06521v1},
author = {Saito, Hiroki},
eprint = {arXiv:1804.06521v1},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Saito - 2018 - Method to solve quantum few-body problems with artificial neural networks.pdf:pdf},
title = {{Method to Solve Quantum Few-Body Problems with Artificial Neural Networks}},
url = {https://arxiv.org/pdf/1804.06521.pdf},
year = {2018}
}
@article{Hinton2014,
abstract = {It is possible to learn multiple layers of non-linear features by backpropagating error derivatives through a feedforward neural network. This is a very effective learning procedure when there is a huge amount of labeled training data, but for many learning tasks very few labeled examples are available. In an effort to overcome the need for labeled data, several different generative models were developed that learned interesting features by modeling the higher order statistical structure of a set of input vectors. One of these generative models, the restricted Boltzmann machine (RBM), has no connections between its hidden units and this makes perceptual inference and learning much simpler. More significantly, after a layer of hidden features has been learned, the activities of these features can be used as training data for another RBM. By applying this idea recursively, it is possible to learn a deep hierarchy of progressively more complicated features without requiring any labeled data. This deep hierarchy can then be treated as a feedforward neural network which can be discriminatively fine-tuned using backpropagation. Using a stack of RBMs to initialize the weights of a feedforward neural network allows backpropagation to work effectively in much deeper networks and it leads to much better generalization. A stack of RBMs can also be used to initialize a deep Boltzmann machine that has many hidden layers. Combining this initialization method with a new method for fine-tuning the weights finally leads to the first efficient way of training Boltzmann machines with many hidden layers and millions of weights.},
annote = {Et bredt perspektiv som oppsummerer tanker fra 80 tallet og fremover. Tar for seg muligheten for {\aa} kombinere feed forward og deep (R)BMs.},
author = {Hinton, Geoffrey},
doi = {10.1111/cogs.12049},
file = {:Users/Vilde/Downloads/Hinton-2014-Cognitive{\_}Science.pdf:pdf},
isbn = {1551-6709},
issn = {03640213},
journal = {Cognitive Science},
keywords = {Backpropagation,Boltzmann machines,Contrastive divergence,Deep learning,Distributed representations,Learning features,Learning graphical models,Variational learning},
number = {6},
pages = {1078--1101},
pmid = {23800216},
title = {{Where do Features Come From?}},
volume = {38},
year = {2014}
}
@article{Umrigar2005,
abstract = {We present a simple, robust, and efficient method for varying the parameters in a many-body wave function to optimize the expectation value of the energy. The effectiveness of the method is demonstrated by optimizing the parameters in flexible Jastrow factors that include 3-body electron-electron-nucleus correlation terms for the NO 2 and decapentaene (C 10 H 12) molecules. The basic idea is to add terms to the straightforward expression for the Hessian of the energy that have zero expectation value, but that cancel much of the statistical fluctuations for a finite Monte Carlo sample. The method is compared to what is currently the most popular method for optimizing many-body wave functions, namely, minimization of the variance of the local energy. The most efficient wave function is obtained by optimizing a linear combination of the energy and the variance.},
annote = {!!},
author = {Umrigar, C J and Filippi, Claudia},
doi = {10.1103/PhysRevLett.94.150201},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Umrigar, Filippi - Unknown - Energy and Variance Optimization of Many-Body Wave Functions.pdf:pdf},
journal = {Physical Review Letters},
title = {{Energy and Variance Optimization of Many-Body Wave Functions}},
url = {https://journals.aps.org/prl/pdf/10.1103/PhysRevLett.94.150201},
volume = {94},
year = {2005}
}
@article{Weigel2010,
abstract = {Besides the well-known effect of autocorrelations in time series of Monte Carlo simulation data resulting from the underlying Markov process, using the same data pool for computing various estimates entails addi-tional cross correlations. This effect, if not properly taken into account, leads to systematically wrong error estimates for combined quantities. Using a straightforward recipe of data analysis employing the jackknife or similar resampling techniques, such problems can be avoided. In addition, a covariance analysis allows for the formulation of optimal estimators with often significantly reduced variance as compared to more conventional averages.},
author = {Weigel, Martin and Janke, Wolfhard},
doi = {10.1103/PhysRevE.81.066701},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Weigel, Janke - Unknown - Error estimation and reduction with cross correlations.pdf:pdf},
journal = {Physical Review E},
keywords = {0510Ln,0570Fh,6460FϪ,PACS number͑s͒},
number = {6},
title = {{Error Estimation and Reduction with Cross Correlations}},
url = {https://journals.aps.org/pre/pdf/10.1103/PhysRevE.81.066701},
volume = {81},
year = {2010}
}
@phdthesis{Lohne2010,
author = {Lohne, Magnus Pedersen},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Lohne - 2010 - COUPLED-CLUSTER STUDIES OF QUANTUM DOTS.pdf:pdf},
school = {University of Oslo},
title = {{Coupled-Cluster Studies of Quantum Dots}},
type = {MSc thesis},
url = {https://www.duo.uio.no/bitstream/handle/10852/10966/mplohne.pdf?sequence=2},
year = {2010}
}
@article{Bailly2011,
abstract = {In this paper, we address the problem of non-parametric density estimation on a set of strings $\Sigma$ * . We introduce a probabilistic model – called quadratic weighted automaton, or QWA – and we present some methods which can be used in a density estimation task. A spectral analysis method leads to an effective regularization and a consistent estimate of the parameters. We provide a set of theoretical results on the convergence of this method. Experiments show that the combination of this method with likelihood maximization may be an interesting alternative to the well-known Baum-Welch algorithm.},
annote = {The mathematical structure of quantum mechanics appears naturally when one explores more flexible models than Eq. (1) while still attempts to ensure the positivity of the probability density (Cheng2017)

Representing probability density using square of a function was also put forward by [39, 40]. These ap- proach ensures the positivity of probability and naturally ad- mit a quantum mechanical interpretation. (Han2017)},
author = {Bailly, Raphael},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Bailly - 2011 - Quadratic Weighted Automata Spectral Algorithm and Likelihood Maximization.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {grammatical inference,non-parametric density estimation},
pages = {147--162},
title = {{Quadratic Weighted Automata: Spectral Algorithm and Likelihood Maximization}},
url = {http://proceedings.mlr.press/v20/bailly11/bailly11.pdf},
volume = {20},
year = {2011}
}
@article{Taddei2015,
abstract = {We show how a ground-state trial wave function of a Fermi liquid can be systematically improved by introducing a sequence of renormalized coordinates through an iterative backflow transformation. We apply this scheme to calculate the ground-state energy of liquid 3 He in two dimensions at freezing density using variational and fixed-node diffusion Monte Carlo. Compared with exact transient estimate results for systems with a small number of particles, we find that variance extrapolations provide accurate results for the true ground state together with stringent lower bounds. For larger systems these bounds can in turn be used to quantify the systematic bias of fixed-node calculations. These wave functions are size consistent and the scaling of their computational complexity with the number of particles is the same as for standard backflow wave functions.},
annote = {According to (Ruggeri2017) this article introduces "class of wave functions for quantum many-body systems in continuous space that include sets of auxiliary coordinates obtained with iterated backflow transformations. "},
author = {Taddei, Michele and Ruggeri, Michele and Moroni, Saverio and Holzmann, Markus},
doi = {10.1103/PhysRevB.91.115106},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Taddei et al. - 2015 - Iterative backflow renormalization procedure for many-body ground-state wave functions of strongly interacting no.pdf:pdf},
journal = {Physical Review B},
number = {11},
title = {{Iterative Backflow Renormalization Procedure for Many-Body Ground-State Wave Functions of Strongly Interacting Normal Fermi Liquids}},
url = {https://journals.aps.org/prb/pdf/10.1103/PhysRevB.91.115106},
volume = {91},
year = {2015}
}
@article{Flad2007,
abstract = {We present a novel application of best N -term approximation theory in the framework of electronic structure calculations. The paper focusses on the description of electron correlations within a Jastrow-type ansatz for the wavefunction. As a starting point we discuss certain natural assumptions on the asymptotic behaviour of two-particle correlation functions F (2) near electron-electron and electron-nuclear cusps. Based on Nitsche's characterization of best N -term approximation spaces A $\alpha$ q (H 1), we prove that F (2) ∈ A $\alpha$ q (H 1) for q {\textgreater} 1 and $\alpha$ = 1 q − 1 2 with respect to a certain class of anisotropic wavelet tensor product bases. Computational arguments are given in favour of this specific class compared to other possible tensor product bases. Finally, we compare the approximation properties of wavelet bases with standard Gaussian-type basis sets frequently used in quantum chemistry.},
author = {Flad, Heinz-J{\"{u}}rgen and Hackbusch, Wolfgang and Schneider, Reinhold},
doi = {10.1051/m2an:2007016},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Flad, Hackbusch, Schneider - 2007 - ESAIM Mathematical Modelling and Numerical Analysis.pdf:pdf},
journal = {ESAIM: Mathematical Modelling and Numerical Analysis},
number = {2},
pages = {261--279},
title = {{Best N-Term Approximation in Electronic Structure Calculations. II. Jastrow Factors}},
url = {http://www.numdam.org/article/M2AN{\_}2007{\_}{\_}41{\_}2{\_}261{\_}0.pdf},
volume = {41},
year = {2007}
}
@article{Filippi2016,
abstract = {We present a simple and general formalism to compute efficiently the derivatives of a multi-determinant Jastrow-Slater wave function, the local energy, the interatomic forces, and similar quantities needed in quantum Monte Carlo. Through a straightforward manipulation of matrices evaluated on the occupied and virtual orbitals, we obtain an efficiency equivalent to algorithmic differentiation in the computation of the interatomic forces and the optimization of the orbital parameters. Furthermore, for a large multi-determinant expansion, the significant computational gain afforded by a recently introduced table method is here extended to the local value of any one-body operator and to its derivatives, in both all-electron and pseudopotential calculations. Published by AIP Publishing. [http://dx.doi.org/10.1063/1.4948778]},
author = {Filippi, Claudia and Assaraf, Roland and Moroni, Saverio},
doi = {10.1063/1.3516208},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Filippi, Assaraf, Moroni - 2016 - Simple Formalism for Efficient Derivatives and Multi-Determinant Expansions in Quantum Monte Carlo.pdf:pdf},
journal = {The Journal of Chemical Physics},
number = {19},
title = {{Simple Formalism for Efficient Derivatives and Multi-Determinant Expansions in Quantum Monte Carlo}},
url = {https://doi.org/10.1063/1.4948778},
volume = {144},
year = {2016}
}
@article{Taut1994,
abstract = {Two electrons in an external oscillator potential: exact solution versus one-particle approximations M Taut, A Ernst and H Eschrig -Two-dimensional hydrogen in a magnetic field: analytical solutions M Taut -Renormalized perturbation series for quantum dots A Matulis and F M Peeters -Recent citations Inhomogeneity induced and appropriately parameterized semilocal exchange and correlation energy functionals in two-dimensions Abhilash Patra et al -Dissipation Effects in Schr{\"{o}}dinger and Quantal Density Functional Theories of Electrons in an Electromagnetic Field Xiao-Yin Pan and Viraht Sahni -Density–wave-function mapping in degenerate current-density-functional theory Andre Laestadius and Erik I. Tellgren -This content was downloaded from IP address 193.157.136.146 on 08/05/2018 at 18:13 Abstract Particular analyiical solutions of the two-dimensional Schrodinger equation are described for two electrons (interacting with Coulomb potentials) in a homogeneous magnetic field B and an external oscillator potential with frequency q. These exact solutions occur at an infinite and countable set of values of the quantity iu = Jm. Additionally, approximate closed-form solutions for the limits of small 3 (perturbation theory in the electron-electron interaction) and large 5 (harmonic approximation) arc discussed and compared w i t h the exact solutions.},
author = {Taut, M},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - 1994 - Two electrons in a homogeneous magnetic field particular analytical solutions.pdf:pdf},
journal = {Journal of Physics A: Mathematical and General},
number = {3},
pages = {1045--1055},
title = {{Two Electrons in a Homogeneous Magnetic Field: Particular Analytical Solutions}},
url = {http://iopscience.iop.org/article/10.1088/0305-4470/27/3/040/pdf},
volume = {27},
year = {1994}
}
@techreport{Jones2017,
abstract = {Get an overview of the history of artificial intelligence as well as the latest in neural network and deep learning approaches. Learn why, although AI and machine learning have had their ups and downs, new approaches like deep learning and cognitive computing have significantly raised the bar in these disciplines. For millennia, humans have pondered the idea of building intelligent machines. Ever since, artificial intelligence (AI) has had highs and lows, demonstrated successes and unfulfilled potential. Today, the news is filled with the application of machine learning algorithms to new problems. From cancer detection and prediction to image understanding and summarization and natural language processing, AI is empowering people and changing our world. The history of modern AI has all the elements of a great drama. Beginning in the 1950s with a focus on thinking machines and interesting characters like Alan Turing and John von Neumann, AI began its first rise. Decades of booms and busts and impossibly high expectations followed, but AI and its pioneers pushed forward. AI is now exposing its true potential, focusing on applications and delivering technologies like deep learning and cognitive computing. This article explores some of the important aspects of AI and its subfields. Let's begin with a timeline of AI, and then dig into each of these elements.},
author = {Jones, M Tim},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Jones - 2017 - A beginner's guide to artificial intelligence, machine learning, and cognitive computing.pdf:pdf},
institution = {IBM developerWorks},
title = {{A Beginner's Guide to Artificial Intelligence, Machine Learning, and Cognitive Computing}},
url = {https://www.ibm.com/developerworks/library/cc-beginner-guide-machine-learning-ai-cognitive/cc-beginner-guide-machine-learning-ai-cognitive-pdf.pdf},
year = {2017}
}
@article{Vitiello1988,
abstract = {A new class of trial wave functions is introduced to compute variationally the ground-state energy of solid He. This wave function is symmetric under particle exchange, translationally invariant, and does not require the a priori introduction of a crystal lattice. It gives a lower energy than and has properties comparable with those given by previous calculations in which atoms are explicitly localized. The same functional form of the wave function is used to investigate the liquid phase, where a lower energy than those given by a wave function of the Jastrow form is obtained as well. PACS numbers: 67.80. — s, 02.50,+s, 67.40.Db Monte Carlo variational computations for quantum many-body systems were first carried out by McMillan. ' In this work a trial wave function of the well-known Jas-trow form gave reasonable results for liquid He. For solid He, the same wave function gave too high an ener-gy. The parametrization strength of the Jastrow func-tion which produces long-range order gives rise to a crys-tal that is too tightly localized to be a good description of a quantum solid. Good variational energies were obtained with Monte Carlo computations by Hansen and Levesque, using one-body Gaussian factors coupling atoms to lattice sites as previously suggested by Nosanow. 3 This destroys both the translational invariance and the symmetry of the trial wave function that are inherent in the system. We have recently observed that these properties can be restored while retaining a good quantitative description of the crystal. Early attempts to do this were made with use of a self-consistent theory. However, the energies obtained were higher than those determined by Hansen and Levesque. Our new trial wave function 0T(R), R= jri, r2, . . . , rive, can be conveniently written by the introduction of an artificial or "shadow" set of variables S — = fsi, s2, . . . , stvI through :-is given by :-(R,S) =exp[ — —, ' g; (J u(r j) — gk p(rk — sk) gt (yg U— ({\$}/yg)], (2) where r;t = {\~{}} r; — rt {\~{}} is the distance between particles i and j and si = (si — s (. In Eq. (2) the first sum in the exponential is the usual two-body correlation function of the Jastrow form. The last term is a function of the aux-iliary variables sj, for which model potential of the form s " has been taken. In this work p was chosen to be C(rk — sk), where C is a variational parameter. The function eT(R) is both translationally invariant and symmetric under particle interchange. There were several complementary rationales for ex-perimentation with a wave function having this struc-ture. The first is very simply that classical systems ex-hibit long-range order at low enough temperatures. To use this directly in the Jastrow factor violates the re-quirement that the latter solve the Schrodinger equation at small pair separation. In Eq. (I), the shadow parti-cles are the analog of the classical system and can be given a low effective "temperature, " while the pair corre-lations among the "real" particles R can approximate a solution of the Schrodinger equation. The long-range crystalline order of the shadow particles is imposed on the real by the one-to-one coupling of Eq. (2). A different justification arises from the path-integral picture of a quantum solid. Consider the "center of mass" r;(c.m.) of all the positions of particle i on a e (R) =E " {\~{}}G(R,S)@(S)dS. (3) Consider the approximation of o(S) on the right-hand side by a simple Jastrow function +J(S) = +fp(s; — s1). (4) ! Feynman path in imaginary time. If one averages over fluctuations about the centers of mass, then the repulsive core diameter of the resulting "interaction" between the coordinates r;(c.m.) should be larger than that in the bare pair potential V(r). Thus the correlations among the r;(c.m.) will have more structure than for the actual coordinates r;. Therefore the r;(c.m.) should resemble a classical system more than a quantum one. We are presently attempting to incorporate these ideas into an approximate theory of quantum solids and fluids. In this paper the centers of mass are modeled by shadow parti-cles. The fluctuation of the real particle with respect to the center of mass, or shadow, can be introduced, at least crudely, by a harmonic interaction. A more formal motivation comes from the ideas of a Green's-function Monte Carlo method, s where the in-tegral equation form of the Schrodinger equation is used: 1970 1988 The American Physical Society VOLUME 60, NUMBER 19 PHYSICAL REVIEW LETTERS 9 MA+ 1988 Suppose that G(R,S) is given by the Boltzmann Green's function for free particles at some effective temperature, Go(R, S){\~{}}exp[ — Cgq (rq — sk) ], "dressed" by Jastrow factors in R and S to model the correlations in G(R, S) while keeping it symmetric in R and S and so as to satisfy approximately " H(R)G(R,S)dS = I, (6) where H is the Hamiltonian. With these approximations one is led directly to Eqs. (I) and (2) as a generalization of the Jastrow form. fO ET = dR+THer (7) or in terms of:-, as In the shadow wave function, the correlations among the real particles are enhanced to all orders as compared with a pure Jastrow form for the fluid. One can hope to achieve correlations as strong in the crystal as the Nosanow-Jastrow form while retaining Bose symmetry and translational invariance. In fact, our results show that this is true. The variational energy is given by fff dR dS) dS2=(R, S)):-(R,S2)H:-(R,S2)/:-(R, Sp) fff dRdS)dS2=(R, S)):-(R,S2)},
annote = {!! The introduction of shadow variables},
author = {Vitiello, Silvio and Runge, Karl and Kalos, M H},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Vitiello, Runge, Kalos - Unknown - Variational Calculations for Solid and Liquid He with a {\&}quotShadow{\&}quot Wave Function.pdf:pdf},
journal = {Physical Review Letters},
number = {19},
title = {{Variational Calculations for Solid and Liquid He with a "Shadow" Wave Function}},
url = {https://journals.aps.org/prl/pdf/10.1103/PhysRevLett.60.1970},
volume = {60},
year = {1988}
}
@article{Alexander1997,
author = {Alexander, S. A. and Coldwell, R. L.},
doi = {10.1002/(SICI)1097-461X(1997)63:5<1001::AID-QUA9>3.0.CO;2-1},
file = {:Users/Vilde/Downloads/Alexander{\_}et{\_}al-1997-International{\_}Journal{\_}of{\_}Quantum{\_}Chemistry.pdf:pdf},
isbn = {1097461X},
issn = {00207608},
journal = {International Journal of Quantum Chemistry},
number = {5},
pages = {1001--1022},
title = {{Atomic Wave Function Forms}},
volume = {63},
year = {1997}
}
@article{Anderson1995,
abstract = {A Bose-Einstein condensate was produced in a vapor of rubidium-87 atoms that was confined by magnetic fields and evaporatively cooled. The condensate fraction first appeared near a temperature of 170 nanokelvin and a number density of 2.5 x 1012 per cubic centimeter and could be preserved for more than 15 seconds. Three primary signatures of Bose-Einstein condensation were seen. (i) On top of a broad thermal velocity distribution, a narrow peak appeared that was centered at zero velocity. (ii) The fraction of the atoms that were in this low-velocity peak increased abruptly as the sample tem-perature was lowered. (iii) The peak exhibited a nonthermal, anisotropic velocity distri-bution expected of the minimum-energy quantum state of the magnetic trap in contrast to the isotropic, thermal velocity distribution observed in the broad uncondensed fraction. On the microscopic quantum level, there are profound differences between fermions (particles with half integer spin) and bosons (particles with integer spin). Every statisti-cal mechanics text discusses how these dif-ferences should affect the behavior of atom-ic gas samples. Thus, it is ironic that the quantum statistics of atoms has never made any observable difference to the collective macroscopic properties of real gas samples. Certainly the most striking difference is the prediction, originally by Einstein, that a gas of noninteracting bosonic atoms will, below a certain temperature, suddenly develop a macroscopic population in the lowest ener-gy quantum mechanical state (1, 2). How-ever, this phenomenon of Bose-Einstein condensation (BEC) requires a sample so cold that the thermal deBroglie wave-length, Xdb, becomes larger than the mean spacing between particles (3). More precise-ly, the dimensionless phase-space density, pps = n(Xdb)3, must be greater than 2.612 (2, 4), where n is the number density. Ful-filling this stringent requirement has eluded physicists for decades. Certain well-known physical systems do display characteristics of quantum degeneracy, in particular super-fluidity in helium and superconductivity in metals. These systems exhibit counterintui-tive behavior associated with macroscopic quantum states and have been the subject of extensive study. However, in these sys-tems the bosons are so closely packed that they can be understood only as strongly interacting systems. These strong},
annote = {Experiment where they cooled down 4 × 106 87Rb to temperatures in the order of 100 nK to observe Bose–Einstein condensation in the dilute gas. (Nilsen2007) attempt to model this in his paper.},
author = {Anderson, M H and Ensher, J R and Matthews, M R and Wieman, C E and Cornell, E A},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Anderson et al. - Unknown - Observation of Bose-Einstein Condensation in a Dilute Atomic Vapor.pdf:pdf},
journal = {Science},
number = {5221},
title = {{Observation of Bose-Einstein Condensation in a Dilute Atomic Vapor}},
url = {http://science.sciencemag.org/content/sci/269/5221/198.full.pdf},
volume = {269},
year = {1995}
}
@article{Kvaal2007,
abstract = {The widely used large-scale diagonalization method using harmonic oscillator basis functions ͑an instance of the Rayleigh-Ritz method ͓S. Gould, Variational Methods for Eigenvalue Problems: An Introduction to the Methods of Rayleigh, Ritz, Weinstein, and Aronszajn ͑Dover, New York, 1995͔͒, also called a spectral method, configuration-interaction method, or " exact diagonalization " method͒ is systematically analyzed using results for the convergence of Hermite function series. We apply this theory to a Hamiltonian for a one-dimensional model of a quantum dot. The method is shown to converge slowly, and the nonsmooth character of the interaction potential is identified as the main problem with the chosen basis, while, on the other hand, its important advantages are pointed out. An effective interaction obtained by a similarity transformation is proposed for improving the convergence of the diagonalization scheme, and numerical experiments are per-formed to demonstrate the improvement. Generalizations to more particles and dimensions are discussed.},
author = {Kvaal, Simen and Hjorth-Jensen, Morten and Nilsen, Halvor M{\o}ll},
doi = {10.1103/PhysRevB.76.085421},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Kvaal, Hjorth-Jensen, Nilsen - Unknown - Effective interactions, large-scale diagonalization, and one-dimensional quantum dots.pdf:pdf},
journal = {Physical Review B},
number = {8},
pages = {085421},
title = {{Effective Interactions, Large-Scale Diagonalization, and One-Dimensional Quantum Dots}},
url = {https://journals.aps.org/prb/pdf/10.1103/PhysRevB.76.085421},
volume = {76},
year = {2007}
}
@article{Calcavecchia2016,
abstract = {We use the shadow wave function formalism as a convenient model to study the fermion sign problem affecting all projector quantum Monte Carlo methods in continuum space. We demonstrate that the efficiency of imaginary-time projection algorithms decays exponentially with increasing number of particles and/or imaginary-time propagation. Moreover, we derive an analytical expression that connects the localization of the system with the magnitude of the sign problem, illustrating this behavior through numerical results. Finally, we discuss the computational complexity of the fermion sign problem and methods for alleviating its severity.},
annote = {Good discussion in beginning on NP++ problems regarding QMC, refers 4 articles on recent developments of construction AND optimization of trial wf's. 

Also: shadow wave function. Introducing a sum/integral over auxiliary variables. Must.Ceck.Out.},
author = {Calcavecchia, Francesco and Holzmann, Markus},
doi = {10.1103/PhysRevE.93.043321},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Calcavecchia, Holzmann - 2016 - Fermion sign problem in imaginary-time projection continuum quantum Monte Carlo with local interaction.pdf:pdf},
journal = {Physical Review E},
number = {4},
title = {{Fermion Sign Problem in Imaginary-Time Projection Continuum Quantum Monte Carlo with Local Interaction}},
url = {https://journals.aps.org/pre/pdf/10.1103/PhysRevE.93.043321},
volume = {93},
year = {2016}
}
@inproceedings{Neiswanger2014,
abstract = {Communication costs, resulting from synchro-nization requirements during learning, can greatly slow down many parallel machine learning algorithms. In this paper, we present a parallel Markov chain Monte Carlo (MCMC) algorithm in which subsets of data are pro-cessed independently, with very little com-munication. First, we arbitrarily partition data onto multiple machines. Then, on each machine, any classical MCMC method (e.g., Gibbs sampling) may be used to draw samples from a posterior distribution given the data subset. Finally, the samples from each ma-chine are combined to form samples from the full posterior. This embarrassingly parallel algorithm allows each machine to act inde-pendently on a subset of the data (without communication) until the final combination stage. We prove that our algorithm generates asymptotically exact samples and empirically demonstrate its ability to parallelize burn-in and sampling in several models.},
author = {Neiswanger, Willie and Wang, Chong and Xing, Eric P},
booktitle = {Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Neiswanger, Wang, Xing - Unknown - Asymptotically Exact, Embarrassingly Parallel MCMC.pdf:pdf},
pages = {623--632},
publisher = {AUAI Press},
title = {{Asymptotically Exact, Embarrassingly Parallel MCMC}},
url = {http://www.cs.cmu.edu/{~}epxing/papers/2014/Neiswanger{\_}Wang{\_}Xing{\_}UAI14a.pdf},
year = {2014}
}
@incollection{Smolensky1986,
annote = {The first introduction of the restricted Boltzmann machine, under the name "harmonium". (Welling2005).},
author = {Smolensky, Paul},
booktitle = {Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Volume 1: Foundations},
chapter = {6},
editor = {Rumelhart, David E. and McClelland, James L.},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(2).pdf:pdf},
isbn = {0-262-68053-X},
pages = {194--281},
publisher = {MIT Press},
title = {{Information Processing in Dynamical Systems: Foundations of Harmony Theory}},
year = {1986}
}
@article{Dandrea2009,
abstract = {We present a novel technique well suited for studying the ground state of inhomogeneous fermionic matter in a wide range of different systems. The system is described using a fermionic shadow wave function, and the energy is computed by means of the variational Monte Carlo technique. The general form of the fermionic shadow wave function is useful for describing many-body systems with the coexistence of different phases as well in the presence of defects or impurities, but it requires overcoming a significant sign problem. As an application, we studied the energy to activate vacancies in solid 3 He.},
author = {Dandrea, L and Pederiva, F and Gandolfi, S and Kalos, M H},
doi = {10.1103/PhysRevLett.102.255302},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Dandrea et al. - Unknown - Fermionic Shadow Wave Function Variational Calculations of the Vacancy Formation Energy in 3 He.pdf:pdf},
journal = {Physical Review Letters},
keywords = {6780D{\`{A}},PACS numbers},
number = {25},
title = {{Fermionic Shadow Wave Function Variational Calculations of the Vacancy Formation Energy in 3He}},
url = {https://journals.aps.org/prl/pdf/10.1103/PhysRevLett.102.255302},
volume = {102},
year = {2009}
}
@article{Harju2005,
abstract = {We use a variational Monte Carlo algorithm to solve the electronic struc-ture of two-dimensional semiconductor quantum dots in external magnetic field. We present accurate many-body wave functions for the system in var-ious magnetic field regimes. We show the importance of symmetry, and demonstrate how it can be used to simplify the variational wave functions. We present in detail the algorithm for efficient wave function optimization. We also present a Monte Carlo -based diagonalization technique to solve the quantum dot problem in the strong magnetic field limit where the system is of a multiconfiguration nature.},
annote = {Using QMC for studies of so-called quantum dots (fermionic systems), electrons confined between layers in semi-conductors. (Nilsen2007).},
author = {Harju, Ari},
doi = {10.1007/s10909-005-6308-7},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Harju - Unknown - Variational Monte Carlo for Interacting Electrons in Quantum Dots.pdf:pdf},
journal = {Journal of Low Temperature Physics},
keywords = {0270Ss,7110-w,7321La,PACS numbers},
title = {{Variational Monte Carlo for Interacting Electrons in Quantum Dots}},
url = {https://link.springer.com/content/pdf/10.1007{\%}2Fs10909-005-6308-7.pdf},
volume = {140},
year = {2005}
}
@inproceedings{Esler2008,
abstract = {Over the past two decades, continuum quantum Monte Carlo (QMC) has proved to be an invaluable tool for predicting of the properties of matter from fundamental principles. By solving the Schr{\"{o}}dinger equation through a stochastic projection, it achieves the greatest accuracy and reliability of methods available for physical systems containing more than a few quantum particles. QMC enjoys scaling favorable to quantum chemical methods, with a computational effort which grows with the second or third power of system size. This accuracy and scalability has enabled scientific discovery across a broad spectrum of disciplines. The current methods perform very efficiently at the terascale. The quantum Monte Carlo Endstation project is a collaborative effort among researchers in the field to develop a new generation of algorithms, and their efficient implementations, which will take advantage of the upcoming petaflop architectures. Some aspects of these developments are discussed here. These tools will expand the accuracy, efficiency and range of QMC applicability and enable us to tackle challenges which are currently out of reach. The methods will be applied to several important problems including electronic and structural properties of water, transition metal oxides, nanosystems and ultracold atoms.},
author = {Esler, Kenneth P and Kim, Jeongnim and Ceperley, David M and Purwanto, Wirawan and Walter, Eric J and Krakauer, Henry and Zhang, Shiwei and Kent, Paul R C and Hennig, Richard G and Umrigar, Cyrus and Bajdich, Michal and Koloren{\v{c}}, Jindřich and Mitas, Lubos and Srinivasan, Ashok},
booktitle = {Journal of Physics: Conference Series},
doi = {10.1088/1742-6596/125/1/012057},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Esler et al. - 2008 - Quantum Monte Carlo algorithms for electronic structure at the petascale the endstation project.pdf:pdf},
publisher = {IOP Publishing},
title = {{Quantum Monte Carlo Algorithms for Electronic Structure at the Petascale; the Endstation Project}},
url = {https://pdfs.semanticscholar.org/b99e/9a5e6ce2d43d14a0a8da048d06fe467a8d77.pdf},
volume = {125},
year = {2008}
}
@article{Bressanini2005,
abstract = {The factors influencing the quality of the nodal surfaces, namely, the atomic basis set, the single-particle orbitals, and the configurations included in the wave-function expansion, are examined for a few atomic and molecular systems. The following empirical rules are found: the atomic basis set must be fairly large, complete active space and natural orbitals are usually better than Hartree-Fock orbitals, multiconfiguration expansions perform better than single-determinant wave functions, but only few configurations are effective and their choice is suggested by symmetry considerations, while too long determinantal expansions spoil the nodal surfaces. These rules allow us to reduce the nodal error and to compute the best fixed node-diffusion Monte Carlo energies for a series of dimers of first-row atoms.},
author = {Bressanini, Dario and Morosi, Gabriele and Tarasco, Silvia},
doi = {10.1063/1.2128672͔},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Bressanini, Morosi, Tarasco - 2041 - An investigation of nodal structures and the construction of trial wave functions.pdf:pdf},
journal = {The Journal of Chemical Physics},
title = {{An Investigation of Nodal Structures and the Construction of Trial Wave Functions}},
url = {https://doi.org/10.1063/1.2128672 http://aip.scitation.org/toc/jcp/123/20},
volume = {123},
year = {2005}
}
@book{Murphy2012,
abstract = {Some of the most remarkable issues related to interharmonics observed from a probabilistic perspective are presented. Attention is firstly devoted to interharmonic frequency and amplitude variability. Starting from the basic mathematical and computational aspects of probabilistic harmonic models, the difficulties to include interharmonics are discussed with particular attention to the problem of the frequency resolution and of the computational burden. Then, simulation and measurement aspects are discussed, also showing some numerical and experimental results.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Murphy, Kevin P.},
doi = {10.1007/SpringerReference_35834},
eprint = {0-387-31073-8},
file = {:Users/Vilde/Downloads/MachineLearningMurphy.pdf:pdf},
isbn = {9780262018029},
issn = {0262018020},
pmid = {20236947},
publisher = {The MIT Press},
title = {{Machine Learning: A Probabilistic Perspective}},
url = {http://link.springer.com/chapter/10.1007/978-94-011-3532-0{\_}2},
year = {2012}
}
@phdthesis{Jonsson2018,
author = {Jonsson, Marius},
file = {:Users/Vilde/Downloads/Fresher Guide Part 2.pdf:pdf},
school = {University of Oslo},
title = {{Standard error estimation by an automated blocking method}},
type = {MSc thesis},
year = {2018}
}
@phdthesis{Sciences2013,
author = {H{\o}gberget, J{\o}rgen},
file = {:Users/Vilde/Downloads/jorgenh{\_}thesis-8.pdf:pdf},
number = {June},
school = {University of Oslo},
title = {{Quantum Monte-Carlo Studies of Generalized Many-body Systems}},
type = {MSc thesis},
url = {https://www.duo.uio.no/handle/10852/37167},
year = {2013}
}
@article{Brooks2009,
abstract = {CHARMM (Chemistry at HARvard Molecular Mechanics) is a highly versatile and widely used molecu- lar simulation program. It has been developed over the last three decades with a primary focus on molecules of bio- logical interest, including proteins, peptides, lipids, nucleic acids, carbohydrates, and small molecule ligands, as they occur in solution, crystals, and membrane environments. For the study of such systems, the program provides a large suite of computational tools that include numerous conformational and path sampling methods, free energy estima- tors, molecular minimization, dynamics, and analysis techniques, and model-building capabilities. The CHARMM program is applicable to problems involving a much broader class of many-particle systems. Calculations with CHARMM can be performed using a number of different energy functions and models, from mixed quantum mechanical-molecular mechanical force fields, to all-atom classical potential energy functions with explicit solvent and various boundary conditions, to implicit solvent and membrane models. The program has been ported to numer- ous platforms in both serial and parallel architectures. This article provides an overview of the program as it exists today with an emphasis on developments since the publication of the original CHARMM article in 1983.},
annote = {Discusses parallelization},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Fisher, Daniel R and Kent, David R and Feldmann, Michael T and Goddard, William A},
doi = {10.1002/jcc},
eprint = {NIHMS150003},
file = {:Users/Vilde/Downloads/Fisher{\_}et{\_}al-2008-Journal{\_}of{\_}Computational{\_}Chemistry.pdf:pdf},
isbn = {1096-987X},
issn = {1096-987X},
journal = {Journal of computational chemistry},
keywords = {parallel computing,parallel efficiency,quantum monte carlo,walker initialization},
pages = {2335--2343},
pmid = {20928852},
title = {{An Optimized Initialization Algorithm to Ensure Accuracy in Quantum Monte Carlo Calculations}},
volume = {29},
year = {2008}
}
@article{Luo2015,
annote = {Good review of optimization},
author = {Luo, Ye and Sorella, Sandro},
doi = {10.3389/fmats.2015.00029},
file = {:Users/Vilde/Downloads/fmats-02-00029.pdf:pdf},
issn = {2296-8016},
journal = {Frontiers in Materials},
keywords = {ab initio calculations,electronic structure,high performance computing,is one,many-body calcula-,many-body physics,methods for ab initio,molecular dynamics,of the most accurate,qmc,quantum Monte Carlo,quantum monte carlo},
pages = {29},
title = {{Ab Initio Molecular Dynamics with Quantum Monte Carlo}},
url = {http://journal.frontiersin.org/article/10.3389/fmats.2015.00029/abstract},
volume = {2},
year = {2015}
}
@inproceedings{Ranzato2010a,
abstract = {Learning a generative model of natural images is a use-ful way of extracting features that capture interesting regu-larities. Previous work on learning such models has focused on methods in which the latent features are used to deter-mine the mean and variance of each pixel independently, or on methods in which the hidden units determine the covari-ance matrix of a zero-mean Gaussian distribution. In this work, we propose a probabilistic model that combines these two approaches into a single framework. We represent each image using one set of binary latent features that model the image-specific covariance and a separate set that model the mean. We show that this approach provides a probabilis-tic framework for the widely used simple-cell complex-cell architecture, it produces very realistic samples of natural images and it extracts features that yield state-of-the-art recognition accuracy on the challenging CIFAR 10 dataset.},
annote = {Training GB-RBM known to be hard, this article focused on improving the model in the view of generative models (Melchior2017).

Modified the GB-RBM such that it is capable of modelling higher order statistics directly.
(Melchior2012).

While an MRF is a particular case of a PoE, a BM is an MRF with a particular energy function that leads to a complete undirected graph. This implies a fully connected network where the pairwise communication between two units is symmetrical.
Can make even complexer BMs where more than two units interact, named higher order BMs (Melchior2012).},
author = {Ranzato, Marc Aurelio and Hinton, Geoffrey E},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2010.5539962},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Ranzato, Hinton - Unknown - Modeling Pixel Means and Covariances Using Factorized Third-Order Boltzmann Machines(2).pdf:pdf},
pages = {2551--2558},
publisher = {IEEE},
title = {{Modeling Pixel Means and Covariances Using Factorized Third-Order Boltzmann Machines}},
url = {http://www.cs.utoronto.ca/{~}hinton/absps/ranzato{\_}cvpr2010.pdf},
year = {2010}
}
@article{Toulouse2016,
abstract = {We provide a pedagogical introduction to the two main variants of real-space quantum Monte Carlo methods for electronic structure calculations: variational Monte Carlo (VMC) and diffusion Monte Carlo (DMC). Assuming no prior knowledge on the subject, we review in depth the Metropolis–Hastings algorithm used in VMC for sampling the square of an approximate wave function, discussing details important for applications to electronic systems. We also review in detail the more sophisticated DMC algorithm within the fixed-node approximation, introduced to avoid the infamous Fermionic sign problem, which allows one to sample a more accurate approximation to the ground-state wave function. Throughout this review, we discuss the statistical methods used for evaluating expectation values and statistical uncertainties. In particular, we show how to estimate nonlinear functions of expectation values and their statistical uncertainties.},
author = {Toulouse, Julien and Assaraf, Roland and Umrigar, Cyrus J.},
doi = {10.1016/BS.AIQ.2015.07.003},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Toulouse, Assaraf, Umrigar - 2016 - Introduction to the Variational and Diffusion Monte Carlo Methods.pdf:pdf},
isbn = {9780128030608},
issn = {0065-3276},
journal = {Advances in Quantum Chemistry},
month = {jan},
pages = {285--314},
publisher = {Academic Press},
title = {{Introduction to the Variational and Diffusion Monte Carlo Methods}},
url = {https://www.sciencedirect.com/science/article/pii/S0065327615000386},
volume = {73},
year = {2016}
}
@article{Bergstra2012,
abstract = {Grid search and manual search are the most widely used strategies for hyper-parameter optimiza-tion. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a compar-ison with a large previous study that used grid search and manual search to configure neural net-works and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising con-figuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent " High Throughput " methods achieve surprising success—they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural base-line against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.},
author = {Bergstra, James and Bengio, Yoshua},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Bergstra JAMESBERGSTRA, Yoshua Bengio YOSHUABENGIO - 2012 - Random Search for Hyper-Parameter Optimization.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {deep learning,global optimization,model selection,neural networks,response surface modeling},
pages = {281--305},
title = {{Random Search for Hyper-Parameter Optimization}},
url = {http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf},
volume = {13},
year = {2012}
}
@article{Hinton2006,
abstract = {High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such "autoencoder" networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.},
annote = {BMs are popular in the field of dimensionality reduction. (Melchior2012)

The GB-RBM. (Melchior2012)

To deal with real-valued data such as the pixel intensities in natural images, they replaced the binary visible units by linear units with dependent Gaussian noise (Nair2010)},
author = {Hinton, G. E. and Salakhutdinov, R. R.},
doi = {10.1126/science.1127647},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Hinton, Salakhutdinov - 2006 - Reducing the dimensionality of data with neural networks.pdf:pdf},
issn = {1095-9203},
journal = {Science},
number = {5786},
pages = {504--507},
pmid = {16873662},
publisher = {American Association for the Advancement of Science},
title = {{Reducing the Dimensionality of Data with Neural Networks}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16873662},
volume = {313},
year = {2006}
}
@book{Gardiner2004,
annote = {For Fokker Planck (og Langevin, men ikke s{\aa} mye?)},
author = {Gardiner, C W},
edition = {3rd},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Gardiner - Unknown - Handbook of Stochastic Methods for Physics, Chemistry and the Natural Sciences.pdf:pdf},
isbn = {978-3540208822},
publisher = {Springer},
title = {{Handbook of Stochastic Methods for Physics, Chemistry and the Natural Sciences}},
url = {http://library.mpib-berlin.mpg.de/toc/ze{\_}2006{\_}653.pdf},
year = {2004}
}
@article{Nightingale1998,
abstract = {In this review we discuss, from a unified point of view, a variety of Monte Carlo methods used to solve eigenvalue problems in statistical mechanics and quantum mechanics. Although the applications of these methods differ widely, the underlying mathematics is quite similar in that they are stochastic imple-mentations of the power method. In all cases, optimized trial states can be used to reduce the errors of Monte Carlo estimates.},
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/9804288v2},
author = {Nightingale, M P and Umrigar, C J},
eprint = {9804288v2},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Nightingale, Umrigar - 1998 - Monte Carlo Eigenvalue Methods in Quantum Mechanics and Statistical Mechanics.pdf:pdf},
journal = {Advances in Chemical Physics},
number = {4},
primaryClass = {arXiv:cond-mat},
publisher = {John Wiley {\&} Sons},
title = {{Monte Carlo Eigenvalue Methods in Quantum Mechanics and Statistical Mechanics}},
url = {https://arxiv.org/pdf/cond-mat/9804288.pdf},
volume = {105},
year = {1998}
}
@phdthesis{Kvaal2008,
author = {Kvaal, Simen},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Kvaal - 2008 - Analysis of many-body methods for quantum dots.pdf:pdf},
school = {University of Oslo},
title = {{Analysis of many-body methods for quantum dots}},
type = {PhD thesis},
url = {http://folk.uio.no/simenkva/simenkvaal{\_}thesis{\_}final.pdf},
year = {2008}
}
@book{Lippman2013,
author = {Lippman, Stanley B and Lajoie, Jos{\'{e}}e and Moo, Barbara E},
edition = {5th},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(5).pdf:pdf},
isbn = {978-0-321-71411-4},
publisher = {Objectwrite Inc},
title = {{C++ Primer}},
year = {2013}
}
@article{LeRoux2008,
abstract = {Deep Belief Networks (DBN) are generative neural network models with many layers of hidden explanatory factors, recently introduced by Hinton et al., along with a greedy layer-wise unsupervised learning algorithm. The building block of a DBN is a probabilistic model called a Restricted Boltzmann Machine (RBM), used to represent one layer of the model. Restricted Boltzmann Machines are interesting because inference is easy in them, and because they have been successfully used as building blocks for training deeper models. We first prove that adding hidden units yields strictly improved modelling power, while a second theorem shows that RBMs are universal approximators of discrete distributions. We then study the question of whether DBNs with more layers are strictly more powerful in terms of representational power. This suggests a new and less greedy criterion for training RBMs within DBNs.},
annote = {Analysis of the marginal, chapter 4. igure 15 also implies that RBMs can be universal approximators. (Melchior2012)},
author = {{Le Roux}, Nicolas and Bengio, Yoshua},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Le Roux, Bengio - Unknown - Representational Power of Restricted Boltzmann Machines and Deep Belief Networks.pdf:pdf},
journal = {Neural Computation},
number = {6},
pages = {1631--1649},
title = {{Representational Power of Restricted Boltzmann Machines and Deep Belief Networks}},
url = {http://www.iro.umontreal.ca/∼lisa},
volume = {20},
year = {2008}
}
@article{Luchow2015,
abstract = {Jastrow correlation factors play an important role in quantum Monte Carlo calculations. Together with an orbital based antisymmetric function, they allow the construction of highly accurate correlation wave functions. In this paper, a generic expansion of the Jastrow correlation function in terms of polynomials that satisfy both the electron exchange symmetry constraint and the cusp conditions is presented. In particular, an expansion of the three-body electron-electron-nucleus contribution in terms of cuspless homogeneous symmetric polynomials is proposed. The polynomials can be ex-pressed in fairly arbitrary scaling function allowing a generic implementation of the Jastrow factor. It is demonstrated with a few examples that the new Jastrow factor achieves 85{\%}–90{\%} of the total corre-lation energy in a variational quantum Monte Carlo calculation and more than 90{\%} of the diffusion Monte Carlo correlation energy. C 2015 AIP Publishing LLC. [http://dx.doi.org/10.1063/1.4909554]},
author = {L{\"{u}}chow, Arne and Sturm, Alexander and Schulte, Christoph and Mood, Kaveh Haghighi},
doi = {10.1063/1.4909554},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/L{\"{u}}chow et al. - 2015 - Generic Expansion of the Jastrow Correlation Factor in Polynomials Satisfying Symmetry and Cusp Conditions.pdf:pdf},
journal = {The Journal of Chemical Physics},
pages = {84111--1007},
title = {{Generic Expansion of the Jastrow Correlation Factor in Polynomials Satisfying Symmetry and Cusp Conditions}},
url = {https://doi.org/10.1063/1.4909554},
volume = {142},
year = {2015}
}
@phdthesis{Olsen2012,
author = {Olsen, Veronica K Berglyd},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Olsen - 2012 - Full Configuration Interaction Simulation of Quantum Dots.pdf:pdf},
school = {University of Oslo},
title = {{Full Configuration Interaction Simulation of Quantum Dots}},
type = {MSc thesis},
url = {https://www.duo.uio.no/bitstream/handle/10852/34217/vkb-olsen.pdf?sequence=3{\&}isAllowed=y},
year = {2012}
}
@inproceedings{Nair2010,
abstract = {Restricted Boltzmann machines were devel-oped using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have pro-gressively more negative biases. The learning and inference rules for these " Stepped Sig-moid Units " are unchanged. They can be ap-proximated efficiently by noisy, rectified lin-ear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset. Unlike binary units, rectified linear units preserve information about relative in-tensities as information travels through mul-tiple layers of feature detectors.},
author = {Nair, Vinod and Hinton, Geoffrey E},
booktitle = {Proceedings of the 27th international conference on machine learning (ICML-10)},
editor = {F{\"{u}}rnkranz, Johannes and Joachims, Thorsten},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Nair, Hinton - Unknown - Rectified Linear Units Improve Restricted Boltzmann Machines(3).pdf:pdf},
pages = {807--814},
publisher = {Omnipress},
title = {{Rectified Linear Units Improve Restricted Boltzmann Machines}},
url = {https://www.cs.toronto.edu/{~}hinton/absps/reluICML.pdf},
year = {2010}
}
@article{Austin2012,
annote = {Large overview, relatively new},
author = {Austin, Brian M and Zubarev, Dmitry Yu and Lester, William A},
doi = {10.1021/cr2001564},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Austin et al. - 2012 - Quantum Monte Carlo and Related Approaches.pdf:pdf},
journal = {Chemical Reviews},
number = {1},
pages = {263--288},
title = {{Quantum Monte Carlo and Related Approaches}},
url = {https://pubs.acs.org/doi/pdf/10.1021/cr2001564},
volume = {112},
year = {2012}
}
@article{Harju1997,
abstract = {A novel, efficient optimization method for physical problems is presented. The method utilizes the noise inherent in stochastic functions. As an application, an algorithm for the variational optimization of quantum many-body wave functions is derived. The numerical results indicate superior performance when compared to traditional techniques. [S0031-9007(97)03868-4] PACS numbers: 02.60.Pn, 31.25. – v, 71.10. – w, 71.60. + z Optimization in the presence of noise is a difficult task. Most of the optimization methods available are totally deterministic in nature, and, when applied to problems affected by noise, they are either unable to reach an optimum or they may reach a false one. In this Letter we present a novel optimization scheme, called the stochastic gradient approximation (SGA). The method has its roots in the mathematics of automatic control theory [1,2], but to the authors' knowledge it has not been applied for optimization problems in physics before. The algorithm belongs to the class of probabilistic itera-tive methods with variable step size. We consider one important application, namely, the optimization of many-body wave functions using the variational Monte Carlo (VMC) method. The results obtained show conclusively that the SGA constitutes a method tailor-made for quan-tum Monte Carlo (QMC) techniques. The excellent per-formance obtained makes the SGA an attractive tool to other difficult optimization problems as well. Quantum Monte Carlo methods are powerful tools for studying interacting many-particle systems. For fermion systems, the fixed-node diffusion QMC (DMC) can be thought of as a supervariational approach with an energy which is guaranteed to be closer to the exact answer than the starting VMC parent wave function [3]. For a given nodal surface the DMC provides the lowest energy compatible with such a constraint. In atomic and molecular systems, the energies computed with the DMC are comparable in accuracy to the ones obtained using traditional configuration-interaction approaches [3]. This is remarkable when one realizes that in DMC very simple and compact wave functions are used. A popular choice is the Slater-Jastrow form with molecular orbitals from a mean-field calculation, and a parametrized bosonic correlation factor. In such a case, the nodal structure is determined solely by the one-body molecular orbitals. The study of Si n clusters by Grossman and Mit{\'{a}} [4] clearly indicates the importance of the optimization of such orbitals, as done in, for example, [5]. Optimization of the full many-body wave function is crucial for the success not only of the VMC method but of the DMC itself. However, particularly for complex molecules, this is a very time-consuming process. It is clear that an efficient optimization scheme is a very important ingredient for the ultimate success of the QMC methods. Suppose that the quantity one is interested in optimizing is given by},
author = {Harju, A and Barbiellini, B and Siljam{\"{a}}ki, S and Nieminen, R M and Ortiz, G},
doi = {https://doi.org/10.1103/PhysRevLett.79.1173},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Harju et al. - 1997 - Stochastic Gradient Approximation An Efficient Method to Optimize Many-Body Wave Functions.pdf:pdf},
journal = {Physical Review Letters},
number = {7},
pages = {1173},
title = {{Stochastic Gradient Approximation: An Efficient Method to Optimize Many-Body Wave Functions}},
url = {https://journals.aps.org/prl/pdf/10.1103/PhysRevLett.79.1173},
volume = {79},
year = {1997}
}
@phdthesis{Melchior2012,
abstract = {Acknowledgements This thesis would not have been possible without the help and support of the kind and esteemed people around me. Foremost, I want to express my special gratitude to my advisor and friend Nan Wang for his continuous support and the collaborative work I really enjoyed and still enjoy. My sincere thanks to my supervisor professor Laurenz Wiskott for his sup- port and the opportunity to write this thesis. His talent of explaining complicated mathematical topics in a clear way was always motivating me. I also like to thank my second supervisor Dr. Rolf Wu ̈rtz, who already supervised my bachelor thesis. Thanks to Asja Fischer, Oswin Krause and Kai Bru ̈gge for the inspiring discussions we had together with professor Laurenz Wiskott and Nan Wang in our regular meet- ings and in between. The entire focus on this thesis would not have been possible without the support and forbearance of my beloved fianc ́ee Kathrin Mu ̈ller. I also like to thank the rest of my family, without them I would not be where I am today. Finally, I like to thank those three school teachers who always believed in me and whose motivation for their subject and the willing to transfer their knowledge I really appreciate. Thanks to Mrs. No ́e-Depiereux, Mrs. Dr. Hofer and Mr. Hofer.},
author = {Melchior, Jan},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Melchior, Wiskott Pr{\"{u}}fer, Rolf W{\"{u}}rtz Erkl{\"{a}}rung - 2012 - Learning Natural Image Statistics with Gaussian-Binary Restricted Boltzmann M.pdf:pdf},
school = {Ruhr-Universit{\"{a}}t Bochum},
title = {{Learning Natural Image Statistics with Gaussian-Binary Restricted Boltzmann Machines}},
type = {MSc thesis},
url = {https://www.ini.rub.de/PEOPLE/wiskott/Reprints/Melchior-2012-MasterThesis-RBMs.pdf},
year = {2012}
}
@article{Bowler2010,
abstract = {An overview of the CONQUEST linear scaling density functional theory (DFT) code is given, focusing particularly on the scaling behaviour on modern high-performance computing platforms. We demonstrate that essentially perfect linear scaling and weak parallel scaling (with fixed number of atoms per processor core) can be achieved, and that DFT calculations on millions of atoms are now possible.},
annote = {Despite tremendous increases in available numerical computational power in the latter half of the previous-, and the early parts of the current century, any such approximate scheme used is still heavily limited w.r.t. the system size. In practice, most methods are limited to systems of containing on the order of between {\$}10{\^{}}2{\$} (for high- precision methods such as con guration interaction, coupled cluster, di usion Monte Carlo, etc.) and {\$}10{\^{}}5{\$} electrons (for faster Hartree-Fock and density functional methods).
(Ledum2017)},
author = {Bowler, D R and Miyazaki, T},
doi = {10.1088/0953-8984/22/7/074207},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Bowler, Miyazaki - 2010 - Calculations for Millions of Atoms with Density Functional Theory Linear Scaling Shows its Potential.pdf:pdf},
journal = {Journal of Physics: Condensed Matter},
number = {7},
pages = {074207},
title = {{Calculations for Millions of Atoms with Density Functional Theory: Linear Scaling Shows its Potential}},
url = {http://iopscience.iop.org/article/10.1088/0953-8984/22/7/074207/pdf},
volume = {22},
year = {2010}
}
@article{Metropolis1953,
abstract = {THE 0 R Y 0 F T RAe KEF FEe T SIN R A D I 0 L Y SIS 0 F W ATE R 1087 instead, only water molecules with different amounts of excitation energy. These may follow any of three paths: (a) The excitation energy is lost without dissociation into radicals (by collision, or possibly radiation, as in aromatic hydrocarbons). (b) The molecules dissociate, but the resulting radi-cals recombine without escaping from the liquid cage. (c) The molecules dissociate and escape from the cage. In this case we would not expect them to move more than a few molecular diameters through the dense medium before being thermalized. In accordance with the notation introduced by Burton, Magee, and Samuel,22 the molecules following 22 Burton, Magee, and Samuel, J. Chern. Phys. 20, 760 (1952). THE JOURNAL OF CHEMICAL PHYSICS paths (a) and (b) can be designated H 2 0* and those following path (c) can be designated H 2 0t. It seems reasonable to assume for the purpose of these calcula-tions that the ionized H 2 0 molecules will become the H 20 t molecules, but this is not likely to be a complete correspondence. In conclusion we would like to emphasize that the qualitative result of this section is not critically de-pendent on the exact values of the physical parameters used. However, this treatment is classical, and a correct treatment must be wave mechanical; therefore the result of this section cannot be taken as an a priori theoretical prediction. The success of the radical diffu-sion model given above lends some plausibility to the occurrence of electron capture as described by this crude calculation. Further work is clearly needed. A general method, suitable for fast computing machines, for investigatiflg such properties as equations of state for substances consisting of interacting individual molecules is described. The method consists of a modified Monte Carlo integration over configuration space. Results for the two-dimensional rigid-sphere system have been obtained on the Los Alamos MANIAC and are presented here. These results are compared to the free volume equation of state and to a four-term virial coefficient expansion.},
annote = {Metropolis introduseres},
author = {Metropolis, Nicholas and Rosenbluth, Arianna W and Rosenbluth, Marshall N and Teller, Augusta H and Teller, Edward},
doi = {10.1063/1.447334},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Metropolis et al. - 1953 - Equation of State Calculations by Fast Computing Machines.pdf:pdf},
journal = {The Journal of Chemical Physics},
number = {6},
pages = {1087},
title = {{Equation of State Calculations by Fast Computing Machines}},
url = {https://doi.org/10.1063/1.1699114 http://aip.scitation.org/toc/jcp/21/6},
volume = {21},
year = {1953}
}
@phdthesis{Stende2017,
author = {Stende, John-Anders},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Stende - 2017 - Constructing high-dimensional neural network potentials for molecular dynamics.pdf:pdf},
school = {University of Oslo},
title = {{Constructing High-Dimensional Neural Network Potentials for Molecular Dynamics}},
type = {MSc thesis},
url = {https://www.duo.uio.no/bitstream/handle/10852/59442/master.pdf?sequence=1{\&}isAllowed=y},
year = {2017}
}
@book{Kvaal2017,
author = {Kvaal, Simen},
file = {:Users/Vilde/Downloads/notes-fys4480-6.pdf:pdf},
publisher = {University of Oslo},
title = {{Lecture Notes for FYS-KJM 4480 Quantum Mechanics for Many-Particle Systems}},
year = {2017}
}
@inproceedings{Le2012,
abstract = {We consider the problem of building high-level, class-specific feature detectors from only unlabeled data. For example, is it pos-sible to learn a face detector using only unla-beled images? To answer this, we train a 9-layered locally connected sparse autoencoder with pooling and local contrast normalization on a large dataset of images (the model has 1 billion connections, the dataset has 10 mil-lion 200x200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental results reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bod-ies. Starting with these learned features, we trained our network to obtain 15.8{\%} accu-racy in recognizing 22,000 object categories from ImageNet, a leap of 70{\%} relative im-provement over the previous state-of-the-art.},
annote = {Gjennomslaget for unsupervised deep learning da Google greide kjenne igjen katter av seg selv etter {\aa} ha sett YouTube videoer. Autoencoders mm.},
author = {Le, Quoc V and Ranzato, Marc Aurelio and Monga, Rajat and Devin, Matthieu and Chen, Kai and Corrado, Greg S and Dean, Jeff and Ng, Andrew Y},
booktitle = {Proceedings of the 29th International Coference on International Conference on Machine Learning},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Le et al. - 2012 - Building High-level Features Using Large Scale Unsupervised Learning.pdf:pdf},
pages = {507--514},
publisher = {Omnipress},
title = {{Building High-level Features Using Large Scale Unsupervised Learning}},
url = {https://www.cs.princeton.edu/courses/archive/spring13/cos598C/Building High-level Features Using Large Scale Unsupervised Learning.pdf},
year = {2012}
}
@article{Zhang2018,
abstract = {The Restricted Boltzmann Machine (RBM) has aroused wide interest in machine learning fields during the past decade. This review aims to report the recent developments in theoretical research and applications of the RBM. We first give an overview of the general RBM from the theoretical perspective, including stochastic approximation methods, stochastic gradient methods, and preventing overfitting methods. And then this review focuses on the RBM variants which further improve the learning ability of the RBM under general or specific applications. The RBM has recently been extended for representational learning, document modeling, multi-label learning, weakly supervised learning and many other tasks. The RBM and RBM variants provide powerful tools for representing dependency in the data, and they can be used as the basic building blocks to create deep networks. Apart from the Deep Belief Network (DBN) and the Deep Boltzmann Machine (DBM), the RBM can also be combined with the Convolutional Neural Network (CNN) to create deep networks. This review provides a comprehensive view of these advances in the RBM together with its future perspectives.},
author = {Zhang, Nan and Ding, Shifei and Zhang, Jian and Xue, Yu},
doi = {10.1016/J.NEUCOM.2017.09.065},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Zhang et al. - 2018 - An overview on Restricted Boltzmann Machines.pdf:pdf},
issn = {0925-2312},
journal = {Neurocomputing},
month = {jan},
pages = {1186--1199},
publisher = {Elsevier},
title = {{An overview on Restricted Boltzmann Machines}},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217315849},
volume = {275},
year = {2018}
}
@article{Needs2010,
annote = {A newer review},
author = {Needs, R J and Towler, M D and Drummond, N D and {L{\'{o}}pez R{\'{i}}os}, P},
doi = {10.1088/0953-8984/22/2/023201},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Needs et al. - 2010 - Continuum variational and diffusion quantum Monte Carlo calculations.pdf:pdf},
issn = {0953-8984},
journal = {Journal of Physics: Condensed Matter},
month = {jan},
number = {2},
pages = {023201},
publisher = {IOP Publishing},
title = {{Continuum Variational and Diffusion Quantum Monte Carlo Calculations}},
url = {http://stacks.iop.org/0953-8984/22/i=2/a=023201?key=crossref.d7b24f5e48fe3f89fa70b77193ca51e7},
volume = {22},
year = {2010}
}
@article{McMillian1965,
abstract = {The properties of the ground state of liquid He' are studied using a variational wave function of the form II;{\&},f(r;;). The Lennard-Jones 12-6 potential is used with parameters determined from the gas data by deBoer and Michiels. The configuration space integrals are performed by a Monte Carlo technique for 32 and 108 atoms in a cube with periodic boundary conditions. With f(r) =exp[ — (2.6A/r)sg, the ground-state energy is found to be — 0.78{\&}10 " ergs/atom, which is 20{\%} above the experimental value. The liquid structure factor and the two-particle correlation function are in reasonably good agreement with the x-ray and neutron scattering experiments.},
author = {McMillian, W L},
doi = {https://doi.org/10.1103/PhysRev.138.A442},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/McMillian - 1965 - Ground State of Liquid He4.pdf:pdf},
journal = {Physical Review},
number = {2A},
title = {{Ground State of Liquid He{\^{}}4}},
url = {https://journals.aps.org/pr/pdf/10.1103/PhysRev.138.A442},
volume = {138},
year = {1965}
}
@article{Hu2015,
abstract = {We describe a massively parallel implementation of the recently developed discontinuous Galerkin density functional theory (DGDFT) method, for efficient large-scale Kohn-Sham DFT based elec-tronic structure calculations. The DGDFT method uses adaptive local basis (ALB) functions gener-ated on-the-fly during the self-consistent field iteration to represent the solution to the Kohn-Sham equations. The use of the ALB set provides a systematic way to improve the accuracy of the approximation. By using the pole expansion and selected inversion technique to compute electron density, energy, and atomic forces, we can make the computational complexity of DGDFT scale at most quadratically with respect to the number of electrons for both insulating and metallic systems. We show that for the two-dimensional (2D) phosphorene systems studied here, using 37 basis functions per atom allows us to reach an accuracy level of 1.3 × 10 −4 Hartree/atom in terms of the error of energy and 6.2 × 10 −4 Hartree/bohr in terms of the error of atomic force, respectively. DGDFT can achieve 80{\%} parallel efficiency on 128,000 high performance computing cores when it is used to study the electronic structure of 2D phosphorene systems with 3500-14 000 atoms. This high parallel efficiency results from a two-level parallelization scheme that we will describe in detail. C 2015 AIP Publishing LLC. [http://dx.doi.org/10.1063/1.4931732]},
annote = {Despite tremendous increases in available numerical computational power in the latter half of the previous-, and the early parts of the current century, any such approximate scheme used is still heavily limited w.r.t. the system size. In practice, most methods are limited to systems of containing on the order of between {\$}10{\^{}}2{\$} (for high- precision methods such as con guration interaction, coupled cluster, di usion Monte Carlo, etc.) and {\$}10{\^{}}5{\$} electrons (for faster Hartree-Fock and density functional methods).
(Ledum2017)},
author = {Hu, Wei and Lin, Lin and Yang, Chao},
doi = {10.1063/1.4931732},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Hu, Lin, Yang - 2015 - DGDFT A massively parallel method for large scale density functional theory calculations.pdf:pdf},
journal = {The Journal of Chemical Physics},
number = {12},
pages = {124110},
title = {{DGDFT: A Massively Parallel Method for Large Scale Density Functional Theory Calculations}},
url = {https://doi.org/10.1063/1.4931732},
volume = {143},
year = {2015}
}
@article{Moskowitz1981,
author = {Moskowitz, Jules W. and Kalos, M. H.},
doi = {10.1002/qua.560200508},
file = {:Users/Vilde/Downloads/Moskowitz{\_}et{\_}al-1981-International{\_}Journal{\_}of{\_}Quantum{\_}Chemistry.pdf:pdf},
issn = {1097461X},
journal = {International Journal of Quantum Chemistry},
number = {5},
pages = {1107--1119},
title = {{A New Look at Correlations in Atomic and Molecular Systems. I. Application of Fermion Monte Carlo Variational Method}},
volume = {20},
year = {1981}
}
@article{Zhao2010,
abstract = {Hidden Markov models (HMMs) are one of the most popular and success-ful statistical models for time series. Observable operator models (OOMs) are generalizations of HMMs which exhibit several attractive advantages. In particular, a variety of highly efficient, constructive and asymptotically cor-rect learning algorithms are available for OOMs. However, the OOM theory suffers from the negative probability problem (NPP): a given, learnt OOM may sometimes predict negative " probabilities " for certain events. It was recently shown that it is undecidable whether a given OOM will eventually produce such negative values. We propose a novel variant of OOMs, called norm observable operator models (NOOMs), which avoid the NPP by design. Like OOMs, NOOMs use a set of linear operators to update system states. But differing from OOMs, they represent probabilities by the square of the norm of system states, thus precluding negative " probability " values. While being free of the NPP, NOOMs retain most advantages of OOMs. For example, NOOMs also capture (some) processes that cannot be modelled by HMMs. More importantly, in principle NOOMs can be learnt from data in a constructive way; and the learnt models are asymptotically correct. We also prove that NOOMs capture all Markov chain (MC) describable processes. This contribution presents the mathematical foundations of NOOMs, dis-cusses the expressiveness of the model class, and explains how a NOOM can be estimated from data constructively.},
annote = {The mathematical structure of quantum mechanics appears naturally when one explores more flexible models than Eq. (1) while still attempts to ensure the positivity of the probability density (Cheng2017)

Representing probability density using square of a function was also put forward by [39, 40]. These ap- proach ensures the positivity of probability and naturally ad- mit a quantum mechanical interpretation. (Han2017)},
author = {Zhao, Ming-Jie and Jaeger, Herbert},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Zhao, Jaeger - 2009 - Norm Observable Operator Models.pdf:pdf},
journal = {Neural Computation},
number = {7},
pages = {1927--1959},
title = {{Norm Observable Operator Models}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.718.7372{\&}rep=rep1{\&}type=pdf},
volume = {22},
year = {2010}
}
@article{LopezRios2012,
abstract = {We have developed a flexible framework for constructing Jastrow factors which allows for the introduction of terms involving arbitrary numbers of particles. The use of various three-and four-body Jastrow terms in quantum Monte Carlo calculations is investigated, including a four-body van der Waals-like term, and anisotropic terms. We have tested these Jastrow factors on one-and two-dimensional homogeneous electron gases, the Be, B, and O atoms, and the BeH, H 2 O, N 2 , and H 2 molecules. Our optimized Jastrow factors retrieve more than 90{\%} of the fixed-node diffusion Monte Carlo correlation energy in variational Monte Carlo for each system studied. DOI: 10.1103/PhysRevE.86.036703 PACS number(s): 02.70.Ss, 31.15.V−, 71.10.−w, 71.15.−m},
author = {{L{\'{o}}pez R{\'{i}}os}, P and Seth, P and Drummond, N D and Needs, R J},
doi = {10.1103/PhysRevE.86.036703},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/L{\'{o}}pez R{\'{i}}os et al. - 2012 - Framework for constructing generic Jastrow correlation factors.pdf:pdf},
journal = {Physical Review E},
title = {{Framework for Constructing Generic Jastrow Correlation Factors}},
url = {https://journals.aps.org/pre/pdf/10.1103/PhysRevE.86.036703},
volume = {86},
year = {2012}
}
@inproceedings{Kim2013,
abstract = {The transcorrelated (TC) method is one of the wave-function-based methods used for first-principles electronic structure calculations, and in terms of the computational cost is applicable to solid-state calculation. In this method, a many-body wave function of electrons is approximated as a product of the Jastrow factor and the Slater determinant, and the first-principles Hamiltonian is similarity-transformed by the Jastrow factor. The Schr{\"{o}}dinger equation is rewritten as an eigenvalue problem for this similarity-transformed Hamiltonian, from which one obtains a self-consistent field (SCF) equation for optimizing one-electron orbitals in the Slater determinant at low computational cost. In contrast, optimization of the Jastrow factor is computationally much more expensive and has not been performed for solid-state calculation of the TC method before. In this study, we develop a new method for optimizing the Jastrow factor at a reasonable computational cost using the random-phase approximation (RPA) and pseudo-variance minimization. We apply this method to some simple solids, and find that the band gap of a wide-band-gap insulator is much improved by RPA. 1. Introduction First-principles electronic structure calculation has played an active and important role in condensed matter physics. In particular, density functional theory (DFT) [1, 2] has produced prominent successes because simple approximations for the exchange-correlation functional of DFT, such as local density approximation (LDA) or generalized gradient approximation (GGA), provide satisfactory results for many systems at relatively low computational cost. However, it is well known that such simple approximations have several problems in accuracy, e.g., the band gap is much underestimated, and van der Waals interaction is not correctly described. In addition, improving accuracy is difficult to achieve systematically for DFT-based methods because, in DFT, we have to handle the exchange-correlation functional, the exact form of which is quite nontrivial. On the other hand, wave-function theory, in which one explicitly handles the many-body wave function, has a systematic way of improving accuracy, hence it is expected to be a good candidate for high-accuracy calculation. Unfortunately, however, the Hartree-Fock (HF) method, which is the starting point for most of wave-function theories, is known to be highly inaccurate for solid-state calculations because it neglects all electron correlation effects such as the screening effect in solids, whereas other sophisticated wave-function theories are often too expensive for solid-state calculations.},
author = {Ochi, Masayuki and Tsuneyuki, Shinji},
booktitle = {24th IUPAP Conference on Computational Physics},
doi = {10.1088/1742-6596/454/1/012020},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Kim et al. - 2013 - Optimization of the Jastrow Factor.pdf:pdf},
publisher = {IOP Publishing},
title = {{Optimization of the Jastrow Factor in the Correlated Wave Function of Electrons Using the First-Principles Transcorrelated Method for Solid-State Calculations}},
url = {http://iopscience.iop.org/article/10.1088/1742-6596/454/1/012020/pdf},
volume = {454},
year = {2013}
}
@unpublished{Cheng2017,
abstract = {We compare and contrast the statistical physics and quantum physics inspired approaches for unsupervised generative modeling of classical data. The two approaches represent probabilities of observed data using energy-based models and quantum states respectively. Classical and quantum information patterns of the target datasets therefore provide principled guidelines for structural design and learning in these two approaches. Taking the restricted Boltzmann machines (RBM) as an example, we analyze the information theoretical bounds of the two approaches. We verify our reasonings by comparing the performance of RBMs of various architectures on the standard MNIST datasets.},
author = {Cheng, Song and Chen, Jing and Wang, Lei},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Cheng, Chen, Wang - Unknown - Information Perspective to Probabilistic Modeling Boltzmann Machines versus Born Machines.pdf:pdf},
title = {{Information Perspective to Probabilistic Modeling: Boltzmann Machines versus Born Machines}},
url = {https://arxiv.org/pdf/1712.04144.pdf},
year = {2017}
}
@incollection{Hinton1986,
annote = {Probably the second publication to study the Boltzmann Machine.},
author = {Hinton, Geoffrey E. and Sejnowski, Terrence J.},
booktitle = {Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Volume 1: Foundations},
chapter = {7},
editor = {Rumelhart, David E. and McClelland, James L.},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Hinton, Sejnowski - Unknown - Learning and Relearning in Boltzmann Machines.pdf:pdf},
isbn = {0-262-68053-X},
pages = {282--317},
publisher = {MIT Press},
title = {{Learning and Relearning in Boltzmann Machines}},
url = {https://www.researchgate.net/profile/Terrence{\_}Sejnowski/publication/242509302{\_}Learning{\_}and{\_}relearning{\_}in{\_}Boltzmann{\_}machines/links/54a4b00f0cf256bf8bb327cc.pdf},
year = {1986}
}
@phdthesis{Roggero2014,
author = {Roggero, Alessandro},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Pederiva, Roggero - Unknown - Ground state and dynamical properties of many–body systems by non conventional Quantum Monte Carlo algor.pdf:pdf},
school = {University of Trento},
title = {{Ground State and Dynamical Properties of Many–Body Systems by Non Conventional Quantum Monte Carlo Algorithms}},
type = {PhD thesis},
url = {http://eprints-phd.biblio.unitn.it/1340/1/Thesis.pdf},
year = {2014}
}
@article{Yuan2017,
abstract = {We present and compare several many-body methods as applied to two-dimensional quantum dots with circular symmetry. We calculate the approximate ground state energy using a harmonic oscillator basis optimized by Hartree–Fock (HF) theory and further improve the ground state energy using two post-HF methods: in-medium similarity renormalization group and coupled cluster with singles and doubles. With the application of quasidegenerate perturbation theory or the equations-of-motion method to the results of the previous two methods, we obtain addition and removal energies as well. Our results are benchmarked against full configuration interaction and diffusion Monte Carlo where available. We examine the rate of convergence and perform extrapolations to the infinite basis limit using a power-law model. Published by AIP Publishing. https://doi.org/10.1063/1.4995615},
author = {Yuan, Fei and Novario, Samuel J and Parzuchowski, Nathan M and Reimann, Sarah and Bogner, S K and Hjorth-Jensen, Morten},
doi = {10.1063/1.4995615},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Yuan et al. - 2017 - Addition and Removal Energies of Circular Quantum Dots.pdf:pdf},
journal = {The Journal of Chemical Physics},
pages = {164109},
title = {{Addition and Removal Energies of Circular Quantum Dots}},
url = {https://doi.org/10.1063/1.4995615},
volume = {147},
year = {2017}
}
@article{Delyon2017,
abstract = {Based on the central limit theorem, we discuss the problem of evaluation of the statistical error of Monte Carlo calculations using a time-discretized diffusion process. We present a robust and practical method to determine the effective variance of general observables and show how to verify the equilibrium hypothesis by the Kolmogorov-Smirnov test. We then derive scaling laws of the efficiency illustrated by variational Monte Carlo calculations on the two-dimensional electron gas.},
annote = {Good statistical theory},
author = {Delyon, F and Bernu, B and Holzmann, Markus},
doi = {10.1103/PhysRevE.95.023307},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Delyon, Bernu, Holzmann - 2017 - Confidence and efficiency scaling in variational quantum Monte Carlo calculations.pdf:pdf},
journal = {Physical Review E},
number = {2},
title = {{Confidence and Efficiency Scaling in Variational Quantum Monte Carlo Calculations}},
url = {https://journals.aps.org/pre/pdf/10.1103/PhysRevE.95.023307},
volume = {95},
year = {2017}
}
@article{Niu2016,
abstract = {HPCTOOLKIT is an integrated suite of tools that supports measurement, analysis, attribution, and presentation of application performance for both sequential and parallel programs. HPCTOOLKIT can pinpoint and quantify scalability bottlenecks in fully optimized parallel programs with a measurement overhead of only a few percent. Recently, new capabilities were added to HPCTOOLKIT for collecting call path profiles for fully optimized codes without any compiler support, pinpointing and quantifying bottlenecks in multithreaded programs, exploring performance information and source code using a new user interface, and displaying hierarchical space–time diagrams based on traces of asynchronous call path samples. This paper provides an overview of HPCTOOLKIT and illustrates its utility for performance analysis of parallel applications.},
author = {Niu, Qingpeng and Dinan, James and Tirukkovalur, Sravya and Benali, A and Kim, J and Mitas, L and Wagner, L and Sadayappan, P},
doi = {https://doi.org/10.1002/cpe.3748},
file = {:Users/Vilde/Downloads/Niu{\_}et{\_}al-2016-Concurrency{\_}and{\_}Computation{\%}3A{\_}Practice{\_}and{\_}Experience.pdf:pdf},
isbn = {2007015102},
issn = {15320626},
journal = {Concurrency Computation Practice and Experience},
number = {13},
title = {{Global-view coefficients: A Data Management Solution for Parallel QUantum Monte Carlo Applications}},
volume = {28},
year = {2016}
}
@inproceedings{Cho2011,
abstract = {We propose a few remedies to improve training of Gaussian-Bernoulli restricted Boltzmann machines (GBRBM), which is known to be difficult. Firstly, we use a different parameterization of the energy function, which allows for more intuitive interpretation of the parameters and facilitates learning. Secondly, we propose parallel tempering learning for GBRBM. Lastly, we use an adaptive learning rate which is selected automatically in order to stabilize training. Our ex-tensive experiments show that the proposed improvements indeed remove most of the difficulties encountered when training GBRBMs using conventional methods.},
annote = {Example of GB-RBM being "a common choice when needing continuous visibles" (Melchior2017)

Training GB-RBM known to be hard. This article suggested their failure is due to the training algo and proposed some modifications to overcome the difficulties encountered in training GRBMs
(Melchior2012)},
author = {Cho, KyungHyun and Ilin, Alexander and Raiko, Tapani},
booktitle = {Proceedings of the International Conference on Artificial Neural Networks, ICANN},
editor = {Honkela, Timo and W{\l}odzis{\l}aw, Duch and Girolami, Mark and Kaski, Samuel},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Cho, Ilin, Raiko - 2011 - LNCS 6791 - Improved Learning of Gaussian-Bernoulli Restricted Boltzmann Machines.pdf:pdf},
keywords = {Adaptive Learning Rate,Gaussian-Bernoulli Restricted Boltzmann Machine,Parallel Tempering,Restricted Boltzmann Machine},
pages = {10--17},
publisher = {Springer Berlin Heidelberg},
title = {{Improved Learning of Gaussian-Bernoulli Restricted Boltzmann Machines}},
url = {https://link.springer.com/content/pdf/10.1007{\%}2F978-3-642-21735-7{\_}2.pdf},
year = {2011}
}
@phdthesis{Krizhevsky2009,
abstract = {Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous researchers who have tried this have found it dicult to learn a good set of lters from the images. We show how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute the work among multiple machines connected on a network, we show how training such a model can be done in reasonable time. A second problematic aspect of the tiny images dataset is that there are no reliable class labels which makes it hard to use for object recognition experiments. We created two sets of reliable labels. The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of each of 100 non-overlapping classes. Using these labels, we show that object recognition is signicantly improved by pre-training a layer of features on a large set of unlabeled tiny images.},
annote = {Example of GB-RBM being "a common choice when needing continuous visibles" (Melchior2017)

Training of GB-RBM known to be hard, modifiactions to improve it proposed in this thesis (amongst others). 
-This thesis trained GRBMs on natural images and concluded the difficulties are mainly due to the existence of high-frequency noise in the images, which further prevents the model from learning the important structures. (Melchior2017)
-This thesis successfully trained a deep hierarchical network and concluded that a failure is mainly because of the existence of high-frequency noise in natural images, which prevents the model from learning the important structures. (Melchior2012)

States BMs are popular in the field of feature extraction (Melchior2012)

This thesis proposes a slightly different energy expression of the GB-RBM than (Melchior2012), where the visible term does not square the sigma. However, this leads to a counter intuitive scaling of the conditional mean. (Melchior2012)},
author = {Krizhevsky, Alex},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Krizhevsky - 2009 - Learning Multiple Layers of Features from Tiny Images.pdf:pdf},
school = {University of Toronto},
title = {{Learning Multiple Layers of Features from Tiny Images}},
type = {MSc thesis},
url = {https://www.cs.toronto.edu/{~}kriz/learning-features-2009-TR.pdf},
year = {2009}
}
@article{Reatto1988,
abstract = {Some properties of a new class of variational wave functions for boson systems are studied. This study extends the Jastrow class, and many-body correlations are implicitly introduced by a coupling of the particle coordinates to subsidiary shadow variables. We prove that the new wave function has Bose-Einstein condensation both in the liquid and in the solid phase. The maximum-overlap criterion for this wave function with the exact ground state is developed. The kind of Jastrow correlations implicitly contained in the new wave function is studied and we formulate a theory of correlations based on the reference interaction site model.},
author = {Reatto, L and Masserini, G L},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Reatto, Masserini - 1988 - Shadow wave function for many-boson systems.pdf:pdf},
journal = {Physical Review B},
number = {7},
title = {{Shadow Wave Function for Many-Boson Systems}},
url = {https://journals.aps.org/prb/pdf/10.1103/PhysRevB.38.4516},
volume = {38},
year = {1988}
}
@incollection{Welling2005,
abstract = {Directed graphical models with one layer of observed random variables and one or more layers of hidden random variables have been the dom-inant modelling paradigm in many research fields. Although this ap-proach has met with considerable success, the causal semantics of these models can make it difficult to infer the posterior distribution over the hidden variables. In this paper we propose an alternative two-layer model based on exponential family distributions and the semantics of undi-rected models. Inference in these " exponential family harmoniums " is fast while learning is performed by minimizing contrastive divergence. A member of this family is then studied as an alternative probabilistic model for latent semantic indexing. In experiments it is shown that they perform well on document retrieval tasks and provide an elegant solution to searching with keywords.},
annote = {First suggestion of using Gaussian untis in the RBM, according to (Melchoir2017)},
author = {Welling, Max and Rosen-Zvi, Michal and Hinton, Geoffrey},
booktitle = {Advances in Neural Information Processing Systems 17},
editor = {Saul, L. K. and Weiss, Y. and Bottou, L.},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Welling, Rosen-Zvi, Hinton - Unknown - Exponential Family Harmoniums with an Application to Information Retrieval.pdf:pdf},
pages = {1481--1488},
publisher = {MIT Press},
title = {{Exponential Family Harmoniums with an Application to Information Retrieval}},
url = {https://papers.nips.cc/paper/2672-exponential-family-harmoniums-with-an-application-to-information-retrieval.pdf},
year = {2005}
}
@book{HjortJensen2015,
abstract = {Computing comprises three distinct strands: hardware, software and the ways they are used in real or imagined worlds. Its use in research is more than writing or running code. Having something significant to compute and deploying judgement in what is attempted and achieved are especially challenging. In science or engineering, one must define a central problem in computable form, run such software as is appropriate and, last but by no means least, convince others that the results are both valid and useful. These several strands are highly interdependent. A major scientific development can transform disparate aspects of information and computer technologies. Computers affect the way we do science, as well as changing our personal worlds. Access to information is being transformed, with consequences beyond research or even science. Creativity in research is usually considered uniquely human, with inspiration a central factor. Scientific and technological needs are major forces in innovation, and these include hardware and software opportunities. One can try to define the scientific needs for established technologies (atomic energy, the early semiconductor industry), for rapidly developing technologies (advanced materials, microelectronics) and for emerging technologies (nanotechnology, novel information technologies). Did these needs define new computing, or was science diverted into applications of then-available codes? Regarding credibility, why is it that engineers accept computer realizations when designing engineered structures, whereas predictive modelling of materials has yet to achieve industrial confidence outside very special cases? The tensions between computing and traditional science are complex, unpredictable and potentially powerful.},
author = {Hjorth-Jensen, Morten},
file = {:Users/Vilde/Downloads/lectures2015.pdf:pdf},
publisher = {University of Oslo},
title = {{Computational Physics Lecture Notes}},
year = {2015}
}
@phdthesis{Kristiansen2017,
abstract = {The scope of the thesis is 60 credits. The front page depicts a section of the root system of the exceptional Lie group E 8 , projected into the plane. Lie groups were invented by the Norwegian mathematician Sophus Lie (1842–1899) to express symmetries in differential equations and today they play a central role in various parts of mathematics. Abstract The solution of the time-dependent Schr{\"{o}}dinger equation plays a central role for our understanding of quantum mechanical systems, spanning from studies and implementations of quantum circuits to nuclears reactions in stars and the synthesis of the elements. It provides invaluable information about the temporal evolution of quantum mechanical systems and their behavior when interacting with matter and/or external probes. The time-dependent Schr{\"{o}}dinger equation (TDSE) plays thus a ubiquitous role when studying interacting quantum mechanical many-particle systems. Due to the high level of complexity involved in time-dependent studies, TDSE applications and studies have often been limited to few-body systems only. In order to tackle the increasing complexities of different many-particle systems, we have in this thesis developed an efficient many-body approach based on the orbital-adaptive time-dependent coupled-cluster [1] (OATDCC) method. The coupled-cluster method which we base our theoretical deriva-tions on, has been applied to a wide range of time-independent many-particle systems, from atomic and molecular physics to strongly interacting matter as seen in compact objects like neutron stars. Coupled cluster theory allows for systematic approximations to the full many-body problem and circumvents thus many of the dimensionality problems encountered in for example large-scale diagonalization problems. We refer our implementations and studies to as just the time-dependent coupled-cluster (TDCC) method. The TDCC method approximates solutions to the quantum N -body problem and for N = 2 TDCC is equivalent to the time-dependent configuration-interaction method (TDCI). The latter provides, within a given effective space, exact results that can be used to benchmark results from approximative methods like the TDCC developed here. In this work, in order to compare our TDCC method with exact results, we have also developed and implemented a TDCI solver. This is shown to be correct by comparing with previous studies and is used as a foundation for verifying the implementation of the TDCC method. We demonstrate that the methods are equal to numerical precision for one and two-dimensional 1},
author = {Kristiansen, H{\aa}kon Emil},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Kristiansen - Unknown - Time Evolution of Quantum Mechanical Many-Body Systems.pdf:pdf},
school = {University of Oslo},
title = {{Time Evolution of Quantum Mechanical Many-Body Systems}},
type = {MSc thesis},
url = {https://www.duo.uio.no/bitstream/handle/10852/60338/H-konEmilKristiansen{\_}Thesis.pdf?sequence=1{\&}isAllowed=y},
year = {2017}
}
@article{Hinton2006a,
abstract = {We show how to use " complementary priors " to eliminate the explaining away effects that make inference difficult in densely-connected belief nets that have many hidden layers. Using com-plementary priors, we derive a fast, greedy algo-rithm that can learn deep, directed belief networks one layer at a time, provided the top two lay-ers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights us-ing a contrastive version of the wake-sleep algo-rithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit im-ages and their labels. This generative model gives better digit classification than the best discrimi-native learning algorithms. The low-dimensional manifolds on which the digits lie are modelled by long ravines in the free-energy landscape of the top-level associative memory and it is easy to ex-plore these ravines by using the directed connec-tions to display what the associative memory has in mind.},
annote = {The article that regained people's faith in (deep) neural networks.},
author = {Hinton, Geoffrey E and Osindero, Simon and Teh, Yee-Whye},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Hinton, Osindero, Teh - Unknown - A fast learning algorithm for deep belief nets.pdf:pdf},
journal = {Neural Computation},
number = {7},
title = {{A Fast Learning Algorithm for Deep Belief Nets}},
url = {https://www.cs.toronto.edu/{~}hinton/absps/fastnc.pdf},
volume = {18},
year = {2006}
}
@article{Hinton2007,
abstract = {To achieve its impressive performance in tasks such as speech perception or object recognition, the brain extracts multiple levels of representation from the sen-sory input. Backpropagation was the first computation-ally efficient model of how neural networks could learn multiple layers of representation, but it required labeled training data and it did not work well in deep networks. The limitations of backpropagation learning can now be overcome by using multilayer neural networks that con-tain top-down connections and training them to gener-ate sensory data rather than to classify it. Learning multilayer generative models might seem difficult, but a recent discovery makes it easy to learn nonlinear distributed representations one layer at a time. Learning feature detectors To enable the perceptual system to make the fine distinctions that are required to control behavior, sensory cortex needs an efficient way of adapting the synaptic weights of multiple layers of feature-detecting neurons. The backpropagation learning procedure [1] iteratively adjusts all of the weights to optimize some measure of the classification performance of the network, but this requires labeled training data. To learn multiple layers of feature detectors when labeled data are scarce or non-existent, some objective other than classification is required. In a neural network that contains both bot-tom-up 'recognition' connections and top-down 'generative' connections it is possible to recognize data using a bottom-up pass and to generate data using a top-down pass. If the neurons are stochastic, repeated top-down passes will generate a whole distribution of data-vectors. This suggests a sensible objective for learning: adjust the weights on the top-down connections to maximize the probability that the network would generate the training data. The neural network's model of the training data then resides in its top-down connections. The role of the bottom-up connections is to enable the network to determine activations for the features in each layer that constitute a plausible explanation of how the network could have generated an observed sensory data-vector. The hope is that the active features in the higher layers will be a much better guide to appropriate actions than the raw sensory data or the lower-level features. As we shall see, this is not just wishful thinking – if three layers of feature detectors are trained on unlabeled images of handwritten digits, the complicated nonlinear features in the top layer enable excellent recognition of poorly written digits like those in Figure 1b [2]. There are several reasons for believing that our visual systems contain multilayer generative models in which top-down connections can be used to generate low-level features of images from high-level representations, and bottom-up connections can be used to infer the high-level representations that would have generated an observed set of low-level features. Single cell recordings [3] and the reciprocal connectivity between cortical areas [4] both suggest a hierarchy of progressively more complex features in which each layer can influence the layer below. Vivid visual imagery, dreaming, and the disambiguating effect of context on the interpretation of local image regions [5] also suggest that the visual system can perform top-down generation. The aim of this review is to complement the neural and psychological evidence for generative models by reviewing recent computational advances that make it easier to learn generative models than their feed-forward counterparts. The advances are illustrated in the domain of handwritten digits where a learned generative model outperforms dis-criminative learning methods at classification.},
annote = {Hinton argues the human brain generative, because of fex dreaming.},
author = {Hinton, Geoffrey E},
doi = {10.1016/j.tics.2007.09.004},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Hinton - Unknown - Learning multiple layers of representation(2).pdf:pdf},
journal = {Trends in Cognitive Sciences},
number = {10},
pages = {428--434},
title = {{Learning Multiple Layers of Representation}},
url = {http://www.cs.toronto.edu/{~}hinton/csc321/readings/tics.pdf},
volume = {11},
year = {2007}
}
@incollection{Rubenstein2017,
annote = {Trial wave function and minimization (including stochastic reconfiguration)},
author = {Rubenstein, Brenda},
booktitle = {Variational Methods in Molecular Modeling},
chapter = {10},
doi = {10.1007/978-981-10-2502-0_10},
editor = {Wu, Jianzhong},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - Introduction to the Variational Monte Carlo Method in Quantum Chemistry and Physics.pdf:pdf},
isbn = {978-981-10-2500-6},
pages = {258--313},
publisher = {Springer Science+Business Media Singapore 2017},
title = {{Introduction to the Variational Monte Carlo Method in Quantum Chemistry and Physics}},
url = {https://link.springer.com/content/pdf/10.1007{\%}2F978-981-10-2502-0{\_}10.pdf},
year = {2017}
}
@article{Lynn2017,
abstract = {Local chiral effective field theory interactions have recently been developed and used in the context of quantum Monte Carlo few-and many-body methods for nuclear physics. In this work, we go over detailed features of local chiral nucleon-nucleon interactions and examine their effect on properties of the deuteron, paying special attention to the perturbativeness of the expansion. We then turn to three-nucleon interactions, focusing on operator ambiguities and their interplay with regulator effects. We then discuss the nuclear Green's function Monte Carlo method, going over both wave-function correlations and approximations for the two-and three-body propagators. Following this, we present a range of results on light nuclei: Binding energies and distribution functions are contrasted and compared, starting from several different microscopic interactions.},
author = {Lynn, J E and Tews, I and Carlson, J and Gandolfi, S and Gezerlis, A and Schmidt, K E and Schwenk, A},
doi = {10.1103/PhysRevC.96.054007},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Lynn et al. - 2017 - Quantum Monte Carlo calculations of light nuclei with local chiral two-and three-nucleon interactions.pdf:pdf},
journal = {Physical Review C},
number = {5},
title = {{Quantum Monte Carlo Calculations of Light Nuclei with Local Chiral Two-and Three-Nucleon Interactions}},
url = {https://journals.aps.org/prc/pdf/10.1103/PhysRevC.96.054007},
volume = {96},
year = {2017}
}
@article{VandeVondele2012,
abstract = {In this work, the applicability and performance of a linear scaling algorithm is investigated for three-dimensional condensed phase systems. A simple but robust approach based on the matrix sign function is employed together with a thresholding matrix multiplication that does not require a prescribed sparsity pattern. Semiempirical methods and density functional theory have been tested. We demonstrate that self-consistent calculations with 1 million atoms are feasible for simple systems. With this approach, the computational cost of the calculation depends strongly on basis set quality. In the current implementation, high quality calculations for dense systems are limited to a few hundred thousand atoms. We report on the sparsities of the involved matrices as obtained at convergence and for intermediate iterations. We investigate how determining the chemical potential impacts the computational cost for very large systems.},
annote = {Despite tremendous increases in available numerical computational power in the latter half of the previous-, and the early parts of the current century, any such approximate scheme used is still heavily limited w.r.t. the system size. In practice, most methods are limited to systems of containing on the order of between {\$}10{\^{}}2{\$} (for high- precision methods such as con guration interaction, coupled cluster, di usion Monte Carlo, etc.) and {\$}10{\^{}}5{\$} electrons (for faster Hartree-Fock and density functional methods).
(Ledum2017)},
author = {VandeVondele, Joost and Bor{\v{s}}tnik, Urban and Hutter, J{\"{u}}rg},
doi = {10.1021/ct200897x},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Vandevondele, Bor{\v{s}} Tnik, Rg Hutter - Unknown - Linear Scaling Self-Consistent Field Calculations with Millions of Atoms in the Condense.pdf:pdf},
journal = {Journal of chemical theory and computation},
number = {10},
pages = {3565--3573},
title = {{Linear Scaling Self-Consistent Field Calculations with Millions of Atoms in the Condensed Phase}},
url = {https://pubs.acs.org/doi/pdf/10.1021/ct200897x},
volume = {8},
year = {2012}
}
@article{MacFarland1994,
author = {MacFarland, T and Vitiello, S A and Reatto, L and Chester, G V and Kalos, M H},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - full-text(4).pdf:pdf},
journal = {Physical Review B},
number = {18},
title = {{Trial Shadow Wave Function for the Ground State of 4He}},
volume = {50},
year = {1994}
}
@article{Taut1993,
abstract = {The problem of the Schrodinger equation for two electrons (interacting with Coulomb potentials) in an external harmonic-oscillator potential is revisited and shown to be solvable analytically for a particu-lar, denumerably infinite set of oscillator frequencies. Solutions are given for ground and excited states in the singlet and triplet spin configurations. PACS number(s): 31.20.Di, 03.65.Ge, 31.20.Tz, 36.90.+f},
author = {Taut, M},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Taut - 1993 - Two Electrons in an External Oscillator Potential Particular Analytic Solutions of a Coulomb Correlation Problem.pdf:pdf},
journal = {Physical Review A},
number = {5},
pages = {3561},
title = {{Two Electrons in an External Oscillator Potential: Particular Analytic Solutions of a Coulomb Correlation Problem}},
url = {https://journals.aps.org/pra/pdf/10.1103/PhysRevA.48.3561},
volume = {48},
year = {1993}
}
@article{Nilsen2005,
abstract = {In this work we compare the results of the Gross-Pitaevskii and modified Gross-Pitaevskii equations with ab initio variational Monte Carlo calculations for Bose-Einstein condensates of atoms in axially symmetric traps. We examine both the ground state and excited states having a vortex line along the z axis at high values of the gas parameter and demonstrate an excellent agreement between the modified Gross-Pitaevskii and ab initio Monte Carlo methods, both for the ground and vortex states.},
annote = {We can take advantage of the fact that a Bose-Einstein condensation gas is dilute and describe the two body interaction V{\_}int (r{\_}i - r{\_}j) by a hard-core potential of radius a, where a is the scattering length, thus treating the atoms as hard spheres. (Nilsen2007).},
author = {Nilsen, J K and Mur-Petit, J and Guilleumas, M and Hjorth-Jensen, M and Polls, A},
doi = {10.1103/PhysRevA.71.053610},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Nilsen et al. - Unknown - Vortices in atomic Bose-Einstein condensates in the large-gas-parameter region.pdf:pdf},
journal = {Physical Review A},
number = {5},
title = {{Vortices in Atomic Bose-Einstein Condensates in the Large-Gas-Parameter Region}},
url = {https://journals.aps.org/pra/pdf/10.1103/PhysRevA.71.053610},
volume = {75},
year = {2005}
}
@phdthesis{Ledum2017,
abstract = {We implement two di erent ab initio electronic structure methods: Hartree-Fock (HF), and quantum variational Monte Carlo (VMC). Gaussian type orbitals are used for the HF method, while the VMC framework allows more general orbital bases (in- cluding the possibility of using the optmized HF orbitals). A thorough introduction to the underlying theory of both methods is presented, and the codes are tested on selected rst row atoms and simple molecules. Ground state energies are found to be in good agreement with the litterature. Secondly, a general function approximation scheme is implemented using arti - cial neural networks (ANN). The ANN implementation is based on the TensorFlow library developed by the Google Brain team. It is thoroughly tested on single and multivariable functions and subsequently shown to be able to approximate potential energy surfaces (PES) using data from the aforementioned ab initio calculations. The ANN may then be used as a force eld in molecular dynamics (MD) simu- lations—in place of ordinary parametrized e ective MD potentials—thereby success- fully bridging the quantum mechanical and the microscopic regimes. Whereas tradi- tional MD potentials require hand crafting and tuning of a parametrized functional form, the present work implements a multiscale modelling approach in which essen- tially no human intervention is needed. Such "parameter-free" multiscale modelling is preferable for obvious reasons: the results should be fundamentally independent of the human experimenter's ability to guess an appropriate functional form. Lastly: Showcasing the full usage of the computational framework developed, we present a simple—proof of concept—MD simulation using an ANN trained to approx- imate a PES.},
author = {Ledum, Morten},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Ledum - 2017 - A Computational Environment for Multiscale Modeling.pdf:pdf},
school = {University of Oslo},
title = {{A Computational Environment for Multiscale Modeling}},
type = {MSc thesis},
url = {https://www.duo.uio.no/bitstream/handle/10852/61196/morten-ledum-master-final.pdf?sequence=1{\&}isAllowed=y},
year = {2017}
}
@book{Dickhoff2005,
annote = {An alternative text book that also discusses bosons.},
author = {Dickhoff, Willem and {Van Neck}, Dimitri},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - Many-Body Theory Exposed! Propagator description of quantum mechanics in many-body systems.pdf:pdf},
isbn = {981-256-294-X},
publisher = {World Scientific Publishing Co. Pte. Ltd.},
title = {{Many-Body Theory Exposed! Propagator Description of Quantum Mechanics in Many-Body Systems}},
url = {http://www.uio.no/studier/emner/matnat/fys/FYS-KJM4480/h09/undervisningsmateriale/Lecture notes/dickhoffvanneck.pdf},
year = {2005}
}
@article{Hastings1970,
author = {Hastings, W K},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Hastings - 1970 - Monte Carlo Sampling Methods Using Markov Chains and Their Applications.pdf:pdf},
journal = {Biometrika},
number = {1},
pages = {97--109},
title = {{Monte Carlo Sampling Methods Using Markov Chains and Their Applications}},
url = {https://pdfs.semanticscholar.org/a430/cb602f7d47c21cc4fa94a351ec0c4a9f1fbd.pdf},
volume = {57},
year = {1970}
}
@article{Gruneis2017,
abstract = {The explicitly correlated approach is one of the most important breakthroughs in ab initio electronic structure theory, providing arguably the most compact, accurate, and efficient ansatz for describing the correlated motion of electrons. Since Hylleraas first used an explicitly correlated wave function for the He atom in 1929, numerous attempts have been made to tackle the significant challenges involved in constructing practical explicitly correlated methods that are applicable to larger systems. These include identifying suitable mathematical forms of a correlated wave function and an efficient evaluation of many-electron integrals. R12 theory, which employs the resolution of the identity approximation, emerged in 1985, followed by the introduction of novel correlation factors and wave function ans{\"{a}}tze, leading to the establishment of F12 theory in the 2000s. Rapid progress in recent years has significantly extended the application range of explicitly correlated theory, offering the potential of an accurate wave-function treatment of complex systems such as photosystems and semiconductors. This perspec-tive surveys explicitly correlated electronic structure theory, with an emphasis on recent stochastic and deterministic approaches that hold significant promise for applications to large and complex systems including solids. Published by AIP Publishing. [http://dx.doi.org/10.1063/1.4976974]},
annote = {Review},
author = {Gr{\"{u}}neis, Andreas and Hirata, So and Ohnishi, Yu-Ya and Ten-No, Seiichiro},
doi = {10.1063/1.4976974},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Gr{\"{u}}neis et al. - 2017 - Perspective Explicitly Correlated Electronic Structure Theory for Complex Systems.pdf:pdf},
journal = {The Journal of Chemical Physics},
title = {{Perspective: Explicitly Correlated Electronic Structure Theory for Complex Systems}},
url = {https://doi.org/10.1063/1.4976974},
volume = {146},
year = {2017}
}
@article{Melchior2017,
abstract = {We present a theoretical analysis of Gaussian-binary restricted Boltzmann machines (GRBMs) from the perspective of density models. The key aspect of this analysis is to show that GRBMs can be formulated as a constrained mixture of Gaussians, which gives a much better insight into the model's capabilities and limitations. We further show that GRBMs are capable of learning meaningful features without using a regularization term and that the results are comparable to those of independent component analysis. This is illustrated for both a two-dimensional blind source separation task and for modeling natural image patches. Our findings exemplify that reported difficulties in training GRBMs are due to the failure of the training algorithm rather than the model itself. Based on our analysis we derive a better training setup and show empirically that it leads to faster and more robust training of GRBMs. Finally, we compare different sampling algorithms for training GRBMs and show that Contrastive Divergence performs better than training methods that use a persistent Markov chain.},
author = {Melchior, Jan and Wang, Nan and Wiskott, Laurenz},
doi = {10.1371/journal.pone.0171015},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Melchior, Wang, Wiskott - Unknown - Gaussian-binary restricted Boltzmann machines for modeling natural image statistics(2).pdf:pdf},
journal = {PLoS ONE},
number = {2},
pages = {1--24},
title = {{Gaussian-Binary Restricted Boltzmann Machines for Modeling Natural Image Statistics}},
url = {http://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0171015{\&}type=printable},
volume = {12},
year = {2017}
}
@article{Calcavecchia2014,
abstract = {We present a whole series of methods to alleviate the sign problem of the fermionic shadow wave function in the context of variational Monte Carlo. The effectiveness of our techniques is demonstrated on liquid 3 He. We found that although the variance is reduced, the gain in efficiency is restricted by the increased computational cost. Yet, this development not only extends the scope of the fermionic shadow wave function, but also facilitates highly accurate quantum Monte Carlo simulations previously thought not feasible. DOI: 10.1103/PhysRevE.90.053304 PACS number(s): 02.70.Ss, 67.30.−n, 71.15.Pd, 05.30.Fk},
author = {Calcavecchia, Francesco and Pederiva, Francesco and Kalos, Malvin H and K{\"{u}}hne, Thomas D},
doi = {10.1103/PhysRevE.90.053304},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Calcavecchia et al. - Unknown - Sign problem of the fermionic shadow wave function.pdf:pdf},
journal = {Physical Review E},
number = {5},
title = {{Sign Problem of the Fermionic Shadow Wave Function}},
url = {https://journals.aps.org/pre/pdf/10.1103/PhysRevE.90.053304},
volume = {90},
year = {2014}
}
@article{Christensson2009,
abstract = {We show that the convergence behavior of the many-body numerical diagonalization scheme for strongly interacting bosons in a trap can be significantly improved by the Lee-Suzuki method adapted from nuclear physics: One can construct an effective interaction that acts in a space much smaller than the original Hilbert space. In particular for short-ranged forces and strong correlations, the method offers a good estimate of the energy and the excitation spectrum, at a computational cost several orders of magnitude smaller than that required by the standard method. The many-body problem of interacting bosons or fermi-ons poses a continuous challenge for quantum physics. The complexity of the quantum states increases quickly with higher particle numbers or stronger correlations, making it essentially impossible to solve the many-body problem ex-actly. Thus mean-field methods are often applied, being nu-merically much less demanding than any attempt to diago-nalize the many-body Hamiltonian. Examples are the Gross-Pitaevskii approach for trapped bosons ͓1–3͔, or the celebrated Kohn-Sham equations ͓4,5͔ for fermions, as often used in the local ͑spin͒ density approximation. However, these methods can treat correlations only in an approximate way, and are proven insufficient for strong interactions be-tween the particles. Quantum Monte Carlo calculations pro-vide an alternative approach in many cases ͑see, for example, the review by Harju ͓6͔͒, but have other drawbacks, such as limited accessibility of the excitation spectrum, a problem shared by the other methods. The development of alternative diagonalization methods such as, e.g., coupled cluster meth-ods ͓7͔ is an urgent issue. Facing the above problems with strong interactions, one quickly realizes that often, the only method of choice is the straightforward numerical diagonalization of the many-body Hamiltonian. In fact, this has been tried for a large variety of physical problems, ranging from nuclear structure ͑see, for example, the review by Caurier et al. ͓8͔͒ and quantum chemistry to artificially made quantum systems such as me-tallic clusters ͓9͔ and quantum dots ͓10͔. However, with in-creasing particle number or stronger interactions between the particles, the number of basis states needed for an accurate description of the many-body quantum system increases be-yond computational reach. Truncations of Hilbert space be-come necessary—but often, for the reduced basis, the results are too inaccurate ͓11͔. In nuclear physics, a significant step forward has been achieved by applying the Lee-Suzuki method ͓12,13͔, that prescribes unitary transformations on operators ͑e.g., the Hamiltonian͒ to obtain effective operators within the reduced basis space. This method has been successfully used in so called no-core shell model calculations, for example, where nuclear systems with ϳ12 fermions have been studied ͓14͔. Since the experimental realization of Bose-Einstein con-densation with cold, trapped atoms, much interest turned to the physics of harmonically confined many-boson systems. Although the trapping potentials today confine thousands of bosons, the few-body regime does not seem to be impossible to reach, having in mind also the recent advances with opti-cal lattices ͓15͔. Increasing technological expertise with Bose-Einstein condensates " on chips " ͓16͔, together with the newly emerging research area of " atomtronics " ͓17͔, makes the need for further theoretical developments for a descrip-tion of cold-atom gases with strong correlations an urgent issue. In this paper, we apply the Lee-Suzuki method—to the best of our knowledge, for the first time—to a system of harmonically trapped spinless bosons with short-ranged re-pulsive interactions. The fact that the Lee-Suzuki method works very well for the strong short-ranged interactions be-tween the nucleons encourages its application to describe cold atom gases beyond mean field. At this point we note that there exist alternative ways of doing the unitary transformation. Two examples, so called renormalization group transformations, are " V low−k " ͓18͔ and SRG ͑similarity renormalization group͒ ͓19͔. SRG is fre-quently used in nuclear physics ͓20͔. Another example, re-lated to SRG, is UCOM ͑unitary correlation operator method͒ ͓21͔. In future studies, it would be interesting to try alternative methods for the problem at hand, but here we have focused on the Lee-Suzuki transformation. Another study which applies the Lee-Suzuki transformation on a non-nuclear system is ͓22͔, in which the two-electron problem in a quantum dot is examined. Also, in ͓23,24͔ the few-body problem of a trapped Fermi gas is investigated with tech-niques similar to what is used here. For an ultracold gas of neutral atoms, the interaction be-tween the particles can often be modeled by a short-range potential. We choose to use a Gaussian distribution function parametrized by a range ␴, and a strength coefficient g. We here let the system be ͑quasi-͒ two-dimensional. The Hamil-tonian is},
annote = {Bosons},
author = {Christensson, J and Forss{\'{e}}n, C and {\AA}berg, S and Reimann, S M},
doi = {10.1103/PhysRevA.79.012707},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Christensson et al. - Unknown - Effective-interaction approach to the many-boson problem.pdf:pdf},
journal = {Physical Review A},
number = {1},
pages = {012707},
title = {{Effective-interaction approach to the many-boson problem}},
url = {https://journals.aps.org/pra/pdf/10.1103/PhysRevA.79.012707},
volume = {79},
year = {2009}
}
@article{Langley2011,
abstract = {Machine Learning saw its first issues appear in 1986. Naturally, the publication did not spring fully grown from its founders' brows; we laid the first plans in 1983, during the Sec-ond International Workshop on Machine Learning at Allerton House, Illinois. My partners in crime were Ryszard Michalski, Jaime Carbonell, and Tom Mitchell, who had organized the first two workshops and who had edited the book based on the initial event (Michalski et al. 1983). The reasons for launching a new journal were familiar ones. The first workshop in 1980 at Carnegie-Mellon University had identified a community of researchers with common interests in computational approaches to learning and arrived at a name for its activities. Moreover, the parent fields of artificial intelligence and cognitive science were showing little interest at the time in learning-related issues, preferring to focus on the role of knowledge in intelligence, regardless of its origin. As a result, we encountered some difficulty publishing and, more generally, felt we were not getting the attention we deserved. Finally, there was the common urge of young, energetic researchers to create something of their own to which they could attach their names. At least that was part of my own motivation; I cannot speak for my co-founders. Our group agreed that the new field needed a journal, and we also decided that I would be the first Executive Editor, with the other three serving as Editors. In 1984, I moved from Carnegie-Mellon University to the University of California, Irvine, where I received depart-ment support for the enterprise and set up an editorial office. We began to explore publishers, eventually settled on Kluwer, and started to solicit submissions. We made many decisions in those early days, from selecting an initial editorial board to determining the publication's size and format 1 that I cannot detail here. 1 I recommended that the journal have a green cover, but I did not propose the pea green shade that Kluwer ultimately selected. 276 Mach Learn (2011) 82: 275–279 More importantly, I began to think about what it would mean for an article to make a genuine contribution to machine learning. Between 1984 and 1990, when I turned over the executive editorship to Jaime Carbonell, I formed a number of opinions about these issues, some of which readers will find in editorials (e.g., Langley 1986, 1987, 1989) contained in the journal's early volumes. One requirement was that authors should specify their learning task and their learning method clearly enough to allow replication, with pseudocode being a useful means to that end. I also worked with authors, sometimes more than they desired, to make their articles transparent to readers. In the remainder of this essay, I will focus on two key changes I encouraged during my editorship that I believe were beneficial to the field and on some unexpected side effects that I feel have been far less desirable. This will involve contrasting the state of machine learning in the mid-1980s with that in later periods, including the present. I will assume that many readers have little knowledge of the field's origins or how it reached its current state, and I hope they will find my observations about its history informative and thought provoking. First, early research on machine learning adopted an informal approach to evaluation. Pa-pers typically reported runs of learning methods on a small set of training cases or problems, the outputs of these runs, and arguments for why the latter were reasonable or desirable re-sults. This was appropriate in the field's initial days, when it was still demonstrating that machine learning was possible in any form. However, experience with reviewing submis-sions to the journal led a few of us to believe it was time for more formal approaches to evaluation. My discussions on this topic with Dennis Kibler, who was also at UCI, were especially productive. The central idea, already proposed by Simon (1983), was that the purpose of learning is to improve performance on some class of tasks. In this view, it made little sense to describe a learning method in the absence of some performance system that utilized the acquired knowledge. Different performance measures would be appropriate for distinct tasks (e.g., accuracy for classification or efficiency for problem solving), but it seemed that such metrics were always possible and that many claims about learning could be linked to them. Of course, one could approach this idea in different ways. Some formal treatments were already available, but they typically focused on worst-case analyses. Another option was to compare a system's error rates or reaction times to those obtained in psychological studies, but most researchers were interested in demonstrating functionality rather than in fitting such data. Nevertheless, the empirical methods used in psychology suggested ways to design and run controlled experiments with learning systems. Kibler and Langley (1988) laid out a framework for such an experimental science of machine learning, including examples from the emerging literature in this area. Many authors adopted this perspective and, within a few years, the vast majority of Machine Learning articles reported experimental results about performance improvement on well-defined tasks. The experimental movement was aided by another development. David Aha, then a PhD student at UCI, began to collect data sets for use in empirical studies of machine learning. This grew into the UCI Machine Learning Repository (http://archive.ics.uci.edu/ml/), which he made available to the community by FTP in 1987. This was rapidly adopted by many researchers because it was easy to use and because it let them compare their results to previ-ous findings on the same tasks. The Repository focused on supervised concept learning for classification, but this was already a topic of widespread interest and it proved attractive to many in the field. The early movement in machine learning was also characterized by an emphasis on 'sym-bolic' representations of learned knowledge, such as production rules, decision trees, and logical formulae. In fact, the original call for papers to Machine Learning, which I au-thored, explicitly welcomed submissions on these topics but discouraged papers on neural},
author = {Langley, Pat},
doi = {10.1007/s10994-011-5242-y},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Langley, Langley - 2011 - The changing science of machine learning.pdf:pdf},
journal = {Machine Learning},
number = {3},
pages = {275--279},
title = {{The Changing Science of Machine Learning}},
url = {https://link.springer.com/content/pdf/10.1007{\%}2Fs10994-011-5242-y.pdf},
volume = {82},
year = {2011}
}
@unpublished{Vanderwerken2013,
abstract = {SUMMARY 5 Markov chain Monte Carlo is an inherently serial algorithm. Although likelihood calculations for individual steps can sometimes be parallelized, the serial evolution of the process is widely viewed as incompatible with parallelization, offering no speedup for samplers which require large numbers of iterations to converge to equilibrium. We provide a methodology for paralleliz-ing Markov chain Monte Carlo across large numbers of independent, asynchronous processors. 10 Our approach uses a partitioning and weight estimation scheme to combine independent simula-tions run on separate processors into rigorous Monte Carlo estimates. The method is originally motivated by sampling multimodal target distributions, where we see an exponential speedup in running time. However we show that the approach is general-purpose and applicable to all Markov chain Monte Carlo simulations, and demonstrate speedups proportional to the number 15 of available processors on slowly mixing chains with unimodal target distributions. The approach is simple and easy to implement, and suggests additional directions for further research. 1. INTRODUCTION Markov chain Monte Carlo methods are the dominant computational tool in Bayesian statis-20 tics, and their emergence is commonly credited with the meteoric rise of modern Bayesian analysis. Markov chain Monte Carlo renders computationally tractable many important applied Bayesian analyses that were analytically intractable, and therefore impractical, 25 years ago. However, the ensuing spread of Bayesian statistical modeling has led to new computational challenges for Bayesians, as models become more complex and higher-dimensional, and both 25 parameter sets and data sets become orders of magnitude larger. Additionally, the computing world has changed: the steady march of Moore's law -the ex-ponential growth in processor speeds that has continually expanded the applicability of Markov chain methods -is gone. Computer manufacturers have shifted from a model of increasingly faster CPUs to one of growing parallelism: multi-core platforms, cluster computing, and the 30 massive parallelism of GPUs. Unfortunately, Markov chain Monte Carlo is an inherently se-rial process: reliance on iterative convergence to equilibrium and long-run averages means that the n steps of a Markov chain cannot be computed in parallel because step i depends on steps 1, . . . , i − 1. Although some effort has been put into parallelizing individual Markov chain steps, the simulation of chains requiring large numbers of iterations to converge is generally viewed as 35 unparallelizable. Running multiple chains in parallel does not lead to significant speedups when convergence is slow, since each must be run long enough to equilibrate (Geyer, 1992). Similar arguments apply to other dynamical simulation problems where interest is in the equilibrium behavior of systems with relaxation times, such as molecular dynamics simulation.},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.7479v1},
author = {Vanderwerken, D N and Schmidler, S C},
eprint = {arXiv:1312.7479v1},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Vanderwerken, Schmidler - 2013 - arXiv1312.7479v1 stat.CO 28 Dec 2013.pdf:pdf},
keywords = {Adaptive Markov chain Monte Carlo,Langevin diffusion,Parallel computing,Some key words},
series = {arXiv.org},
title = {{Parallel Markov Chain Monte Carlo}},
url = {https://arxiv.org/pdf/1312.7479.pdf},
year = {2013}
}
@incollection{Lee2008,
abstract = {Motivated in part by the hierarchical organization of the cortex, a number of al-gorithms have recently been proposed that try to learn hierarchical, or " deep, " structure from unlabeled data. While several authors have formally or informally compared their algorithms to computations performed in visual area V1 (and the cochlea), little attempt has been made thus far to evaluate these algorithms in terms of their fidelity for mimicking computations at deeper levels in the cortical hier-archy. This paper presents an unsupervised learning model that faithfully mimics certain properties of visual area V2. Specifically, we develop a sparse variant of the deep belief networks of Hinton et al. (2006). We learn two layers of nodes in the network, and demonstrate that the first layer, similar to prior work on sparse coding and ICA, results in localized, oriented, edge filters, similar to the Gabor functions known to model V1 cell receptive fields. Further, the second layer in our model encodes correlations of the first layer responses in the data. Specifically, it picks up both colinear (" contour ") features as well as corners and junctions. More interestingly, in a quantitative comparison, the encoding of these more complex " corner " features matches well with the results from the Ito {\&} Komatsu's study of biological V2 responses. This suggests that our sparse variant of deep belief networks holds promise for modeling more higher-order features.},
annote = {Training GB-RBM known to be hard, this article proposes modifications to improve it (Melchior2017).

Several modifications to GB-RBM proposed to overcome training difficulties, this article added a sparseness penalty on the gradient that forced the model to prefer sparse representations and seems to help learning meaningful features (Melchior2012)},
author = {Lee, Honglak and Ekanadham, Chaitanya and Ng, Andrew Y.},
booktitle = {Advances in Neural Information Processing Systems 20},
editor = {Platt, J. C. and Koller, D. and Singer, Y. and Roweis, S. T.},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Lee, Ekanadham, Ng - Unknown - Sparse deep belief net model for visual area V2.pdf:pdf},
pages = {873--880},
publisher = {Curran Associates, Inc.},
title = {{Sparse Deep Belief Net Model for Visual Area V2}},
url = {https://papers.nips.cc/paper/3313-sparse-deep-belief-net-model-for-visual-area-v2.pdf},
year = {2008}
}
@article{Lester2009,
abstract = {a b s t r a c t The quantum Monte Carlo (QMC) method has become increasingly important for solution of the station-ary Schr{\"{o}}dinger equation for atoms, molecules and solids. The method has been shown to exhibit high accuracy that scales better with system size than other ab initio methods. Moreover, as typically imple-mented, QMC takes full advantage of parallel computing systems. These attributes for electronic structure calculations will be described, as well as recent applications that demonstrate the breadth of the QMC approach.},
author = {Lester, William A and Mitas, Lubos and Hammond, Brian},
doi = {10.1016/j.cplett.2009.06.095},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Lester, Mitas, Hammond - 2009 - Quantum Monte Carlo for Atoms, Molecules and Solids.pdf:pdf},
journal = {Chemical Physics Letters},
number = {1-3},
pages = {1--10},
title = {{Quantum Monte Carlo for Atoms, Molecules and Solids}},
url = {https://ac.els-cdn.com/S0009261409008033/1-s2.0-S0009261409008033-main.pdf?{\_}tid=380f897a-e97b-4122-9816-57ace06ffe1b{\&}acdnat=1526766031{\_}5dd7b3ed639f1b8b2672d60b49156841},
volume = {478},
year = {2009}
}
@phdthesis{Mork2016,
author = {M{\o}rk, H{\aa}kon Bakke},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Sebastian, M{\o}rk - 2016 - QUANTUM MONTE CARLO STUDIES OF MANY-ELECTRON SYSTEMS.pdf:pdf},
school = {University of Oslo},
title = {{Quantum Monte Carlo Studies of Many-Electron Systems}},
type = {MSc thesis},
url = {https://www.duo.uio.no/bitstream/handle/10852/52486/Masteroppgave.pdf?sequence=1},
year = {2016}
}
@article{Gao2017,
abstract = {Part of the challenge for quantum many-body problems comes from the difficulty of representing large-scale quantum states, which in general requires an exponentially large number of parameters. Neural networks provide a powerful tool to represent quantum many-body states. An important open question is what characterizes the representational power of deep and shallow neural networks, which is of fundamental interest due to the popularity of deep learning methods. Here, we give a proof that, assuming a widely believed computational complexity conjecture, a deep neural network can efficiently represent most physical states, including the ground states of many-body Hamiltonians and states generated by quantum dynamics, while a shallow network representation with a restricted Boltzmann machine cannot efficiently represent some of those states.},
author = {Gao, Xun and Duan, Lu-Ming},
doi = {10.1038/s41467-017-00705-2},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Gao, Duan - Unknown - Efficient representation of quantum many-body states with deep neural networks.pdf:pdf},
journal = {Nature communications},
number = {1},
pages = {662},
title = {{Efficient representation of quantum many-body states with deep neural networks}},
url = {https://www.nature.com/articles/s41467-017-00705-2.pdf},
volume = {8},
year = {2017}
}
@inproceedings{Umrigar1999,
abstract = {The two ingredients of variational Monte Carlo, viz., the Metrop-olis method for sampling any known probability distribution and the vari-ance minimization method for optimizing trial wavefunctions are discussed. General issues, related to the eeciency of the methods, such as the choice of the Metropolis proposal matrix, are emphasised. The ideas are illustrated by examples from electronic structure calculations of atoms and molecules.},
annote = {God p{\aa} markov process biten, samt g{\aa}r litt i detalj p{\aa} oppdatere partikler sekvensielt vs randomly (s 137-138)

Snakker om hvordan ting g{\aa}r som N, og sammnligning til quadrature metoder.

G{\aa}r ogs{\aa} inn p{\aa} alle partikler eller en eller et hvilket som helst antall av gangen:

"Finally we note that although each of the ab ove algorithms assumes that all the electrons are moved during each Monte Carlo up date it is trivial to mo dify the algorithms to move only one electron at each Monte Carlo step or in fact any numb er in between" p.141.

De viser ogs{\aa} begge versjonene i grafer. Diskuterer autocorrelation, hvordan vurdere 'suksess'. Og referer det at 1 partikkel bedre enn alle er vist i (Ceperley1977).},
author = {Umrigar, C J},
booktitle = {Quantum Monte Carlo Methods in Physics and Chemistry},
editor = {Umrigar, C J and Nightingale, M P},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Umrigar - Unknown - VARIATIONAL MONTE CARLO BASICS AND APPLICATIONS TO ATOMS AND MOLECULES.pdf:pdf},
publisher = {NATO Adv Study Inst; Natl Sci Fdn; Ctr Europeen Calcul Atom Molec; Cornell Univ},
title = {{Variational Monte Carlo Basics and Applications to Atoms and Molecules}},
url = {http://www.phys.uri.edu/nigh/QMC-NATO/webpage/abstracts/umrigar.ps},
year = {1999}
}
@article{Calcavecchia2015,
abstract = {PACS 02.70.Ss – Quantum Monte Carlo methods PACS 31.15.vn – Electron correlation calculations for diatomic molecules PACS 71.15.-m – Methods of electronic structure calculations Abstract – We demonstrate that extending the shadow wave function to fermionic systems facilitates to accurately calculate strongly correlated multi-reference systems such as the stretched H2 molecule. This development considerably extends the scope of electronic-structure calcula-tions and enables to efficiently recover the static correlation energy using just a single Slater determinant.},
author = {Calcavecchia, Francesco and K{\"{u}}hne, Thomas D},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Calcavecchia et al. - 2015 - On fermionic shadow wave functions for strongly correlated multi-reference systems based on a single Slater.pdf:pdf},
journal = {Europhysics Letters},
number = {2},
title = {{On Fermionic Shadow Wave Functions for Strongly Correlated Multi-Reference Systems Based on a Single Slater Determinant}},
url = {www.epljournal.org},
volume = {110},
year = {2015}
}
@book{Kalos2008,
author = {Kalos, Malvin H. and Whitlock, Paula A.},
edition = {Second, Re},
file = {:Users/Vilde/Downloads/MonteCarloMethods.pdf:pdf},
isbn = {978-3-527-40760-6},
publisher = {WILEY-VCH Verlag GmbH {\&} Co.},
title = {{Monte Carlo Methods}},
year = {2008}
}
@misc{AlexiaJolicoeur-Martineau,
author = {{Alexia Jolicoeur-Martineau}},
title = {{Meow Generator}},
url = {https://ajolicoeur.wordpress.com/cats/},
urldate = {2018-06-26}
}
@article{Lonardoni2018,
abstract = {Quantum Monte Carlo methods have recently been employed to study properties of nuclei and infinite matter using local chiral effective-field-theory interactions. In this work, we present a detailed description of the auxiliary field diffusion Monte Carlo algorithm for nuclei in combination with local chiral two-and three-nucleon interactions up to next-to-next-to-leading order. We show results for the binding energy, charge radius, charge form factor, and Coulomb sum rule in nuclei with 3 A 16. Particular attention is devoted to the effect of different operator structures in the three-body force for different cutoffs. The outcomes suggest that local chiral interactions fit to few-body observables give a very good description of the ground-state properties of nuclei up to 16 O, with the exception of one fit for the softer cutoff which predicts overbinding in larger nuclei.},
author = {Lonardoni, D and Gandolfi, S and Lynn, J E and Petrie, C and Carlson, J and Schmidt, K E and Schwenk, A},
doi = {10.1103/PhysRevC.97.044318},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Lonardoni et al. - 2018 - Auxiliary field diffusion Monte Carlo calculations of light and medium-mass nuclei with local chiral interacti.pdf:pdf},
journal = {Physical Review C},
keywords = {doi:10.1103/PhysRevC.97.044318 url:https://doi.org},
number = {4},
title = {{Auxiliary Field Diffusion Monte Carlo Calculations of Light and Medium-Mass Nuclei with Local Chiral Interactions}},
url = {https://journals.aps.org/prc/pdf/10.1103/PhysRevC.97.044318},
volume = {97},
year = {2018}
}
@article{Lutsyshyn2015,
abstract = {a b s t r a c t We present a scheme for the parallelization of quantum Monte Carlo method on graphical processing units, focusing on variational Monte Carlo simulation of bosonic systems. We use asynchronous execution schemes with shared memory persistence, and obtain an excellent utilization of the accelerator. The CUDA code is provided along with a package that simulates liquid helium-4. The program was benchmarked on several models of Nvidia GPU, including Fermi GTX560 and M2090, and the Kepler architecture K20 GPU. Special optimization was developed for the Kepler cards, including placement of data structures in the register space of the Kepler GPUs. Kepler-specific optimization is discussed. RAM: Typical execution uses as much RAM as is available on the GPU; usually between 1 GB and 12 GB. Minimal requirement is 1 MB. Classification: 4.12, 7.7. Nature of problem: QL package executes variational Monte Carlo for liquid helium-4 with Aziz II interaction potential and a Jastrow pair product trial wavefunction. Sampling is performed with a Metropolis scheme applied to single-particle updates. With minimal changes, the package can be applied to other bosonic fluids, given a pairwise interaction potential and a wavefunction in the form of a product of one-and two-body correlation factors. Solution method: The program is parallelized for execution with Nvidia GPU. By design, the generation of new configurations is performed with shared memory persistence and the asynchronous execution allows for the CPU load masking. Restrictions: Code is limited to variational Monte Carlo. Due to the limitation of the shared memory of GPU, only systems under 2000 particles can be treated on the Fermi generation cards, and up to 10000 on Kepler cards.},
author = {Lutsyshyn, Y},
doi = {10.1016/j.cpc.2014.09.016},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Lutsyshyn - 2015 - Fast quantum Monte Carlo on a GPU.pdf:pdf},
journal = {Computer Physics Communications},
keywords = {CUDA,GPU,Liquid 4He,QMC,Quantum Monte Carlo,Quantum liquid,VMC},
pages = {162--174},
title = {{Fast Quantum Monte Carlo on a GPU}},
url = {http://cpc.cs.qub.ac.uk/summaries/AEUP{\_}v1{\_}0.html http://cpc.cs.qub.ac.uk/licence/licence.html http://www.physik.uni-rostock.de/qtmps. http://dx.doi.org/10.1016/j.cpc.2014.09.016},
volume = {187},
year = {2015}
}
@article{Luchow2007,
abstract = {The fixed-node variant of the diffusion quantum Monte Carlo method ͑FN-DMC͒ is capable of obtaining the exact eigenvalues ͑albeit numerically with statistical error͒ of a many-electron Hamilton operator, provided that the nodal hypersurface of the exact wave function is given. The use of nodes of a trial wave function leads to the node location error. The authors have developed local criteria to assess the accuracy of the nodes based on the distances of the nodal hypersurfaces of ⌿ T , T⌿ T , and H⌿ T which coincide for the exact wave function. These criteria are used to develop direct optimization methods for the nodal hypersurface. The optimization of the nodes is demonstrated for simple wave functions of the Be atom and the C 2 molecule and verified with FN-DMC calculations.},
author = {L{\"{u}}chow, Arne and Petz, Ren{\'{e}} and Scott, Tony C},
doi = {10.1063/1.2716640͔},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/L{\"{u}}chow, Petz, Scott - 2007 - Direct optimization of nodal hypersurfaces in approximate wave functions On the nodal structure of single-.pdf:pdf},
journal = {The Journal of Chemical Physics},
pages = {144110},
title = {{Direct Optimization of Nodal Hypersurfaces in Approximate Wave Functions}},
url = {https://doi.org/10.1063/1.2716640 http://aip.scitation.org/toc/jcp/126/14},
volume = {126},
year = {2007}
}
@inproceedings{Mathuriya2017,
abstract = {QMCPACK has enabled cutting-edge materials research on supercomputers for over a decade. It scales nearly ideally but has low single-node efficiency due to the physics-based abstractions using array-of-structures objects, causing in-efficient vectorization. We present a systematic approach to transform QMCPACK to better exploit the new hard-ware features of modern CPUs in portable and maintainable ways. We develop miniapps for fast prototyping and optimiza-tions. We implement new containers in structure-of-arrays data layout to facilitate vectorizations by the compilers. Fur-ther speedup and smaller memory-footprints are obtained by computing data on the fly with the vectorized routines and expanding single-precision use. All these are seamlessly in-corporated in production QMCPACK. We demonstrate upto 4.5x speedups on recent Intel {\textregistered} processors and IBM Blue Gene/Q for representative workloads. Energy consumption is reduced significantly commensurate to the speedup factor. Memory-footprints are reduced by up-to 3.8x, opening the possibility to solve much larger problems of future.},
author = {Mathuriya, Amrita and Luo, Ye and Clay, Raymond C and Benali, Anouar and Shulenburger, Luke and Kim, Jeongnim},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
doi = {10.1145/3126908.3126952},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Mathuriya et al. - 2017 - Embracing a New Era of Highly Efficient and Productive Quantum Monte Carlo Simulations.pdf:pdf},
keywords = {CPUs,QMC,optimizations,portability,vectorization},
publisher = {Association for Computing Machinery},
title = {{Embracing a New Era of Highly Efficient and Productive Quantum Monte Carlo Simulations}},
url = {https://doi.org/10.1145/3126908.3126952},
year = {2017}
}
@book{Hassani1999,
author = {Hassani, Sadri},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Hassani, Arash, Rita - Unknown - Mathematical Physics A Modem Introduction to Its Foundations.pdf:pdf},
isbn = {0-387-98579-4},
publisher = {Springer-Verlag New York},
title = {{Mathematical Physics - A Modern Introduction to Its Foundations}},
url = {http://202.38.64.11/{~}jmy/documents/ebooks/Hassani Mathematical Physics A Modem Introduction to Its Foundations - S. Hassani {\%}5B0-387-98579-4{\%}5D.pdf},
year = {1999}
}
@book{VanKampen2007,
annote = {For Fokker-Planck og Langevin
Utleder stokastiske prosesser etc men mer som en modell p{\aa} fysiske prosesser enn MCMC simuleringsmetoder.

Ch 1 Stochastic variables
Ch 2 Random events

Ch 3 Stochastic processes
1) Definition
2) Stochastic processes in physics
3) Fourier transformation of stationary processes
4) The Hierarchy of distribution functions
5) The vibrating string and random fields
6) Branching processes

Ch 4 Markov processes
1) The Markov property
2) The Chapman-Kolmogorov equation
3) Stationary Markov Processes
4) The Extraction of a subensemble
5) Markov chains
6) The Decay process

Ch 5 The Master equation
6) Har noe med detailed balance

Ch 6 One-step processes
Ch 7 Chemical reactions

Ch 8 The Fokker-Planck equation (p. 193)
1) Introduction
2) Derivation of the Fokker-Planck equation
3) Brownian motion
4) The Rayleigh particle
5) Application to one-step processes
6) The multivariate Fokker-Planck equation
7) Kramers' equation


Ch 9 The Langevin approach (p. 219)
1) Langevin treatment of Brownian motion
2) Applications
3) Relation to Fokker-Planck equation
4) The Langevin approach
5) Discussion of the Ito-Stratonovich dilemma
6) Non-Gaussian white noise
7) Colored noise

Ch 10 The expansion of the master equation
Ch 11 The diffusion type 
Ch 12 First-passage problems
Ch 13 Unstable systems
Ch 14 Fluctuations in continuous systems
Ch 15 The statistics of jump events
Ch 16 Stochastic differential equations
Ch 17 Stochastic behavior of quantum systems},
author = {{Van Kampen}, N. G.},
edition = {3rd},
file = {:Users/Vilde/Downloads/N.G.-Van-Kampen-Auth.-Stochastic-Processes-in-Physics-and-Chemistry.pdf:pdf},
isbn = {978-0444529657},
publisher = {North Holland},
title = {{Stochastic Processes in Physics and Chemistry}},
year = {2007}
}
@book{Hammond1994,
author = {Hammond, B. L. and {Lester Jr}, W. A. and Reynolds, P. J.},
booktitle = {World Scientific Lecture and Course Notes in Chemistry —},
file = {:Users/Vilde/Downloads/(Exposicion) Bl Hammond-Monte Carlo Methods In Ab Initio Quantum Chemistry-Wspc (1994).pdf:pdf},
isbn = {9810203217},
publisher = {World Scientific Publishing Co. Pte. Ltd.},
title = {{Monte Carlo Methods in Ab Initio Quantum Chemistry}},
year = {1994}
}
@unpublished{Carleo2018,
abstract = {We develop a constructive approach to generate artificial neural networks representing the exact ground states of a large class of many-body lattice Hamiltonians. It is based on the deep Boltzmann machine architecture, in which two layers of hidden neurons mediate quantum correlations among physical degrees of freedom in the visible layer. The approach reproduces the exact imaginary-time Hamiltonian evolution, and is completely deterministic. In turn, compact and exact network representations for the ground states are obtained without stochastic optimization of the network parameters. The number of neurons grows linearly with the system size and total imaginary time, respectively. Physical quantities can be measured by sampling configurations of both physical and neuron degrees of freedom. We provide specific examples for the transverse-field Ising and Heisenberg models by implementing efficient sampling. As a compact, classical representation for many-body quantum systems, our approach is an alternative to the standard path integral, and it is potentially useful also to systematically improve on numerical approaches based on the restricted Boltzmann machine architecture.},
author = {Carleo, Giuseppe and Nomura, Yusuke and Imada, Masatoshi},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Carleo, Nomura, Imada - Unknown - Constructing Exact Representations of Quantum Many-Body Systems with Deep Neural Networks.pdf:pdf},
title = {{Constructing Exact Representations of Quantum Many-Body Systems with Deep Neural Networks}},
url = {https://arxiv.org/pdf/1802.09558.pdf},
year = {2018}
}
@incollection{Ohno2018,
abstract = {Since Metropolis's work , the Monte Carlo method has been applied not only to var-ious statistical problems of classical systems, but also to many quantum mechanical systems. In this chapter, we briefly describe the extension of the Monte Carlo method to quantum mechanical systems. The thermal average of a physical quantity A with respect to the quantum mechan-ical Hamiltonia H is given, in general, by A T = T A exp(H/k B T) Tr exp(H/k B T) = m m A|m exp(−E m /k B T) m exp(−E m /k B T) , (6.1) where the trace Tr denotes the sum of all the diagonal matrix elements (the expectation value) of A sandwiched between m| and |m, where |m are the eigenstates of the Hamiltonian operator and form a complete basis set. If all the eigenvalues E m and the eigenstates |m are already known as is the case for a noninteracting particle system, the Ising model of magnets, or the Einstein model for lattice vibrations, (6.1) can be evaluated exactly in the same way as in the Monte Carlo method for classical systems (or, in simple cases, one may even obtain exact solutions without using the Monte Carlo method). However, in general cases, these eigenvalues and eigenstates are not known, and (6.1) cannot be handled directly. The quantum Monte Carlo method can allow us to sample the phase space with a given distribution exp(H/k B T). This is one of the current topics in the field of Monte Carlo methods that has kept many researchers interested in them.},
author = {Ohno, Kaoru and Esfarjani, Keivan and Kawazoe, Yoshiyuki},
booktitle = {Computational Materials Science},
chapter = {6},
doi = {10.1007/978-3-662-56542-1_6},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Ohno, Esfarjani, Kawazoe - Unknown - Quantum Monte Carlo (QMC) Methods 6.1 Introduction.pdf:pdf},
pages = {339--352},
publisher = {Springer-Verlag GmbH Germany},
title = {{Quantum Monte Carlo (QMC) Methods}},
url = {https://doi.org/10.1007/978-3-662-56542-1{\_}6},
year = {2018}
}
@misc{Jung2015,
author = {{Alexander Jung}},
title = {{Neural Network learning to generate cat images (model G32up-c) - YouTube}},
url = {https://www.youtube.com/watch?v=JRBscukr7ew{\&}feature=youtu.be},
urldate = {2018-06-26},
year = {2015}
}
@article{Giner2016,
abstract = {We explore the use in quantum Monte Carlo (QMC) of trial wave functions consisting of a Jas-trow factor multiplied by a truncated configuration-interaction (CI) expansion in Slater determinants obtained from a CI perturbatively selected iteratively (CIPSI) calculation. In the CIPSI algorithm, the CI expansion is iteratively enlarged by selecting the best determinants using the perturbation theory, which provides an optimal and automatic way of constructing truncated CI expansions approach-ing the full CI limit. We perform a systematic study of variational Monte Carlo (VMC) and fixed-node diffusion Monte Carlo (DMC) total energies of first-row atoms from B to Ne with different levels of opti-misation of the parameters (Jastrow parameters, coefficients of the determinants, and orbital param-eters) in these trial wave functions. The results show that the reoptimisation of the coefficients of the determinants in VMC (together with the Jastrow factor) leads to an important lowering of both VMC and DMC total energies, and to their monotonic convergence with the number of determinants. In addition, we show that the reoptimisation of the orbitals is also important in both VMC and DMC for the Be atom when using a large basis set. These reoptimised Jastrow-CIPSI wave functions appear as promising, systematically improvable trial wave functions for QMC calculations.},
author = {Giner, Emmanuel and Assaraf, Roland and Toulouse, Julien},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Giner, Assaraf, Toulouse - Unknown - Quantum Monte Carlo with reoptimised perturbatively selected configuration-interaction wave functio.pdf:pdf},
journal = {Molecular Physics},
keywords = {Configuration interaction,fixed node diffusion Monte Carlo,perturbation theory,quantum Monte Carlo},
number = {7-8},
pages = {910--920},
title = {{Quantum Monte Carlo with Reoptimised Perturbatively Selected Configuration-Interaction Wave Functions}},
url = {http://dx.doi.org/./..},
volume = {114},
year = {2016}
}
@book{Chaichian2001,
author = {Chaichian, M. and Demichev, A.},
file = {:Users/Vilde/Downloads/M. Chaichian, A. Demichev-Path integrals in physics. Stochastic processes and quantum mechanics. Volume 1-Taylor {\&} Francis (2001).pdf:pdf},
isbn = {0-7503-0801-X},
publisher = {IOP Publishing Ltd},
title = {{Path Integrals in Physics Volume I Stochastic Processes and Quantum Mechanics}},
year = {2001}
}
@article{Nilsen2007,
abstract = {We present a cross-language C++/Python program for simulations of quantum mechanical systems with the use of Quantum Monte Carlo (QMC) methods. We describe a system for which to apply QMC, the algorithms of variational Monte Carlo and diffusion Monte Carlo and we describe how to implement theses methods in pure C++ and C++/Python. Furthermore we check the efficiency of the implementations in serial and parallel cases to show that the overhead using Python can be negligible.},
author = {Nilsen, Jon K},
doi = {10.1016/j.cpc.2007.06.013},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Jon, Nilsen - 2007 - MontePython Implementing Quantum Monte Carlo using Python.pdf:pdf},
journal = {Computer Physics Communications},
pages = {799--814},
title = {{MontePython: Implementing Quantum Monte Carlo using Python}},
url = {www.elsevier.com/locate/cpc http://cpc.cs.qub.ac.uk/summaries/ADZP{\_}v1{\_}0.html http://cpc.cs.qub.ac.uk/licence/licence.html},
volume = {177},
year = {2007}
}
@article{Dubois,
abstract = {We investigate the properties of hard-core bosons in harmonic traps over a wide range of densities. Bose-Einstein condensation is formulated using the one-body density matrix ͑OBDM͒ which is equally valid at low and high densities. The OBDM is calculated using diffusion Monte Carlo methods and it is diagonalized to obtain the ''natural'' single-particle orbitals and their occupation, including the condensate fraction. At low boson density, na 3 Ͻ10 Ϫ5 , where nϭN/V and a is the hard-core diameter, the condensate is localized at the center of the trap. As na 3 increases, the condensate moves to the edges of the trap. At high density, it is localized at the edges of the trap. At na 3 р10 Ϫ4 , the Gross-Pitaevskii theory of the condensate describes the whole system within 1{\%}. At na 3 Ϸ10 Ϫ3 , corrections are 3{\%} to the Grass-Pitaevskii energy but 30{\%} to the Bogoliubov prediction of the condensate depletion. At na 3 տ10 Ϫ2 , mean-field theory fails. At na 3 տ0.1, the bosons behave more like a liquid 4 He droplet than a trapped boson gas.},
annote = {Using QMC for studies of Bose-Einstein condensates of dilute atomic gases (bosonic systems) (Nilsen2007)

Example of successful use of the hard core boson interaction potential (Nilsen2007).},
author = {Dubois, J L and Glyde, H R},
doi = {10.1103/PhysRevA.68.033602},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Dubois, Glyde - Unknown - Natural orbitals and Bose-Einstein condensates in traps A diffusion Monte Carlo analysis.pdf:pdf},
journal = {Physical Review A},
title = {{Natural Orbitals and Bose-Einstein Condensates in Traps: A Diffusion Monte Carlo Analysis}},
url = {https://journals.aps.org/pra/pdf/10.1103/PhysRevA.68.033602},
volume = {68},
year = {2003}
}
@book{Gilks1996,
author = {Gilks, W R and Richardson, S and Spiegelhalter, D J},
file = {:Users/Vilde/Downloads/FirstChapter.pdf:pdf},
isbn = {0 412 05551 1},
publisher = {Chapman {\&} Hall},
title = {{Markov Chain Monte Carlo in Practice}},
url = {https://www.scribd.com/document/82606001/Markov-Chain-Monte-Carlo-in-Practice-W-R-Gilks-S-Richardson-D-J-Spiegelhalter},
year = {1996}
}
@phdthesis{Lawrie2011,
abstract = {A commonly adopted relational account of time evolution in generally covariant systems, and more specifically in quantum cosmology, is argued to be unsatisfactory, insofar as it describes evolution relative to observed readings of a clock that does not exist as a bona fide observable object. A modified strategy is proposed, in which evolution relative to the proper time that elapses along the worldline of a specific observer can be described through the introduction of a “test clock,” regarded as internal to, and hence unobservable by, that observer. This strategy is worked out in detail in the case of a homogeneous cosmology, in the context of both a conventional Schr{\"{o}}dinger quantization scheme, and a “polymer” quantization scheme of the kind inspired by loop quantum gravity. Particular attention is given to limitations placed on the observability of time evolution by the requirement that a test clock should contribute only a negligible energy to the Hamiltonian constraint. It is found that suitable compromises are available, in which the clock energy is reasonably small, while Dirac observables are reasonably sharply defined.},
archivePrefix = {arXiv},
arxivId = {1011.4444},
author = {Skattum, Sigve B{\o}e},
doi = {10.1103/PhysRevD.83.043503},
eprint = {1011.4444},
file = {:Users/Vilde/Downloads/master-2.pdf:pdf},
issn = {1550-7998},
school = {University of Oslo},
title = {{Time Evolution in Quantum Dots: Using the Multiconfiguration Time-Dependent Hartree-Fock Method}},
type = {MSc thesis},
url = {https://link.aps.org/doi/10.1103/PhysRevD.83.043503},
year = {2013}
}
@inproceedings{Wang2012,
abstract = {A Gaussian-binary restricted Boltzmann machine is a widely used energy-based model for continuous data distributions, although many authors reported difficulties in training on natural images. To clarify the model's capabilities and limitations we derive a rewritten formula of the probability density function as a linear superposition of Gaussians. Based on this formula we show how Gaussian-binary RBMs learn natural image statistics. However the probability density function of the model is not a good representation of the data distribution.},
annote = {Several studies have shown the failures of GRBMs empirically, but to our knowledge there is no analysis of GRBMs apart from this preliminary work which accounts the reasons behind these failiures. (Melchior2017).

RBMs difficult to train, this even more critical when using GB-RBMs. (Melchior2012)

We are able to derive a more intuitive formulation of the marginal PDF P(x) of the GB-RBM using the Bayes'theorem and the polynomial expansion as proposed in this article. (Melchior2012)},
author = {Wang, Nan and Melchior, Jan and Wiskott, Laurenz},
booktitle = {Proceedings of the 20th European Symposium on Artifical Neural Networks, Computational Intelligence and Machine Learning},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Wang, Melchior, Wiskott - Unknown - An Analysis of Gaussian-Binary Restricted Boltzmann Machines for Natural Images.pdf:pdf},
pages = {287--292},
publisher = {ESANN},
title = {{An Analysis of Gaussian-Binary Restricted Boltzmann Machines for Natural Images}},
url = {https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2012-95.pdf},
year = {2012}
}
@article{Scemama2016,
abstract = {An algorithm to compute efficiently the first two derivatives of (very) large multideterminant wavefunctions for quantum Monte Carlo calculations is presented. The trial wavefunction being written as a sum of determinants, the computational time needed at each Monte Carlo step is expected to scale linearly in the number of determinants. In this work, we express the multideterminant expansion as a bilinear form in terms of the spin-specific determinants and show that the cost of the leading O{\$}(N{\_}{\{}\backslashrm det{\}}){\$} contribution ({\$}N{\_}{\{}\backslashrm det{\}}{\$}, total number of determinants) can be greatly reduced. In practical applications, it is so reduced that it has been found to have a marginal impact in the total computational cost, at least up to one million of determinants. The practical scaling is thus proportional to the number of spin-specific determinants of order {\$}O(\backslashsqrt{\{}N{\_}{\{}\backslashrm det{\}}{\}}){\$}. The calculation of determinants is performed by using the Sherman-Morrison formula. Introducing a suitably chosen encoding and ordering of the determinants, the number of row substitutions can be reduced, thus accelerating further the calculations. Finally, a new truncation scheme for the multideterminant expansion is proposed so that larger expansions can be considered without increasing the computational time. The algorithm is illustrated with all-electron Fixed-Node Diffusion Monte Carlo calculations of the total energy of the chlorine atom. Calculations using a trial wavefunction including about 750{\~{}}000 determinants with a computational increase of {\$}\backslashsim{\$} 400 compared to a single-determinant calculation are shown to be feasible.},
archivePrefix = {arXiv},
arxivId = {1510.00730},
author = {Scemama, Anthony and Applencourt, Thomas and Giner, Emmanuel and Caffarel, Michel},
doi = {10.1002/jcc.24382},
eprint = {1510.00730},
file = {:Users/Vilde/Downloads/Scemama{\_}et{\_}al-2016-Journal{\_}of{\_}Computational{\_}Chemistry.pdf:pdf},
issn = {1096987X},
journal = {Journal of Computational Chemistry},
keywords = {configuration interaction,fixed-node diffusion Monte Carlo,large multideterminant wavefunction,quantum Monte Carlo},
number = {20},
pages = {1866--1875},
pmid = {27302337},
title = {{Quantum Monte Carlo with very large multideterminant wavefunctions}},
volume = {37},
year = {2016}
}
@article{PedersenLohne2011,
abstract = {We perform coupled - cluster and diffusion Monte Carlo calculations of the energies of circular quantum dots up to 20 electrons . The coupled - cluster calculations include triples corrections and a renormalized Coulomb interaction defined for a given number of low - lying oscillator shells . Using such a renormalized Coulomb interaction brings the coupled - cluster calculations with triples correlations in excellent agreement with the diffusion Monte Carlo calculations . This opens up perspectives for doing ab initio calculations for much larger systems of electrons .},
author = {{Pedersen Lohne}, M and Hagen, G and Hjorth-Jensen, M and Kvaal, S and Pederiva, F},
doi = {10.1103/PhysRevB.84.115302},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Lohne et al. - 2011 - Ab initio computation of the energies of circular quantum dots.pdf:pdf},
journal = {Physical Review B},
pages = {115302},
title = {{Ab Initio Computation of the Energies of Circular Quantum Dots}},
url = {https://journals.aps.org/prb/pdf/10.1103/PhysRevB.84.115302},
volume = {84},
year = {2011}
}
@techreport{Osogami2017,
abstract = {We review Boltzmann machines and energy-based models. A Boltzmann machine defines a probability distribution over binary-valued patterns. One can learn parameters of a Boltzmann machine via gradient based approaches in a way that log likelihood of data is increased. The gradient and Laplacian of a Boltzmann machine admit beautiful mathematical representations, although computing them is in general intractable. This intractability motivates approximate methods, including Gibbs sampler and contrastive divergence, and tractable alternatives, namely energy-based models.},
address = {Tokyo},
annote = {A review. Necessity of hidden units, free energy, relation to logistic regression.},
author = {Osogami, Takayuki},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Osogami - 2017 - Boltzmann Machines and Energy-Based Models.pdf:pdf},
institution = {IBM Research},
title = {{Boltzmann Machines and Energy-Based Models}},
url = {http://domino.watson.ibm.com/library/CyberDig.nsf/papers/4C2606B8355FB45585258183000644FF/{\$}File/RT0979.pdf},
year = {2017}
}
@article{Kalos1962,
abstract = {By means of a suitable Green's function, the Schrodinger equation for the few-body nuclear problem is written as an integral equation. In this equation, the binding energy of the ground state is assumed known and the strength of potential required to give this energy is an eigenvalue to be determined. A random walk can be devised whose collision density satisfies the same integral equation. The simulation of this random walk therefore permits an exact numerical solution by Monte Carlo methods. The calculation has been carried out with pairwise potentials of square, Gauss, and exponential shape.},
author = {Kalos, M H},
doi = {https://doi.org/10.1103/PhysRev.128.1791},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Kalos - 1962 - Monte Carlo Calculations of the Ground State of Three-and Four-Body Nuclei.pdf:pdf},
journal = {Physical Review},
number = {4},
title = {{Monte Carlo Calculations of the Ground State of Three-and Four-Body Nuclei}},
url = {https://journals.aps.org/pr/pdf/10.1103/PhysRev.128.1791},
volume = {128},
year = {1962}
}
@unpublished{Ruggeri2017,
abstract = {We show that the recently introduced iterative backflow renormalization can be interpreted as a general neural network in continuum space with non-linear functions in the hidden units. We use this wave function within Variational Monte Carlo for liquid 4 He in two and three dimensions, where we typically find a tenfold increase in accuracy over currently used wave functions. Furthermore, subsequent stages of the iteration procedure define a set of increasingly good wave functions, each with its own variational energy and variance of the local energy: extrapolation of these energies to zero variance gives values in close agreement with the exact values. For two dimensional 4 He, we also show that the iterative backflow wave function can describe both the liquid and the solid phase with the same functional form –a feature shared with the Shadow Wave Function, but now joined by much higher accuracy. We also achieve significant progress for liquid 3 He in three dimensions, improving previous variational and fixed-node energies for this very challenging fermionic system.},
author = {Ruggeri, Michele and Moroni, Saverio and Holzmann, Markus},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Ruggeri, Moroni, Holzmann - 2017 - Nonlinear Network description for many-body quantum systems in continuous space.pdf:pdf},
keywords = {PACS,PACS numbers},
title = {{Nonlinear Network description for many-body quantum systems in continuous space}},
url = {https://arxiv.org/pdf/1711.01993.pdf},
year = {2017}
}
@article{Ciresan2010,
abstract = {Processing Unit), training set deformations, MNIST 1 , BP (back-propagation). Abstract Good old on-line back-propagation for plain multi-layer perceptrons yields a very low 0.35{\%} error rate on the famous MNIST handwritten digits benchmark. All we need to achieve this best result so far are many hidden layers, many neurons per layer, numerous deformed training images, and graphics cards to greatly speed up learning.},
author = {Ciresan, Dan Claudiu and Meier, Ueli and Gambardella, Luca Maria and Schmidhuber, Urgen},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Cirean et al. - Unknown - Deep Big Simple Neural Nets Excel on Hand- written Digit Recognition.pdf:pdf},
journal = {Neural Computation},
keywords = {GPU (Graphics,MLP (Multilayer Perceptron),NN (Neural Network)},
number = {12},
title = {{Deep, Big, Simple Neural Nets Excel on Handwritten Digit Recognition}},
url = {https://arxiv.org/pdf/1003.0358.pdf},
volume = {22},
year = {2010}
}
@article{Ranzato2010,
abstract = {Deep belief nets have been successful in mod-eling handwritten characters, but it has proved more difficult to apply them to real images. The problem lies in the restricted Boltzmann machine (RBM) which is used as a module for learn-ing deep belief nets one layer at a time. The Gaussian-Binary RBMs that have been used to model real-valued data are not a good way to model the covariance structure of natural images. We propose a factored 3-way RBM that uses the states of its hidden units to represent abnormal-ities in the local covariance structure of an im-age. This provides a probabilistic framework for the widely used simple/complex cell architec-ture. Our model learns binary features that work very well for object recognition on the " tiny im-ages " data set. Even better features are obtained by then using standard binary RBM's to learn a deeper model.},
annote = {Training GB-RBM known to be hard, this article focused on improving the model in the view of generative models (Melchior2017).

Modified the GB-RBM such that it is capable of modelling higher order statistics directly.
(Melchior2012).},
author = {Ranzato, Marc Aurelio and Krizhevsky, Alex and Hinton, Geoffrey E},
editor = {Teh, Yee Whye and Titterington, Mike},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Ranzato, Krizhevsky, Hinton - Unknown - Factored 3-Way Restricted Boltzmann Machines For Modeling Natural Images.pdf:pdf},
journal = {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
number = {May},
pages = {621--628},
publisher = {Proceedings of Machine Learning Research},
title = {{Factored 3-Way Restricted Boltzmann Machines For Modeling Natural Images}},
url = {http://proceedings.mlr.press/v9/ranzato10a/ranzato10a.pdf},
volume = {9},
year = {2010}
}
@article{Carlson2015,
abstract = {Quantum Monte Carlo methods have proved valuable to study the structure and reactions of light nuclei and nucleonic matter starting from realistic nuclear interactions and currents. These ab initio calculations reproduce many low-lying states, moments, and transitions in light nuclei, and simultaneously predict many properties of light nuclei and neutron matter over a rather wide range of energy and momenta. The nuclear interactions and currents are reviewed along with a description of the continuum quantum Monte Carlo methods used in nuclear physics. These methods are similar to those used in condensed matter and electronic structure but naturally include spin-isospin, tensor, spin-orbit, and three-body interactions. A variety of results are presented, including the low-lying spectra of light nuclei, nuclear form factors, and transition matrix elements. Low-energy scattering techniques, studies of the electroweak response of nuclei relevant in electron and neutrino scattering, and the properties of dense nucleonic matter as found in neutron stars are also described. A coherent picture of nuclear structure and dynamics emerges based upon rather simple but realistic interactions and currents.},
author = {Carlson, J and Gandolfi, S and Pederiva, F and Pieper, Steven C and Schiavilla, R and Schmidt, K E and Wiringa, R B},
doi = {10.1103/RevModPhys.87.1067},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Carlson et al. - Unknown - Quantum Monte Carlo methods for nuclear physics.pdf:pdf},
journal = {Reviews of Modern Physics},
number = {3},
title = {{Quantum Monte Carlo Methods for Nuclear Physics}},
url = {https://journals.aps.org/rmp/pdf/10.1103/RevModPhys.87.1067},
volume = {87},
year = {2015}
}
@article{Bengio2009,
abstract = {Theoretical results suggest that in order to learn the kind of com- plicated functions that can represent high-level abstractions (e.g., in vision, language, and other AI-level tasks), one may need deep architec- tures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in com- plicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the state- of-the-art in certain areas. This monograph discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks.},
annote = {This mentions briefly that an GB-RBM can be regarded as a Mixture of Gaussians (Melchior2017)

The BM's stackability allows for constructing deep networks (Melchior2012)},
author = {Bengio, Yoshua},
doi = {10.1561/2200000006},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Bengio - 2009 - Learning Deep Architectures for AI.pdf:pdf},
journal = {Foundations and Trends{\textregistered} in Machine Learning},
number = {1},
pages = {1--127},
title = {{Learning Deep Architectures for AI}},
url = {https://www.csee.umbc.edu/courses/pub/WWW/courses/graduate/678/spring14/BengioDeep.pdf},
volume = {2},
year = {2009}
}
@unpublished{Mehta2014,
abstract = {Deep learning is a broad set of techniques that uses multiple layers of representation to automat-ically learn relevant features directly from structured data. Recently, such techniques have yielded record-breaking results on a diverse set of difficult machine learning tasks in computer vision, speech recognition, and natural language processing. Despite the enormous success of deep learning, rel-atively little is understood theoretically about why these techniques are so successful at feature learning and compression. Here, we show that deep learning is intimately related to one of the most important and successful techniques in theoretical physics, the renormalization group (RG). RG is an iterative coarse-graining scheme that allows for the extraction of relevant features (i.e. operators) as a physical system is examined at different length scales. We construct an exact map-ping from the variational renormalization group, first introduced by Kadanoff, and deep learning architectures based on Restricted Boltzmann Machines (RBMs). We illustrate these ideas using the nearest-neighbor Ising Model in one and two-dimensions. Our results suggests that deep learning algorithms may be employing a generalized RG-like scheme to learn relevant features from data. A central goal of modern machine learning research is to learn and extract important features directly from data. Among the most promising and successful tech-niques for accomplishing this goal are those associated with the emerging sub-discipline of deep learning. Deep learning uses multiple layers of representation to learn descriptive features directly from training data [1, 2] and has been successfully utilized, often achieving record breaking results, in difficult machine learning tasks in-cluding object labeling [3], speech recognition [4], and natural language processing [5]. In this work, we will focus on a set of deep learning algorithms known as deep neural networks (DNNs) [6]. DNNs are biologically-inspired graphical statistical mod-els that consist of multiple layers of " neurons " , with units in one layer receiving inputs from units in the layer be-low them. Despite their enormous success, it is still un-clear what advantages these deep, multi-layer architec-tures possess over shallower architectures with a similar number of parameters. In particular, it is still not well understood theoretically why DNNs are so successful at uncovering features in structured data. (But see [7–9].) One possible explanation for the success of DNN ar-chitectures is that they can be viewed as an iterative coarse-graining scheme, where each new high-level layer of the neural network learns increasingly abstract higher-level features from the data [1, 10]. The initial layers of the the DNN can be thought of as low-level feature de-tecters which are then fed into higher layers in the DNN which combine these low-level features into more abstract higher-level features, providing a useful, and at times re-duced, representation of the data. By successively apply-ing feature extraction, DNNs learn to deemphasize irrel-evant features in the data while simultaneously learning relevant ones. (Note that in a supervised setting, such as classification, relevant and irrelevant are ultimately determined by the problem at hand. Here we are con-cerned solely with the unsupervised aspect of training DNNs, and the use of DNNs for compression [6].) In what follows, we make this explanation precise. This successive coarse-graining procedure is reminis-cent of one of the most successful and important tools in theoretical physics, the renormalization group (RG) [11, 12]. RG is an iterative coarse-graining procedure designed to tackle difficult physics problems involving many length scales. The central goal of RG is to ex-tract relevant features of a physical system for describing phenomena at large length scales by integrating out (i.e. marginalizing over) short distance degrees of freedom. In any RG sequence, fluctuations are integrated out start-ing at the microscopic scale and then moving iteratively on to fluctuations at larger scales. Under this proce-dure, certain features, called relevant operators, become increasingly important while other features, dubbed irrel-evant operators, have a diminishing effect on the physical properties of the system at large scales. In general, it is impossible to carry out the renormal-ization procedure exactly. Therefore, a number of ap-proximate RG procedures have been developed in the theoretical physics community [12–15]. One such ap-proximate method is a class of variational " real-space " renormalization schemes introduced by Kadanoff for per-forming RG on spin systems [14, 16, 17]. Kadanoff's variational RG scheme introduces coarse-grained auxil-iary, or " hidden " , spins that are coupled to the physical spin systems through some unknown coupling parame-ters. A parameter-dependent free energy is calculated for the coarse-grained spin system from the coupled system by integrating out the physical spins. The coupling pa-rameters are chosen through a variational procedure that minimizes the difference between the free energies of the physical and hidden spin systems. This ensures that the coarse-grained system preserves the long-distance infor-mation present in the physical system. Carrying out this},
archivePrefix = {arXiv},
arxivId = {arXiv:1410.3831v1},
author = {Mehta, Pankaj and Schwab, David J},
eprint = {arXiv:1410.3831v1},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Mehta, Schwab - 2014 - An Exact Mapping Between the Variational Renormalization Group and Deep Learning.pdf:pdf},
title = {{An Exact Mapping Between the Variational Renormalization Group and Deep Learning}},
url = {https://arxiv.org/pdf/1410.3831.pdf},
year = {2014}
}
@article{Ten-no2012,
abstract = {We summarize explicitly correlated electronic structure theory in perspective of future work in the field. Earlier stages of approaches with different Ansa¨tze in physics and chemistry are described. We then discuss recent advances focusing on explicitly correlated wave functions using cusp conditions. Removal of Coulomb singularities in terms of the rational generator is brought out from the viewpoint of many-body perturbation theory. On the basis of decomposition schemes for many-electron integrals in R12 and F12 methods, we further discuss the possibility of increasing the accuracy of molecular numerical integration and massively parallel calculations of explicitly correlated methods.},
author = {Ten-no, Seiichiro},
doi = {10.1007/s00214-011-1070-1},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - Explicitly correlated wave functions summary and perspective Seiichiro Ten-no.pdf:pdf},
journal = {Theoretical Chemistry Accounts},
keywords = {Ansatz {\'{A}},Auxiliary basis set {\'{A}},Cusp conditions {\'{A}} R12 theory {\'{A}} F12 theory {\'{A}} SP,Hybrid parallelization,Many-electron integrals {\'{A}},Numerical quadratures {\'{A}},Pseudospectral reweighting {\'{A}},Resolution of the identity {\'{A}},Slater-type geminals {\'{A}}},
number = {1},
title = {{Explicitly Correlated Wave Functions: Summary and Perspective}},
url = {https://link.springer.com/content/pdf/10.1007{\%}2Fs00214-011-1070-1.pdf},
volume = {131},
year = {2012}
}
@article{Ackley1985,
annote = {The first presentation of the Boltzmann Machine.},
author = {Ackley, David H and Hinton, Geoffrey E and Sejnowski, Terrence J},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Ackley, Hinton, Sejnowski - 1985 - A Learning Algorithm for Boltzmann Machines.pdf:pdf},
journal = {Cognitive Science},
number = {1},
pages = {147--169},
title = {{A Learning Algorithm for Boltzmann Machines}},
url = {http://csjarchive.cogsci.rpi.edu/1985v09/i01/p0147p0169/MAIN.PDF},
volume = {9},
year = {1985}
}
@article{Ghosal2007,
abstract = {We study the development of electron-electron correlations in circular quantum dots as the density is decreased. We consider a wide range of both electron number, N ഛ 20, and electron gas parameter, r s Շ 18, using the diffusion quantum Monte Carlo technique. Features associated with correlation appear to develop very differently in quantum dots than in bulk. The main reason is that translational symmetry is necessarily broken in a dot, leading to density modulation and inhomogeneity. Electron-electron interactions act to enhance this modulation ultimately leading to localization. This process appears to be completely smooth and occurs over a wide range of density. Thus there is a broad regime of " incipient " Wigner crystallization in these quantum dots. Our specific conclusions are ͑i͒ the density develops sharp rings while the pair density shows both radial and angular inhomogeneity; ͑ii͒ the spin of the ground state is consistent with Hund's ͑first͒ rule throughout our entire range of r s for all 4 ഛ N ഛ 20; ͑iii͒ the addition energy curve first becomes smoother as interactions strengthen—the mesoscopic fluctuations are damped by correlation—and then starts to show features characteristic of the classical addition energy; ͑iv͒ localization effects are stronger for a smaller number of electrons; ͑v͒ finally, the gap to certain spin excitations becomes small at the strong interaction ͑large r s ͒ side of our regime.},
annote = {Includes density plots},
author = {Ghosal, Amit and G{\"{u}}{\c{c}}l{\"{u}}, A D and Umrigar, C J and Ullmo, Denis and Baranger, Harold U},
doi = {10.1103/PhysRevB.76.085341},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Ghosal et al. - Unknown - Incipient Wigner Localization in Circular uantum Dots.pdf:pdf},
journal = {Physical Review B},
title = {{Incipient Wigner Localization in Circular Quantum Dots}},
url = {https://journals.aps.org/prb/pdf/10.1103/PhysRevB.76.085341},
volume = {76},
year = {2007}
}
@article{Torlai2017,
abstract = {The experimental realization of increasingly complex syn-thetic quantum systems calls for the development of general theoretical methods to validate and fully exploit quantum resources. Quantum state tomography (QST) aims to recon-struct the full quantum state from simple measurements, and therefore provides a key tool to obtain reliable analytics 1–3 . However, exact brute-force approaches to QST place a high demand on computational resources, making them unfeasi-ble for anything except small systems 4,5 . Here we show how machine learning techniques can be used to perform QST of highly entangled states with more than a hundred qubits, to a high degree of accuracy. We demonstrate that machine learning allows one to reconstruct traditionally challenging many-body quantities—such as the entanglement entropy— from simple, experimentally accessible measurements. This approach can benefit existing and future generations of devices ranging from quantum computers to ultracold-atom quantum simulators 6–8 . Machine learning methods have been demonstrated to be par-ticularly powerful at compressing high-dimensional data into low-dimensional representations 9,10 . Largely developed in the domain of data science, these techniques have recently been used to address fundamental questions in the domain of physical sci-ences. Applications to quantum many-body systems have been put forward in the last year, for example, to classify phases of matter 11–13 , and to simulate quantum systems 14 . QST is itself a data-driven problem, in which we aim to obtain a complete quantum-mechanical description of a system, on the basis of a limited set of experimentally accessible measurements. While compressed sensing approaches 15 reduce the experimental burden of full QST, large systems can be studied only through techniques requiring a feasible number of measurements. For example, permu-tationally invariant tomography 16 makes efficient use of the symme-tries of prototypical quantum optics states, and can be amenable to a large number of qubits. However, the general case of many-body systems is challenging for QST. In this context, matrix product states are the state-of-the-art tool for QST of low-entangled states 17,18},
author = {Torlai, Giacomo and Mazzola, Guglielmo and Carrasquilla, Juan and Troyer, Matthias and Melko, Roger and Carleo, Giuseppe},
doi = {10.1038/s41567-018-0048-5},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Torlai et al. - Unknown - Neural-network quantum state tomography.pdf:pdf},
journal = {Nature Physics},
pages = {447--450},
title = {{Neural-Network Quantum State Tomography}},
url = {https://www.nature.com/articles/s41567-018-0048-5.pdf},
volume = {14},
year = {2017}
}
@article{Courville2011,
abstract = {We introduce the spike and slab Restricted Boltzmann Machine, characterized by hav-ing both a real-valued vector, the slab, and a binary variable, the spike, associated with each unit in the hidden layer. The model possesses some practical properties such as being amenable to Block Gibbs sampling as well as being capable of generating similar latent representations of the data to the re-cently introduced mean and covariance Re-stricted Boltzmann Machine. We illustrate how the spike and slab Restricted Boltzmann Machine achieves competitive performance on the CIFAR-10 object recognition task.},
annote = {Training GB-RBM known to be hard, this article focused on improving the model in the view of generative models (Melchior2017).

Here it is mentioned briefly that a GB-RBM can be regarded as a mixture of Gaussians (Melchior2017).

Modified the GB-RBM such that it is capable of modelling higher order statistics directly.
(Melchior2012).},
author = {Courville, Aaron and Bergstra, James and Bengio, Yoshua},
editor = {Gordon, Geoffrey and Dunson, David and Dud{\'{i}}k, Miroslav},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Courville, Bergstra, Bengio - Unknown - A Spike and Slab Restricted Boltzmann Machine.pdf:pdf},
journal = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
number = {Apr},
pages = {233--241},
publisher = {Proceedings of Machine Learning Research},
title = {{A Spike and Slab Restricted Boltzmann Machine}},
url = {http://proceedings.mlr.press/v15/courville11a/courville11a.pdf},
volume = {15},
year = {2011}
}
@article{Greene2017,
abstract = {A recent rejuvenation of experimental and theoretical interest in the physics of few-body systems has provided deep, fundamental insights into a broad range of problems. Few-body physics is a cross-cutting discipline not restricted to conventional subject areas such as nuclear physics or atomic or molecular physics. To a large degree, the recent explosion of interest in this subject has been sparked by dramatic enhancements of experimental capabilities in ultracold atomic systems over the past decade, which now permit atoms and molecules to be explored deep in the quantum mechanical limit with controllable two-body interactions. This control, typically enabled by magnetic or electromagnetically dressed Fano-Feshbach resonances, allows, in particular, access to the range of universal few-body physics, where two-body scattering lengths far exceed all other length scales in the problem. The Efimov effect, where three particles experiencing short-range interactions can counterintuitively exhibit an infinite number of bound or quasibound energy levels, is the most famous example of universality. Tremendous progress in the field of universal Efimov physics has taken off, driven particularly by a combination of experimental and theoretical studies in the past decade, and prior to the first observation in 2006, by an extensive set of theoretical studies dating back to 1970. Because experimental observations of Efimov physics have usually relied on resonances or interference phenomena in three-body recombination, this connects naturally with the processes of molecule formation in a low-temperature gas of atoms or nucleons, and more generally with N-body recombination processes. Some other topics not closely related to the Efimov effect are also reviewed in this article, including confinement-induced resonances for explorations of lower-dimensionality systems, and some chemically interesting systems with longer-range forces such as the ion-atom-atom recombination problem. DOI: 10.1103/RevModPhys.89.035006 CONTENTS I. Introduction and Overview 2 A. Systems with finite-range interactions 2 B. Coulomb systems 3 C. Chemical physics 5 D. Fragmentation, recombination, and molecule formation 6 E. Recombination processes involving cluster resonances with more than three particles 8 II. Adiabatic Hyperspherical Treatment 8 A. Recombination cross sections and rate coefficients 11 III. The Birth of Few-body Physics: The Effects of Thomas and Efimov 13 A. The Thomas collapse 13 B. Efimov physics and universality in ultracold gases 13 C. Faddeev equations for three identical bosons: Bound states 13 1. Hamiltonian and Faddeev operator equations 13 2. Faddeev equations in momentum representation 14 3. Separable potential approximation: Two-body transition elements and the reduced Faddeev equation 15 D. Separable potentials for van der Waals pairwise interactions 16 E. The Efimov spectrum and its universal aspects 17 F. Efimov states in homonuclear systems 18},
author = {Greene, Chris H and Giannakeas, P and P{\'{e}}rez-R{\'{i}}os, J},
doi = {10.1103/RevModPhys.89.035006},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Greene, Giannakeas, P{\'{e}}rez-R{\'{i}}os - Unknown - Universal few-body physics and cluster formation.pdf:pdf},
journal = {Reviews of Modern Physics},
title = {{Universal Few-Body Physics and Cluster Formation}},
url = {https://journals.aps.org/rmp/pdf/10.1103/RevModPhys.89.035006},
volume = {89},
year = {2017}
}
@article{Meierovich1996,
abstract = {Bosonic van der Waals clusters of sizes three, four, and five are studied by diffusion quantum Monte-Carlo techniques. In particular we study the unbinding transition, the ultraquantum limit where the ground state ceases to exist as a bound state. We discuss the quality of trial wave functions used in the calculations, the critical behavior in the vicinity of the unbinding transition, and simple improvements of the diffusion Monte Carlo algorithm.},
annote = {The elegant solution of optimizing var/E. (Umrigar1999)

A lot of good discussion input on trial wf optimization.},
author = {Meierovich, M and Mushinski, A and Nightingale, M P},
doi = {10.1063/1.472459},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Meierovich, Mushinski, Nightingale - 1996 - van der Waals clusters in the ultraquantum limit A Monte Carlo study.pdf:pdf},
journal = {The Journal of Chemical Physics},
number = {6498},
title = {{Van Der Waals Clusters in the Ultraquantum Limit: A Monte Carlo Study}},
url = {https://doi.org/10.1063/1.472459 http://aip.scitation.org/toc/jcp/105/15},
volume = {105},
year = {1996}
}
@article{Vitiello1991,
abstract = {{An implementation of the Green's-function Monte Carlo method, using a shadow wave function as the importance function, is presented. This implementation gives faster convergence and more stable random walks than previous versions. The method is used to calculate the ground-state energy and the radial distribution function g(r) of solid He at density p=0.0335 A . The results obtained are com-pared with the literature and with the experimental values. Recently, an algorithm for the Monte Carlo solution of the Schrodinger equation was introduced' that used the shadow wave function as the importance function in the calculations. The motivation was that the shadow wave function has many features that make it a much im-proved candidate for an importance function in Green's-function Monte Carlo simulations. For example, the sha-dow wave function has Bose symmetry, is translationally invariant in the solid phase, and requires no a priori in-troduction of a lattice in the solid calculations. In addi-tion, the same form of the wave function can be used in the liquid and solid phases with just a change in the vari-ational parameters. Furthermore, an artificially equili-brated liquid at high density will crystallize from a solid seed in three-dimensional variational calculations. The algorithm presented in Refs. 1 and 2 is based on the Green's function Monte Carlo method developed by Kalos. In this method the integral form of the Schrodinger equation +o(R) =ED j G(R, R'){\%}'0(R')dR' is used. The kernel G(R, R'), the Green's function of the problem, is formally the inverse of the Hamiltonian operator g2 H= — g 7;+V, 2{\&}i where V is the interaction potential. Eo is the ground-state energy of the system described by the eigenfunction 00 that satisfies the Schrodinger equation H4 (R)=E.{\%} (R) . The essence of the method is to solve the integral equa-tion in Eq. (1) iteratively: 4'"'(R)=E I G(R, R')4'" "(R')dR', (4) with the iterations carried out by Monte Carlo methods. In the last equation E, is our best estimate of the ground-state energy. In the limit of large n, qt'"'(R) con-verges to {\%}'o(R {\}}, the lowest eigenfunction of the Schrodinger equation not orthogonal to 0" '(R). The iterations are initiated with a set of coordinates drawn from a trial wave function, often from a variational Monte Carlo calculation and each iteration is performed by sampling a new set of coordinates R from the Green's function, given the set R' from the previous iteration, n — 1. Each iteration is termed a generation and the ran-dom walk which is composed of many generations, asymptotically converges to the ground-state eigenfunc-tion. The Green's function is not known exactly for most forces and cannot be sampled directly in a Monte Carlo simulation. It is possible, though, to sample G (R, R ') re-cursively and this is the basis for the Green's function Monte Carlo method. More detailed descriptions are given in Ceperley and Kalos and in Schmidt and Kalos. The Green's function Monte Carlo method sketched above is subject to large statistical Auctuations and ran-dom walks may not converge. These undesirable aspects can be avoided through the introduction of importance sampling into the calculation. Importance sampling im-proves the Monte Carlo calculation by biasing the ran-dom walk to avoid strongly repulsive regions of the domain and to stay in regions where contributions to the next generation of Eq. (4) are likely. A good approxima-tion for the importance function is a variational wave function which contains as much of the physics as possi-ble. In the calculations described here, the shadow wave function is used as the importance function. The form of the shadow wave function is given by 4 T (R) = f:-(R,s)dS, (5) where R = Ir " r2, . . . , r " I is the 3-X dimensional vector of the coordinates of the particles and S= Is " s2, . . . , s " I is a 3-X dimensional vector of auxiliary coordinates. We call the latter shadow particles. The function =(R,S) is defined as :-(R,S)=p " (R) Q 8(rk — sk)p, (S), k where 7373 1991 The American Physical Society},
author = {Vitiello, Silvio A and Whitlock, Paula A},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Vitiello, Whitlock - 1991 - Green s-function Monte Carlo algorithm for the solution of the Schrodinger equation with the shadow wave fun.pdf:pdf},
journal = {Physical Review B},
number = {14},
title = {{Greens-Function Monte Carlo Algorithm for the Solution of the Schrodinger Equation with the Shadow Wave Function}},
url = {https://journals.aps.org/prb/pdf/10.1103/PhysRevB.44.7373},
volume = {44},
year = {1991}
}
@incollection{Bishop2006,
author = {Bishop, Christopher M.},
booktitle = {Large-Scale Kernel Machines},
edition = {1},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - full-text.pdf:pdf},
isbn = {978-0-387-31073-2},
publisher = {Springer-Verlag New York},
title = {{Pattern Recognition and Machine Learning}},
year = {2006}
}
@article{Lin2000,
abstract = {An algorithm is proposed to optimize quantum Monte Carlo ͑QMC͒ wave functions based on Newton's method and analytical computation of the first and second derivatives of the variational energy. This direct application of the variational principle yields significantly lower energy than variance minimization methods when applied to the same trial wave function. Quadratic convergence to the local minimum of the variational parameters is achieved. A general theorem is presented, which substantially simplifies the analytic expressions of derivatives in the case of wave function optimization. To demonstrate the method, the ground-state energies of the first-row elements are calculated.},
author = {Lin, Xi and Zhang, Hongkai and Rappe, Andrew M},
doi = {10.1063/1.1455618},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Lin, Zhang, Rappe - 2000 - hei.pdf:pdf},
journal = {The Journal of Chemical Physics},
pages = {2650},
title = {{Optimization of Quantum Monte Carlo Wave Functions Using Analytical Energy}},
url = {https://doi.org/10.1063/1.480839},
volume = {112},
year = {2000}
}
@unpublished{Han2017,
abstract = {Generative modeling, which learns joint probability distribution from training data and generates samples according to it, is an important task in machine learning and artificial intelligence. Inspired by probabilistic interpretation of quantum physics, we propose a generative model using matrix product states, which is a tensor network originally proposed for describing (particularly one-dimensional) entangled quantum states. Our model enjoys efficient learning by utilizing the density matrix renormalization group method which allows dynamic adjusting dimensions of the tensors, and offers an efficient direct sampling approach, Zipper, for generative tasks. We apply our method to generative modeling of several standard datasets including the principled Bars and Stripes, random binary patterns and the MNIST handwritten digits, to illustrate ability of our model, and discuss features as well as drawbacks of our model over popular generative models such as Hopfield model, Boltzmann machines and generative adversarial networks. Our work shed light on many interesting directions for future exploration on the development of quantum-inspired algorithms for unsupervised machine learning, which is of possibility of being realized by a quantum device.},
author = {Han, Zhao-Yu and Wang, Jun and Fan, Heng and Wang, Lei and Zhang, Pan},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Han et al. - Unknown - Unsupervised Generative Modeling Using Matrix Product States(2).pdf:pdf},
title = {{Unsupervised Generative Modeling Using Matrix Product States}},
url = {https://arxiv.org/pdf/1709.01662.pdf},
year = {2017}
}
@article{Pederiva1996,
abstract = {The ideas of the shadow wave function are applied to construct a variational wave function to describe the liquid and the solid phase of a system that obeys Fermi statistics. The shadow variables are introduced in the symmetric correlating factor. The antisymmetric part is a standard determinant of plane waves modified by backflow effect. Variational Monte Carlo calculations for 3 He provide ground-state energies in the liquid phase at the level of the most elaborate trial function available in the literature. With this wave function, properties like translational invariance and antisymmetry under particle interchange are maintained even in the crystalline phase. ͓S0163-1829͑96͒08321-X͔},
author = {Pederiva, F and Vitiello, S A and Gernoth, K and Fantoni, S and Reatto, L},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Pederiva et al. - Unknown - Shadow wave function for liquid and solid 3 He.pdf:pdf},
journal = {Physical Review B},
number = {22},
title = {{Shadow Wave Function for Liquid and Solid 3He}},
url = {https://journals.aps.org/prb/pdf/10.1103/PhysRevB.53.15129},
volume = {53},
year = {1996}
}
@article{Operetto2004,
abstract = {A shadow wave function ͑SWF͒ is employed along with variational Monte Carlo techniques to describe the ground-state properties of solid molecular para-hydrogen. The study has been extended to densities below the equilibrium value, to obtain a parameterization of the SWF useful for the description of inhomogeneous phases. We also present an estimate of the vacancy formation energy as a function of the density, and discuss the importance of relaxation effects near the vacant site.},
author = {Operetto, Francesco and Pederiva, Francesco},
doi = {10.1103/PhysRevB.69.024203},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Operetto, Pederiva - Unknown - Variational Monte Carlo study of the ground-state properties and vacancy formation energy of solid para-H.pdf:pdf},
journal = {Physical Review B},
keywords = {0530Jp,6780Mg,PACS number͑s͒},
number = {2},
title = {{Variational Monte Carlo Study of the Ground-State Properties and Vacancy Formation Energy of Solid Para-H2 Using a Shadow Wave Function}},
url = {https://journals.aps.org/prb/pdf/10.1103/PhysRevB.69.024203},
volume = {69},
year = {2004}
}
@book{Casella2006,
abstract = {Review From the reviews: .,."There are interesting and non-standard topics that are not usually included in a first course in measture-theoretic probability including Markov Chains and MCMC, the bootstrap, limit theorems for martingales and mixing sequences, Brownian motion and Markov processes. The material is well-suported with many end-of-chapter problems." D.L. McLeish for Short Book Reviews of the ISI, December 2006 "The reader sees not only how measure theory is used to develop probability theory, but also how probability theory is used in applications. a The discourse is delivered in a theorem proof format and thus is better suited for classroom a . The authors prose is generally well thought out a . will make an attractive choice for a two-semester course on measure and probability, or as a second course for students with a semester of measure or probability theory under their belt." (Peter C. Kiessler, Journal of the American Statistical Association, Vol. 102 (479), 2007) "The book is a well written self-contained textbook on measure and probability theory. It consists of 18 chapters. Every chapter contains many well chosen examples and ends with several problems related to the earlier developed theory (some with hints). a At the very end of the book there is an appendix collecting necessary facts from set theory, calculus and metric spaces. The authors suggest a few possibilities on how to use their book." (Kazimierz Musial, Zentralblatt MATH, Vol. 1125 (2), 2008) "The title of the book consists of the names of its two basic parts. The booka (TM)s third part is comprised of some special topics from probability theory. a The authors suggest using the book intwo-semester graduate programs in statistics or a one-semester seminar on special topics. The material of the book is standard a is clear, comprehensive and a {\~{}}without being intimidatinga (TM)." (Rimas NorvaiAa, Mathematical Reviews, Issue 2007 f) Product Description This is a graduate level textbook on measure theory and probability theory. The book can be used as a text for a two semester sequence of courses in measure theory and probability theory, with an option to include supplemental material on stochastic processes and special topics. It is intended primarily for first year Ph.D. students in mathematics and statistics although mathematically advanced students from engineering and economics would also find the book useful. Prerequisites are kept to the minimal level of an understanding of basic real analysis concepts such as limits, continuity, differentiability, Riemann integration, and convergence of sequences and series. A review of this material is included in the appendix. The book starts with an informal introduction that provides some heuristics into the abstract concepts of measure and integration theory, which are then rigorously developed. The first part of the book can be used for a standard real analysis course for both mathematics and statistics Ph.D. students as it provides full coverage of topics such as the construction of Lebesgue-Stieltjes measures on real line and Euclidean spaces, the basic convergence theorems, L p spaces, signed measures, Radon-Nikodym theorem, Lebesgue's decomposition theorem and the fundamental theorem of Lebesgue integration on R, product spaces and product measures, and Fubini-Tonelli theorems. It also provides an elementary introduction to Banach and Hilbert spaces, convolutions, Fourier series and Fourier and Plancherel transforms. Thus part I would be particularly useful for students in a typical Statistics Ph.D. program if a separate course on real analysis is not a standard requirement. Part II (chapters 6-13) provides full coverage of standard graduate level probability theory. It starts with Kolmogorov's probability model and Kolmogorov's existence theorem. It then treats thoroughly the laws of large numbers including renewal theory and ergodic theorems with applications and then weak convergence of probability distributions, characteristic functions, the Levy-Cramer continuity theorem and the central limit theorem as well as stable laws. It ends with conditional expectations and conditional probability, and an introduction to the theory of discrete time martingales. Part III (chapters 14-18) provides a modest coverage of discrete time Markov chains with countable and general state spaces, MCMC, continuous time discrete space jump Markov processes, Brownian motion, mixing sequences, bootstrap methods, and branching processes. It could be used for a topics/seminar course or as an introduction to stochastic processes. From the reviews: "...There are interesting and non-standard topics that are not usually included in a first course in measture-theoretic probability including Markov Chains and MCMC, the bootstrap, limit theorems for martingales and mixing sequences, Brownian motion and Markov processes. The material is well-suported with many end-of-chapter problems." D.L. McLeish for Short Book Reviews of the ISI, December 2006},
author = {Devore, Jay L and Berk, Kenneth N},
edition = {2nd},
file = {:Users/Vilde/Downloads/(Springer Texts in Statistics) Jay L. Devore, Kenneth N. Berk (auth.)-Modern Mathematical Statistics with Applications  -Springer-Verlag New York (2012).pdf:pdf},
isbn = {978-1-4614-0390-6},
publisher = {Springer Science + Business Media},
title = {{Modern Mathematical Statistics with Applications}},
url = {http://books.google.com/books?id=9tv0taI8l6YC},
year = {2012}
}
@article{Huang2017,
abstract = {Despite their exceptional flexibility and popularity, Monte Carlo methods often suffer from slow mixing times for challenging statistical physics problems. We present a general strategy to overcome this difficulty by adopting ideas and techniques from the machine learning community. We fit the unnormalized probability of the physical model to a feed-forward neural network and reinterpret the architecture as a restricted Boltzmann machine. Then, exploiting its feature detection ability, we utilize the restricted Boltzmann machine to propose efficient Monte Carlo updates to speed up the simulation of the original physical system. We implement these ideas for the Falicov-Kimball model and demonstrate an improved acceptance ratio and autocorrelation time near the phase transition point.},
author = {Huang, Li and Wang, Lei},
doi = {10.1103/PhysRevB.95.035105},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Huang, Wang - 2017 - Accelerated Monte Carlo simulations with restricted Boltzmann machines.pdf:pdf},
journal = {Physical Review B},
title = {{Accelerated Monte Carlo Simulations with Restricted Boltzmann Machines}},
url = {https://journals.aps.org/prb/pdf/10.1103/PhysRevB.95.035105},
volume = {95},
year = {2017}
}
@article{Carleo2017,
abstract = {The challenge posed by the many-body problem in quantum physics originates from the difficulty of describing the nontrivial correlations encoded in the exponential complexity of the many-body wave function. Here we demonstrate that systematic machine learning of the wave function can reduce this complexity to a tractable computational form for some notable cases of physical interest. We introduce a variational representation of quantum states based on artificial neural networks with a variable number of hidden neurons. A reinforcement-learning scheme we demonstrate is capable of both finding the ground state and describing the unitary time evolution of complex interacting quantum systems. Our approach achieves high accuracy in describing prototypical interacting spins models in one and two dimensions.},
author = {Carleo, Giuseppe and Troyer, Matthias},
doi = {10.1126/science.aag2302},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Carleo, Troyer - 2017 - Solving the quantum many-body problem with artificial neural networks.pdf:pdf},
issn = {1095-9203},
journal = {Science},
month = {feb},
number = {6325},
pages = {602--606},
pmid = {28183973},
publisher = {American Association for the Advancement of Science},
title = {{Solving the Quantum Many-Body Problem with Artificial Neural Networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/28183973},
volume = {355},
year = {2017}
}
@article{Theis2011,
abstract = {Statistical models of natural images provide an important tool for researchers in the fields of ma-chine learning and computational neuroscience. The canonical measure to quantitatively assess and compare the performance of statistical models is given by the likelihood. One class of statis-tical models which has recently gained increasing popularity and has been applied to a variety of complex data is formed by deep belief networks. Analyses of these models, however, have often been limited to qualitative analyses based on samples due to the computationally intractable nature of their likelihood. Motivated by these circumstances, the present article introduces a consistent estimator for the likelihood of deep belief networks which is computationally tractable and simple to apply in practice. Using this estimator, we quantitatively investigate a deep belief network for natural image patches and compare its performance to the performance of other models for natural image patches. We find that the deep belief network is outperformed with respect to the likelihood even by very simple mixture models.},
annote = {Training of GB-RBMs known to be hard, modifiactions to improve it proposed by amongst other this article: They iIllustrate that in terms of likelihood estimation GRBMs are already outperformed by simple mixture models. (Melchior2017).

Here it is mentioned briefly that a GB-RBM can be regarded as a mixture of Gaussians (Melchior2017).

To derive a better understanding of the limitations of the model, the likelihood of the model is compared to classical machine learning methods. They analyse the model to show the failures empirically, but there are few works accounting for the failure analytically (Melchior2012).},
author = {Theis, Lucas and Gerwinn, Sebastian and Sinz, Fabian and Bethge, Matthias},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Theis LUCASTHEIS et al. - 2011 - In All Likelihood, Deep Belief Is Not Enough.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {deep belief network,likelihood estimation,natural image statistics,potential log-likelihood,restricted Boltzmann machine},
number = {Nov},
pages = {3071--3096},
title = {{In All Likelihood, Deep Belief Is Not Enough}},
url = {http://www.jmlr.org/papers/volume12/theis11a/theis11a.pdf},
volume = {12},
year = {2011}
}
@book{Gareth2013,
abstract = {3'-Azido-2',3'-dideoxythymidine (AZT, 1, zidovudine, RetrovirTM) is used to treat patients with human immunodeficiency virus (HIV) infection. AZT, after conversion to AZT-5'-triphosphate (AZT-TP) by cellular enzymes, inhibits HIV-reverse transcriptase (HIV-RT). The major clinical limitations of AZT are due to clinical toxicities that include bone marrow suppression, hepatic abnormalities and myopathy, absolute dependence on host cell kinase-mediated activation which leads to low activity, limited brain uptake, a short half-life of about one hour in plasma that dictates frequent administration to maintain therapeutic drug levels, low potential for metabolic activation and/or high susceptibility to catabolism, and the rapid development of resistance by HIV-1. These limitations have prompted the development of strategies for designing prodrugs of AZT. A variety of 5'-O-substituted prodrugs of AZT constitute the subject of this review. The drug-design rationale on which these approaches are based is that the ester conjugate will be converted by hydrolysis and/or enzymatic cleavage to AZT or its 5{\&}prime;-monophosphate (AZT-MP). Most prodrug derivatives of AZT have been prepared by derivatization of AZT at its 5'-O position to provide two prominent classes of compounds that encompass: A) 5'-O-carboxylic esters derived from 1) cyclic 5'-O-carboxylic acids such as steroidal 17b-carboxylic acids, 1-adamantanecarboxylic acid, bicyclam carboxylic acid derivatives, O-acetylsalicylic acid, and carbohydrate derivatives, 2) amino acids, 3) 1, 4-dihydro-1-methyl-3-pyridinylcarboxylic acid, 4) aliphatic fatty acid analogs such as myristic acid containing a heteroatom, or without a heteroatom such as stearic acid, and 5) long chain polyunsaturated fatty acid analogs such as retinoic acid, and B) masked phosphates such as 1) phosphodiesters that include monoalkyl or monoaryl phosphate, carbohydrate, ether lipid, ester lipid, and foscarnet derivatives, 2) a variety of phosphotriesters that include dialkylphosphotriesters, diarylphosphotriesters, glycolate and lactate phosphotriesters, phosphotriester approaches using simultaneous enzymatic and chemical hydrolysis of bis(4-acyloxybenzyl) esters, bis(S-acyl-2-thioethyl) (SATE) esters, cyclosaligenyl prodrugs, glycosyl phosphotriesters, and steroidal phosphotriesters, 3) phosphoramidate derivatives, 4) dinucleoside phosphate derivatives that possess a second anti-HIV moiety such as AZT-P-ddA, AZT-P-ddI, AZTP2AZT, AZTP2ACV), and 5) 5'-hydrogen phosphonate and 5'-methylene phosphonate derivatives of AZT. In these prodrugs, the conjugating moiety is linked to AZT via a 5'-O-ester or 5'-O-phosphate group. 5'-O-Substituted AZT prodrugs have been designed with the objectives of improving anti-HIV activity, enhancing blood-brain barrier penetration, modifying pharmacokinetic properties to increase plasma half-life and improving drug delivery with respect to site-specific targeting or drug localization. Bypassing the first phosphorylation step, regulating transport and conferring sustained release of AZT prolong its duration of action, decrease toxicity and improve patient acceptability. The properties of these prodrugs and their anti-HIV activities are now reviewed.},
author = {Gareth, James and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
file = {:Users/Vilde/Documents/ML spesialpensum/StatisticalLearning.pdf:pdf},
isbn = {978-1-4614-7137-0},
publisher = {Springer Science + Business Media New York},
title = {{An Introduction to Statistical Learning with Applications in R}},
url = {https://link.springer.com/content/pdf/10.1007{\%}2F978-1-4614-7138-7.pdf},
year = {2013}
}
@book{Helgaker2000,
author = {Helgaker, Trygve and J{\o}rgensen, Paul and Olsen, Jeppe},
file = {:Users/Vilde/Downloads/W Langel{\_} T. Helgaker, P. Jorgensen, J. Olsen, T. Helgaker - Molecular electronic-structure theory part 1 (2000, Wiley ).pdf:pdf},
isbn = {0-471-96755-6},
publisher = {John Wiley {\&} Sons Ltd},
title = {{Molecular Electronic-Structure Theory}},
year = {2000}
}
@article{Umrigar2015,
abstract = {Variational Monte Carlo and various projector Monte Carlo (PMC) methods are presented in a unified manner. Similarities and differences between the methods and choices made in designing the methods are discussed. Both methods where the Monte Carlo walk is performed in a discrete space and methods where it is performed in a continuous space are considered. It is pointed out that the usual prescription for importance sampling may not be advantageous depending on the particular quantum Monte Carlo method used and the observables of interest, so alternate prescriptions are presented. The nature of the sign problem is discussed for various versions of PMC methods. A prescription for an exact PMC method in real space, i.e., a method that does not make a fixed-node or similar approximation and does not have a finite basis error, is presented. This method is likely to be practical for systems with a small number of electrons. Approximate PMC methods that are applicable to larger systems and go beyond the fixed-node approximation are also discussed. C 2015 AIP Publishing LLC. [http://dx.doi.org/10.1063/1.4933112]},
author = {Umrigar, C J},
doi = {10.1063/1.4906829},
file = {:Users/Vilde/Library/Application Support/Mendeley Desktop/Downloaded/Umrigar - 2015 - Observations on variational and projector Monte Carlo methods.pdf:pdf},
journal = {The Journal of Chemical Physics},
pages = {164105},
title = {{Observations on Variational and Projector Monte Carlo Methods}},
url = {https://doi.org/10.1063/1.4933112 http://aip.scitation.org/toc/jcp/143/16},
volume = {143},
year = {2015}
}
